{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "996e6224",
   "metadata": {},
   "source": [
    "---\n",
    "# Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746daf51",
   "metadata": {},
   "source": [
    "**Add project_files to system path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f00eba0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jovyan/new_mohamed/Final-Time-Series-Forecasting',\n",
       " '/opt/conda/lib/python39.zip',\n",
       " '/opt/conda/lib/python3.9',\n",
       " '/opt/conda/lib/python3.9/lib-dynload',\n",
       " '',\n",
       " '/opt/conda/lib/python3.9/site-packages',\n",
       " 'Time-Series-Forcasting-Group3']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "if not 'Time-Series-Forcasting-Group3' in sys.path:\n",
    "    sys.path += ['Time-Series-Forcasting-Group3']\n",
    "    \n",
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd15497",
   "metadata": {},
   "source": [
    "**Important library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bda1a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import os\n",
    "from exp.exp_PatchTST import Exp_Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcbca959",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f3f794",
   "metadata": {},
   "source": [
    "---\n",
    "# Working on ETTh1 Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98fb0f8",
   "metadata": {},
   "source": [
    "## Trail 1: PatchTST, Dataset:ETTh1,  Metric: 96\n",
    "### Set hyperparameters\n",
    "Set some parameters (Args) for the our experiment like dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd12fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    **dotdict function**\n",
    "    This function is used to convert a dictionary into\n",
    "    an object whose keys can be accessed as attributes\n",
    "\"\"\"\n",
    "\n",
    "args = dotdict()\n",
    "\n",
    "args.model = 'PatchTST'\n",
    "args.random_seed = 2021\n",
    "args.is_training = 1\n",
    "args.model_id = f\"{args.data}_{args.seq_len}_{args.pred_len}\"\n",
    "args.fc_dropout = 0.3\n",
    "args.head_dropout = 0\n",
    "args.patch_len = 16\n",
    "args.stride = 8\n",
    "args.batch_size = 128\n",
    "args.learning_rate = 0.0001\n",
    "\n",
    "\n",
    "args.use_multi_gpu = False\n",
    "args.use_gpu = True if torch.cuda.is_available() else False\n",
    "args.learning_rate = 0.005\n",
    "args.pred_len = 96 # prediction sequence length\n",
    "args.label_len = 48 # start token length of PatchTST decoder\n",
    "args.use_amp = False # whether to use automatic mixed precision training\n",
    "args.output_attention = False # whether to output attention in ecoder\n",
    "args.features = 'M' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
    "args.train_only=True\n",
    "args.checkpoints = './Checkpoints/PatchTST_checkpoints' # location of model checkpoints\n",
    "args.patience = 3\n",
    "args.train_epochs =100# 6\n",
    "\n",
    "args.data = 'ETTh1'  # data\n",
    "args.root_path = './Datasets/' # root path of data file\n",
    "args.data_path = 'ETTh1.csv' # data file\n",
    "args.target = 'OT' # target feature in S or MS task\n",
    "args.freq = 'h' # freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n",
    "args.seq_len = 336 # input sequence length of PatchTST encoder\n",
    "\n",
    "# PatchTST decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n",
    "args.enc_in = 7 # encoder input size\n",
    "args.dec_in = 7 # decoder input size\n",
    "args.c_out = 7 # output size\n",
    "args.factor = 5 # probsparse attn factor\n",
    "args.d_model =16# 512 # dimension of model\n",
    "args.n_heads = 4#8 # num of heads\n",
    "args.e_layers = 3#2 # num of encoder layers\n",
    "args.d_layers = 1 # num of decoder layers\n",
    "args.d_ff = 128#2048 # dimension of fcn in model\n",
    "args.dropout =0.3# 0.05 # dropout\n",
    "args.attn = 'prob' # attention used in encoder, options:[prob, full]\n",
    "args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n",
    "args.activation = 'gelu' # activation\n",
    "args.distil = True # whether to use distilling in encoder\n",
    "args.mix = True\n",
    "args.padding = 0\n",
    "# args.freq = 'h'\n",
    "args.batch_size = 32 \n",
    "args.loss = 'mse'\n",
    "args.lradj = 'type1'\n",
    "args.num_workers = 0\n",
    "args.itr = 1\n",
    "args.des = \"Exp\"#'exp'\n",
    "args.gpu = 0\n",
    "args.devices = '0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6444f332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter Combination of Trail 1: \n",
      "\n",
      "{'model': 'PatchTST', 'random_seed': 2021, 'is_training': 1, 'model_id': 'None_None_None', 'fc_dropout': 0.3, 'head_dropout': 0, 'patch_len': 16, 'stride': 8, 'batch_size': 32, 'learning_rate': 0.005, 'use_multi_gpu': False, 'use_gpu': True, 'pred_len': 96, 'label_len': 48, 'use_amp': False, 'output_attention': False, 'features': 'M', 'train_only': True, 'checkpoints': './Checkpoints/PatchTST_checkpoints', 'patience': 3, 'train_epochs': 100, 'data': 'ETTh1', 'root_path': './Datasets/', 'data_path': 'ETTh1.csv', 'target': 'OT', 'freq': 'h', 'seq_len': 336, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'factor': 5, 'd_model': 16, 'n_heads': 4, 'e_layers': 3, 'd_layers': 1, 'd_ff': 128, 'dropout': 0.3, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'mix': True, 'padding': 0, 'loss': 'mse', 'lradj': 'type1', 'num_workers': 0, 'itr': 1, 'des': 'Exp', 'gpu': 0, 'devices': '0,1,2,3'}\n"
     ]
    }
   ],
   "source": [
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.devices = args.devices.replace(' ','')\n",
    "    device_ids = args.devices.split(',')\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]\n",
    "    \n",
    "print(\"Hyperparameter Combination of Trail 1: \\n\") \n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cf32b0",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eedf44c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "train 8209\n",
      "val 2785\n",
      "test 2785\n",
      "\titers: 100, epoch: 1 | loss: 0.5151863\n",
      "\tspeed: 0.0759s/iter; left time: 1936.5192s\n",
      "\titers: 200, epoch: 1 | loss: 0.4441786\n",
      "\tspeed: 0.0671s/iter; left time: 1704.7053s\n",
      "Epoch: 1 cost time: 18.41019082069397\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.5304114 Vali Loss: 0.7279106 Test Loss: 0.4189521\n",
      "Validation loss decreased (inf --> 0.727911).  Saving model ...\n",
      "Updating learning rate to 0.005\n",
      "\titers: 100, epoch: 2 | loss: 0.4038369\n",
      "\tspeed: 0.1581s/iter; left time: 3991.8206s\n",
      "\titers: 200, epoch: 2 | loss: 0.4288949\n",
      "\tspeed: 0.0710s/iter; left time: 1786.2780s\n",
      "Epoch: 2 cost time: 17.306489944458008\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.4001373 Vali Loss: 0.7182564 Test Loss: 0.4168549\n",
      "Validation loss decreased (0.727911 --> 0.718256).  Saving model ...\n",
      "Updating learning rate to 0.0025\n",
      "\titers: 100, epoch: 3 | loss: 0.3390920\n",
      "\tspeed: 0.1779s/iter; left time: 4445.9986s\n",
      "\titers: 200, epoch: 3 | loss: 0.2963939\n",
      "\tspeed: 0.0740s/iter; left time: 1842.7161s\n",
      "Epoch: 3 cost time: 18.613014221191406\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.3540420 Vali Loss: 0.7060193 Test Loss: 0.4089992\n",
      "Validation loss decreased (0.718256 --> 0.706019).  Saving model ...\n",
      "Updating learning rate to 0.00125\n",
      "\titers: 100, epoch: 4 | loss: 0.3577551\n",
      "\tspeed: 0.1618s/iter; left time: 4001.8008s\n",
      "\titers: 200, epoch: 4 | loss: 0.3874617\n",
      "\tspeed: 0.0570s/iter; left time: 1404.0802s\n",
      "Epoch: 4 cost time: 16.198665142059326\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.3428958 Vali Loss: 0.6671915 Test Loss: 0.3932728\n",
      "Validation loss decreased (0.706019 --> 0.667192).  Saving model ...\n",
      "Updating learning rate to 0.000625\n",
      "\titers: 100, epoch: 5 | loss: 0.3059645\n",
      "\tspeed: 0.1563s/iter; left time: 3824.7914s\n",
      "\titers: 200, epoch: 5 | loss: 0.3530701\n",
      "\tspeed: 0.0687s/iter; left time: 1675.4985s\n",
      "Epoch: 5 cost time: 16.000317096710205\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.3354728 Vali Loss: 0.6769241 Test Loss: 0.3824903\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0003125\n",
      "\titers: 100, epoch: 6 | loss: 0.2575989\n",
      "\tspeed: 0.1500s/iter; left time: 3633.9940s\n",
      "\titers: 200, epoch: 6 | loss: 0.3064558\n",
      "\tspeed: 0.0669s/iter; left time: 1614.5864s\n",
      "Epoch: 6 cost time: 17.191694498062134\n",
      "Epoch: 6, Steps: 256 | Train Loss: 0.3324869 Vali Loss: 0.6812342 Test Loss: 0.3886511\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.00015625\n",
      "\titers: 100, epoch: 7 | loss: 0.2775109\n",
      "\tspeed: 0.1550s/iter; left time: 3714.7392s\n",
      "\titers: 200, epoch: 7 | loss: 0.3773062\n",
      "\tspeed: 0.0692s/iter; left time: 1651.1612s\n",
      "Epoch: 7 cost time: 17.00107502937317\n",
      "Epoch: 7, Steps: 256 | Train Loss: 0.3312900 Vali Loss: 0.6731864 Test Loss: 0.3858219\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): PatchTST_backbone(\n",
       "    (backbone): TSTiEncoder(\n",
       "      (W_P): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (encoder): TSTEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-2): 3 x TSTEncoderLayer(\n",
       "            (self_attn): _MultiheadAttention(\n",
       "              (W_Q): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (W_K): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (W_V): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (sdp_attn): _ScaledDotProductAttention(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "                (1): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
       "            (norm_attn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.3, inplace=False)\n",
       "              (3): Linear(in_features=128, out_features=16, bias=True)\n",
       "            )\n",
       "            (dropout_ffn): Dropout(p=0.3, inplace=False)\n",
       "            (norm_ffn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): Flatten_Head(\n",
       "      (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "      (linear): Linear(in_features=656, out_features=96, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exp = Exp_Main\n",
    "setting=f'PatchTST_train_on_{args.data}_{args.pred_len}'\n",
    "# set experiments\n",
    "exp = Exp(args)\n",
    "exp.train(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393f553e",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f01abc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 2785\n",
      "mse:0.3932727575302124, mae:0.4153849184513092, rse:0.5956631302833557\n"
     ]
    }
   ],
   "source": [
    "exp.test(setting)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330ff195",
   "metadata": {},
   "source": [
    "---\n",
    "## Trail 2: PatchTST, Dataset:ETTh1 , Metric: 192\n",
    "### Set hyperparameters\n",
    "Set some parameters (Args) for the our experiment like dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c41ad455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ETTh1,  Prediction Length : 192\n"
     ]
    }
   ],
   "source": [
    "args.pred_len = 192 # prediction sequence length\n",
    "print(f\"Dataset: {args.data},  Prediction Length : {args.pred_len}\") \n",
    "# print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379a3424",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3efeb281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "train 8113\n",
      "val 2689\n",
      "test 2689\n",
      "\titers: 100, epoch: 1 | loss: 0.4972065\n",
      "\tspeed: 0.0748s/iter; left time: 1884.9088s\n",
      "\titers: 200, epoch: 1 | loss: 0.4336420\n",
      "\tspeed: 0.0728s/iter; left time: 1827.9767s\n",
      "Epoch: 1 cost time: 18.494192838668823\n",
      "Epoch: 1, Steps: 253 | Train Loss: 0.5782521 Vali Loss: 0.9129704 Test Loss: 0.4498765\n",
      "Validation loss decreased (inf --> 0.912970).  Saving model ...\n",
      "Updating learning rate to 0.005\n",
      "\titers: 100, epoch: 2 | loss: 0.4021264\n",
      "\tspeed: 0.1832s/iter; left time: 4569.8993s\n",
      "\titers: 200, epoch: 2 | loss: 0.4054012\n",
      "\tspeed: 0.0658s/iter; left time: 1635.9973s\n",
      "Epoch: 2 cost time: 17.123370885849\n",
      "Epoch: 2, Steps: 253 | Train Loss: 0.4446002 Vali Loss: 1.1366206 Test Loss: 0.4531257\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0025\n",
      "\titers: 100, epoch: 3 | loss: 0.3814523\n",
      "\tspeed: 0.1810s/iter; left time: 4469.4422s\n",
      "\titers: 200, epoch: 3 | loss: 0.4221437\n",
      "\tspeed: 0.0712s/iter; left time: 1751.7776s\n",
      "Epoch: 3 cost time: 17.890690326690674\n",
      "Epoch: 3, Steps: 253 | Train Loss: 0.3939760 Vali Loss: 1.0783061 Test Loss: 0.4700369\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.00125\n",
      "\titers: 100, epoch: 4 | loss: 0.3901869\n",
      "\tspeed: 0.1899s/iter; left time: 4642.4481s\n",
      "\titers: 200, epoch: 4 | loss: 0.4803623\n",
      "\tspeed: 0.0681s/iter; left time: 1657.8801s\n",
      "Epoch: 4 cost time: 17.203757286071777\n",
      "Epoch: 4, Steps: 253 | Train Loss: 0.3811764 Vali Loss: 1.0655826 Test Loss: 0.4335218\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): PatchTST_backbone(\n",
       "    (backbone): TSTiEncoder(\n",
       "      (W_P): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (encoder): TSTEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-2): 3 x TSTEncoderLayer(\n",
       "            (self_attn): _MultiheadAttention(\n",
       "              (W_Q): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (W_K): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (W_V): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (sdp_attn): _ScaledDotProductAttention(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "                (1): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
       "            (norm_attn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.3, inplace=False)\n",
       "              (3): Linear(in_features=128, out_features=16, bias=True)\n",
       "            )\n",
       "            (dropout_ffn): Dropout(p=0.3, inplace=False)\n",
       "            (norm_ffn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): Flatten_Head(\n",
       "      (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "      (linear): Linear(in_features=656, out_features=192, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exp = Exp_Main\n",
    "args.pred_len = 192\n",
    "setting=f'PatchTST_train_on_{args.data}_{args.pred_len}'\n",
    "# set experiments\n",
    "exp = Exp(args)\n",
    "exp.train(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7857441a",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a7a3c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 2689\n",
      "mse:0.44987642765045166, mae:0.4546157121658325, rse:0.6369397640228271\n"
     ]
    }
   ],
   "source": [
    "exp.test(setting)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966aa17f",
   "metadata": {},
   "source": [
    "---\n",
    "## Trail 3: PatchTST, Dataset:ETTh1,  Metric: 336\n",
    "\n",
    "### Set hyperparameters\n",
    "Set some parameters (Args) for the our experiment like dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b5856e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ETTh1,  Prediction Length : 336\n"
     ]
    }
   ],
   "source": [
    "args.pred_len = 336 # prediction sequence length\n",
    "print(f\"Dataset: {args.data},  Prediction Length : {args.pred_len}\") \n",
    "# print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705209cf",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "998b865e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "train 8302\n",
      "val 2878\n",
      "test 2878\n",
      "\titers: 100, epoch: 1 | loss: 0.3344718\n",
      "\tspeed: 0.0694s/iter; left time: 1789.7446s\n",
      "\titers: 200, epoch: 1 | loss: 0.3247386\n",
      "\tspeed: 0.0660s/iter; left time: 1697.1177s\n",
      "Epoch: 1 cost time: 17.75670599937439\n",
      "Epoch: 1, Steps: 259 | Train Loss: 0.4408747 Vali Loss: 0.3721916 Test Loss: 0.3404652\n",
      "Validation loss decreased (inf --> 0.372192).  Saving model ...\n",
      "Updating learning rate to 0.005\n",
      "\titers: 100, epoch: 2 | loss: 0.2608819\n",
      "\tspeed: 0.1612s/iter; left time: 4118.5023s\n",
      "\titers: 200, epoch: 2 | loss: 0.2351755\n",
      "\tspeed: 0.0708s/iter; left time: 1801.2028s\n",
      "Epoch: 2 cost time: 17.503792762756348\n",
      "Epoch: 2, Steps: 259 | Train Loss: 0.2291536 Vali Loss: 0.2295149 Test Loss: 0.2050908\n",
      "Validation loss decreased (0.372192 --> 0.229515).  Saving model ...\n",
      "Updating learning rate to 0.0025\n",
      "\titers: 100, epoch: 3 | loss: 0.1918993\n",
      "\tspeed: 0.1670s/iter; left time: 4222.5122s\n",
      "\titers: 200, epoch: 3 | loss: 0.1933122\n",
      "\tspeed: 0.0689s/iter; left time: 1736.1021s\n",
      "Epoch: 3 cost time: 17.5971736907959\n",
      "Epoch: 3, Steps: 259 | Train Loss: 0.1761852 Vali Loss: 0.1995016 Test Loss: 0.1856215\n",
      "Validation loss decreased (0.229515 --> 0.199502).  Saving model ...\n",
      "Updating learning rate to 0.00125\n",
      "\titers: 100, epoch: 4 | loss: 0.1284760\n",
      "\tspeed: 0.1670s/iter; left time: 4178.1590s\n",
      "\titers: 200, epoch: 4 | loss: 0.2224447\n",
      "\tspeed: 0.0642s/iter; left time: 1599.0356s\n",
      "Epoch: 4 cost time: 17.59629797935486\n",
      "Epoch: 4, Steps: 259 | Train Loss: 0.1662189 Vali Loss: 0.1942462 Test Loss: 0.1758670\n",
      "Validation loss decreased (0.199502 --> 0.194246).  Saving model ...\n",
      "Updating learning rate to 0.000625\n",
      "\titers: 100, epoch: 5 | loss: 0.1533053\n",
      "\tspeed: 0.1600s/iter; left time: 3962.5602s\n",
      "\titers: 200, epoch: 5 | loss: 0.1642608\n",
      "\tspeed: 0.0660s/iter; left time: 1628.1169s\n",
      "Epoch: 5 cost time: 16.81342601776123\n",
      "Epoch: 5, Steps: 259 | Train Loss: 0.1578499 Vali Loss: 0.1977934 Test Loss: 0.1776309\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0003125\n",
      "\titers: 100, epoch: 6 | loss: 0.1343656\n",
      "\tspeed: 0.1668s/iter; left time: 4088.6286s\n",
      "\titers: 200, epoch: 6 | loss: 0.1735907\n",
      "\tspeed: 0.0641s/iter; left time: 1563.6987s\n",
      "Epoch: 6 cost time: 16.020346879959106\n",
      "Epoch: 6, Steps: 259 | Train Loss: 0.1574573 Vali Loss: 0.1939369 Test Loss: 0.1713414\n",
      "Validation loss decreased (0.194246 --> 0.193937).  Saving model ...\n",
      "Updating learning rate to 0.00015625\n",
      "\titers: 100, epoch: 7 | loss: 0.1135342\n",
      "\tspeed: 0.1602s/iter; left time: 3885.0875s\n",
      "\titers: 200, epoch: 7 | loss: 0.1734605\n",
      "\tspeed: 0.0668s/iter; left time: 1613.7510s\n",
      "Epoch: 7 cost time: 16.904083967208862\n",
      "Epoch: 7, Steps: 259 | Train Loss: 0.1541995 Vali Loss: 0.1903215 Test Loss: 0.1723544\n",
      "Validation loss decreased (0.193937 --> 0.190322).  Saving model ...\n",
      "Updating learning rate to 7.8125e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1397794\n",
      "\tspeed: 0.1579s/iter; left time: 3787.4919s\n",
      "\titers: 200, epoch: 8 | loss: 0.1621282\n",
      "\tspeed: 0.0681s/iter; left time: 1626.0041s\n",
      "Epoch: 8 cost time: 16.87517499923706\n",
      "Epoch: 8, Steps: 259 | Train Loss: 0.1527380 Vali Loss: 0.1910122 Test Loss: 0.1725030\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1569609\n",
      "\tspeed: 0.1661s/iter; left time: 3941.4183s\n",
      "\titers: 200, epoch: 9 | loss: 0.1250813\n",
      "\tspeed: 0.0679s/iter; left time: 1604.3095s\n",
      "Epoch: 9 cost time: 17.39609670639038\n",
      "Epoch: 9, Steps: 259 | Train Loss: 0.1522767 Vali Loss: 0.1925583 Test Loss: 0.1731428\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1498338\n",
      "\tspeed: 0.1520s/iter; left time: 3568.0099s\n",
      "\titers: 200, epoch: 10 | loss: 0.1342901\n",
      "\tspeed: 0.0650s/iter; left time: 1518.9914s\n",
      "Epoch: 10 cost time: 15.986849784851074\n",
      "Epoch: 10, Steps: 259 | Train Loss: 0.1525342 Vali Loss: 0.1915675 Test Loss: 0.1719509\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): PatchTST_backbone(\n",
       "    (backbone): TSTiEncoder(\n",
       "      (W_P): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (encoder): TSTEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-2): 3 x TSTEncoderLayer(\n",
       "            (self_attn): _MultiheadAttention(\n",
       "              (W_Q): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (W_K): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (W_V): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (sdp_attn): _ScaledDotProductAttention(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "                (1): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
       "            (norm_attn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.3, inplace=False)\n",
       "              (3): Linear(in_features=128, out_features=16, bias=True)\n",
       "            )\n",
       "            (dropout_ffn): Dropout(p=0.3, inplace=False)\n",
       "            (norm_ffn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): Flatten_Head(\n",
       "      (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "      (linear): Linear(in_features=656, out_features=3, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exp = Exp_Main\n",
    "args.pred_len = 3\n",
    "setting=f'PatchTST_train_on_{args.data}_{args.pred_len}'\n",
    "# set experiments\n",
    "exp = Exp(args)\n",
    "exp.train(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1718e2a",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d4e9454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 2878\n",
      "mse:0.17235438525676727, mae:0.27333182096481323, rse:0.39380258321762085\n"
     ]
    }
   ],
   "source": [
    "exp.test(setting)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb626614",
   "metadata": {},
   "source": [
    "---\n",
    "## Trail 4: PatchTST, Dataset:ETTh1,  Metric: 720\n",
    "\n",
    "### Set hyperparameters\n",
    "Set some parameters (Args) for the our experiment like dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3788c2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ETTh1,  Prediction Length : 720\n"
     ]
    }
   ],
   "source": [
    "args.pred_len = 720 # prediction sequence length\n",
    "print(f\"Dataset: {args.data},  Prediction Length : {args.pred_len}\") \n",
    "# print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72c7e51",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f299a8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "train 8301\n",
      "val 2877\n",
      "test 2877\n",
      "\titers: 100, epoch: 1 | loss: 0.5212657\n",
      "\tspeed: 0.0661s/iter; left time: 1706.5893s\n",
      "\titers: 200, epoch: 1 | loss: 0.3030730\n",
      "\tspeed: 0.0708s/iter; left time: 1820.6244s\n",
      "Epoch: 1 cost time: 17.715425729751587\n",
      "Epoch: 1, Steps: 259 | Train Loss: 0.4712917 Vali Loss: 0.3448377 Test Loss: 0.3140948\n",
      "Validation loss decreased (inf --> 0.344838).  Saving model ...\n",
      "Updating learning rate to 0.005\n",
      "\titers: 100, epoch: 2 | loss: 0.1874618\n",
      "\tspeed: 0.1680s/iter; left time: 4291.2789s\n",
      "\titers: 200, epoch: 2 | loss: 0.2577136\n",
      "\tspeed: 0.0650s/iter; left time: 1653.7612s\n",
      "Epoch: 2 cost time: 17.31331515312195\n",
      "Epoch: 2, Steps: 259 | Train Loss: 0.2389915 Vali Loss: 0.2476892 Test Loss: 0.2330408\n",
      "Validation loss decreased (0.344838 --> 0.247689).  Saving model ...\n",
      "Updating learning rate to 0.0025\n",
      "\titers: 100, epoch: 3 | loss: 0.2026190\n",
      "\tspeed: 0.1532s/iter; left time: 3872.1060s\n",
      "\titers: 200, epoch: 3 | loss: 0.1800532\n",
      "\tspeed: 0.0689s/iter; left time: 1734.6719s\n",
      "Epoch: 3 cost time: 17.889608144760132\n",
      "Epoch: 3, Steps: 259 | Train Loss: 0.1938484 Vali Loss: 0.2197589 Test Loss: 0.2050859\n",
      "Validation loss decreased (0.247689 --> 0.219759).  Saving model ...\n",
      "Updating learning rate to 0.00125\n",
      "\titers: 100, epoch: 4 | loss: 0.1967302\n",
      "\tspeed: 0.1670s/iter; left time: 4179.5297s\n",
      "\titers: 200, epoch: 4 | loss: 0.1291154\n",
      "\tspeed: 0.0640s/iter; left time: 1595.8293s\n",
      "Epoch: 4 cost time: 16.186620235443115\n",
      "Epoch: 4, Steps: 259 | Train Loss: 0.1806932 Vali Loss: 0.2195199 Test Loss: 0.1984482\n",
      "Validation loss decreased (0.219759 --> 0.219520).  Saving model ...\n",
      "Updating learning rate to 0.000625\n",
      "\titers: 100, epoch: 5 | loss: 0.1961870\n",
      "\tspeed: 0.1640s/iter; left time: 4062.4642s\n",
      "\titers: 200, epoch: 5 | loss: 0.1491721\n",
      "\tspeed: 0.0680s/iter; left time: 1676.3251s\n",
      "Epoch: 5 cost time: 17.992636680603027\n",
      "Epoch: 5, Steps: 259 | Train Loss: 0.1773702 Vali Loss: 0.2242986 Test Loss: 0.2060752\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0003125\n",
      "\titers: 100, epoch: 6 | loss: 0.1637586\n",
      "\tspeed: 0.1731s/iter; left time: 4242.5016s\n",
      "\titers: 200, epoch: 6 | loss: 0.1525438\n",
      "\tspeed: 0.0689s/iter; left time: 1682.6489s\n",
      "Epoch: 6 cost time: 17.396287441253662\n",
      "Epoch: 6, Steps: 259 | Train Loss: 0.1727093 Vali Loss: 0.2202408 Test Loss: 0.1969083\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.00015625\n",
      "\titers: 100, epoch: 7 | loss: 0.1360321\n",
      "\tspeed: 0.1621s/iter; left time: 3929.5082s\n",
      "\titers: 200, epoch: 7 | loss: 0.1627487\n",
      "\tspeed: 0.0679s/iter; left time: 1638.5215s\n",
      "Epoch: 7 cost time: 17.00168800354004\n",
      "Epoch: 7, Steps: 259 | Train Loss: 0.1712782 Vali Loss: 0.2200048 Test Loss: 0.1991123\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): PatchTST_backbone(\n",
       "    (backbone): TSTiEncoder(\n",
       "      (W_P): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (encoder): TSTEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-2): 3 x TSTEncoderLayer(\n",
       "            (self_attn): _MultiheadAttention(\n",
       "              (W_Q): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (W_K): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (W_V): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (sdp_attn): _ScaledDotProductAttention(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "                (1): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
       "            (norm_attn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.3, inplace=False)\n",
       "              (3): Linear(in_features=128, out_features=16, bias=True)\n",
       "            )\n",
       "            (dropout_ffn): Dropout(p=0.3, inplace=False)\n",
       "            (norm_ffn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): Flatten_Head(\n",
       "      (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "      (linear): Linear(in_features=656, out_features=4, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exp = Exp_Main\n",
    "args.pred_len = 4\n",
    "setting=f'PatchTST_train_on_{args.data}_{args.pred_len}'\n",
    "# set experiments\n",
    "exp = Exp(args)\n",
    "exp.train(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce832af5",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d474f8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 2877\n",
      "mse:0.19844816625118256, mae:0.2914038896560669, rse:0.42253634333610535\n"
     ]
    }
   ],
   "source": [
    "exp.test(setting)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993f0adf",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The training process is progressing well and the `PatchTST` model is being optimized in an effective manner. \n",
    "- The loss is steadily decreasing over the epochs, which indicates the model is learning and improving. \n",
    "- The validation loss is also decreasing at each epoch, showing the model is generalizing well.\n",
    "- The training speed (secs/iter) improves over time, likely due to optimizations in the model and dropout of neurons. This indicates the model is becoming more efficient as it trains.\n",
    "\n",
    "**The key positive signs I see are:**\n",
    "\n",
    "- Decreasing loss and validation loss\n",
    "- Improving training speed over time\n",
    "- Learning rate decay schedule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739f2102",
   "metadata": {},
   "source": [
    "---\n",
    "# Working on ETTh2 Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3486e4a2",
   "metadata": {},
   "source": [
    "## Trail 1: PatchTST, Dataset:ETTh2,  Metric: 96\n",
    "### Set hyperparameters\n",
    "Set some parameters (Args) for the our experiment like dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e7c9bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ETTh2,  Prediction Length : 96\n"
     ]
    }
   ],
   "source": [
    "args.data_path = 'ETTh2.csv' # data file\n",
    "args.data = 'ETTh2'  # data\n",
    "args.pred_len = 96 # prediction sequence length\n",
    "\n",
    "print(f\"Dataset: {args.data},  Prediction Length : {args.pred_len}\") \n",
    "# print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a416904c",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76ca7b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "train 8209\n",
      "val 2785\n",
      "test 2785\n",
      "\titers: 100, epoch: 1 | loss: 0.4108657\n",
      "\tspeed: 0.0710s/iter; left time: 1809.9244s\n",
      "\titers: 200, epoch: 1 | loss: 0.3111556\n",
      "\tspeed: 0.0652s/iter; left time: 1656.1540s\n",
      "Epoch: 1 cost time: 17.398212432861328\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.5997753 Vali Loss: 0.2730317 Test Loss: 0.3700201\n",
      "Validation loss decreased (inf --> 0.273032).  Saving model ...\n",
      "Updating learning rate to 0.005\n",
      "\titers: 100, epoch: 2 | loss: 0.5012991\n",
      "\tspeed: 0.1698s/iter; left time: 4286.6351s\n",
      "\titers: 200, epoch: 2 | loss: 0.5826704\n",
      "\tspeed: 0.0661s/iter; left time: 1661.5996s\n",
      "Epoch: 2 cost time: 17.30525517463684\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.4644897 Vali Loss: 0.2412224 Test Loss: 0.3228672\n",
      "Validation loss decreased (0.273032 --> 0.241222).  Saving model ...\n",
      "Updating learning rate to 0.0025\n",
      "\titers: 100, epoch: 3 | loss: 0.2503873\n",
      "\tspeed: 0.1681s/iter; left time: 4200.1778s\n",
      "\titers: 200, epoch: 3 | loss: 0.3579534\n",
      "\tspeed: 0.0699s/iter; left time: 1740.4312s\n",
      "Epoch: 3 cost time: 17.700376272201538\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.3816156 Vali Loss: 0.2516633 Test Loss: 0.3534242\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.00125\n",
      "\titers: 100, epoch: 4 | loss: 0.2196120\n",
      "\tspeed: 0.1541s/iter; left time: 3810.6190s\n",
      "\titers: 200, epoch: 4 | loss: 0.2641724\n",
      "\tspeed: 0.0689s/iter; left time: 1697.0724s\n",
      "Epoch: 4 cost time: 17.800501346588135\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.3495773 Vali Loss: 0.2651534 Test Loss: 0.3917835\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.000625\n",
      "\titers: 100, epoch: 5 | loss: 0.4314533\n",
      "\tspeed: 0.1700s/iter; left time: 4159.9815s\n",
      "\titers: 200, epoch: 5 | loss: 0.2819008\n",
      "\tspeed: 0.0701s/iter; left time: 1709.9130s\n",
      "Epoch: 5 cost time: 16.896082401275635\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.3360222 Vali Loss: 0.2837178 Test Loss: 0.4560379\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): PatchTST_backbone(\n",
       "    (backbone): TSTiEncoder(\n",
       "      (W_P): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (encoder): TSTEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-2): 3 x TSTEncoderLayer(\n",
       "            (self_attn): _MultiheadAttention(\n",
       "              (W_Q): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (W_K): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (W_V): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (sdp_attn): _ScaledDotProductAttention(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "                (1): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
       "            (norm_attn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.3, inplace=False)\n",
       "              (3): Linear(in_features=128, out_features=16, bias=True)\n",
       "            )\n",
       "            (dropout_ffn): Dropout(p=0.3, inplace=False)\n",
       "            (norm_ffn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): Flatten_Head(\n",
       "      (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "      (linear): Linear(in_features=656, out_features=96, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exp = Exp_Main\n",
    "setting=f'PatchTST_train_on_{args.data}_{args.pred_len}'\n",
    "# set experiments\n",
    "exp = Exp(args)\n",
    "exp.train(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f50acac",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67caac15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 2785\n",
      "mse:0.3228672444820404, mae:0.3903789520263672, rse:0.4578811526298523\n"
     ]
    }
   ],
   "source": [
    "exp.test(setting)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa0cf48",
   "metadata": {},
   "source": [
    "---\n",
    "## Trail 2: PatchTST,  Metric: 192\n",
    "### Set hyperparameters\n",
    "Set some parameters (Args) for the our experiment like dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c6f9bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ETTh2,  Prediction Length : 192\n"
     ]
    }
   ],
   "source": [
    "args.pred_len = 192 # prediction sequence length\n",
    "print(f\"Dataset: {args.data},  Prediction Length : {args.pred_len}\") \n",
    "# print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0f06f2",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bb6caef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "train 8113\n",
      "val 2689\n",
      "test 2689\n",
      "\titers: 100, epoch: 1 | loss: 0.5860826\n",
      "\tspeed: 0.0696s/iter; left time: 1753.4439s\n",
      "\titers: 200, epoch: 1 | loss: 0.5593444\n",
      "\tspeed: 0.0772s/iter; left time: 1937.7453s\n",
      "Epoch: 1 cost time: 17.95907950401306\n",
      "Epoch: 1, Steps: 253 | Train Loss: 0.6732758 Vali Loss: 0.3943664 Test Loss: 0.5854144\n",
      "Validation loss decreased (inf --> 0.394366).  Saving model ...\n",
      "Updating learning rate to 0.005\n",
      "\titers: 100, epoch: 2 | loss: 0.6403229\n",
      "\tspeed: 0.1818s/iter; left time: 4534.9218s\n",
      "\titers: 200, epoch: 2 | loss: 0.3194021\n",
      "\tspeed: 0.0781s/iter; left time: 1941.4232s\n",
      "Epoch: 2 cost time: 18.829684495925903\n",
      "Epoch: 2, Steps: 253 | Train Loss: 0.5332889 Vali Loss: 0.3651311 Test Loss: 0.4719868\n",
      "Validation loss decreased (0.394366 --> 0.365131).  Saving model ...\n",
      "Updating learning rate to 0.0025\n",
      "\titers: 100, epoch: 3 | loss: 0.5341831\n",
      "\tspeed: 0.1541s/iter; left time: 3804.8737s\n",
      "\titers: 200, epoch: 3 | loss: 0.2848637\n",
      "\tspeed: 0.0768s/iter; left time: 1888.4022s\n",
      "Epoch: 3 cost time: 17.30146312713623\n",
      "Epoch: 3, Steps: 253 | Train Loss: 0.4656512 Vali Loss: 0.3653076 Test Loss: 0.4902059\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.00125\n",
      "\titers: 100, epoch: 4 | loss: 0.3433905\n",
      "\tspeed: 0.1802s/iter; left time: 4403.9393s\n",
      "\titers: 200, epoch: 4 | loss: 0.5393740\n",
      "\tspeed: 0.0668s/iter; left time: 1626.7135s\n",
      "Epoch: 4 cost time: 17.711206197738647\n",
      "Epoch: 4, Steps: 253 | Train Loss: 0.4348430 Vali Loss: 0.3541564 Test Loss: 0.4623881\n",
      "Validation loss decreased (0.365131 --> 0.354156).  Saving model ...\n",
      "Updating learning rate to 0.000625\n",
      "\titers: 100, epoch: 5 | loss: 0.3963664\n",
      "\tspeed: 0.1840s/iter; left time: 4450.9250s\n",
      "\titers: 200, epoch: 5 | loss: 0.4573777\n",
      "\tspeed: 0.0770s/iter; left time: 1855.7433s\n",
      "Epoch: 5 cost time: 18.816550731658936\n",
      "Epoch: 5, Steps: 253 | Train Loss: 0.4174777 Vali Loss: 0.3321130 Test Loss: 0.4137636\n",
      "Validation loss decreased (0.354156 --> 0.332113).  Saving model ...\n",
      "Updating learning rate to 0.0003125\n",
      "\titers: 100, epoch: 6 | loss: 0.3411645\n",
      "\tspeed: 0.1640s/iter; left time: 3925.2390s\n",
      "\titers: 200, epoch: 6 | loss: 0.3879261\n",
      "\tspeed: 0.0750s/iter; left time: 1786.9535s\n",
      "Epoch: 6 cost time: 17.922263860702515\n",
      "Epoch: 6, Steps: 253 | Train Loss: 0.4126613 Vali Loss: 0.3432979 Test Loss: 0.4297382\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.00015625\n",
      "\titers: 100, epoch: 7 | loss: 0.3538094\n",
      "\tspeed: 0.1600s/iter; left time: 3789.8151s\n",
      "\titers: 200, epoch: 7 | loss: 0.4980257\n",
      "\tspeed: 0.0680s/iter; left time: 1603.6741s\n",
      "Epoch: 7 cost time: 17.507463693618774\n",
      "Epoch: 7, Steps: 253 | Train Loss: 0.4069668 Vali Loss: 0.3439063 Test Loss: 0.4513739\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.4428764\n",
      "\tspeed: 0.1810s/iter; left time: 4241.4769s\n",
      "\titers: 200, epoch: 8 | loss: 0.2537404\n",
      "\tspeed: 0.0689s/iter; left time: 1608.4766s\n",
      "Epoch: 8 cost time: 18.495466470718384\n",
      "Epoch: 8, Steps: 253 | Train Loss: 0.4075858 Vali Loss: 0.3397099 Test Loss: 0.4434524\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): PatchTST_backbone(\n",
       "    (backbone): TSTiEncoder(\n",
       "      (W_P): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (encoder): TSTEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-2): 3 x TSTEncoderLayer(\n",
       "            (self_attn): _MultiheadAttention(\n",
       "              (W_Q): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (W_K): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (W_V): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (sdp_attn): _ScaledDotProductAttention(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "                (1): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
       "            (norm_attn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.3, inplace=False)\n",
       "              (3): Linear(in_features=128, out_features=16, bias=True)\n",
       "            )\n",
       "            (dropout_ffn): Dropout(p=0.3, inplace=False)\n",
       "            (norm_ffn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): Flatten_Head(\n",
       "      (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "      (linear): Linear(in_features=656, out_features=192, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exp = Exp_Main\n",
    "setting=f'PatchTST_train_on_{args.data}_{args.pred_len}'\n",
    "# set experiments\n",
    "exp = Exp(args)\n",
    "exp.train(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0cce7a",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "917e3d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 2689\n",
      "mse:0.41376355290412903, mae:0.43530601263046265, rse:0.5157955884933472\n"
     ]
    }
   ],
   "source": [
    "exp.test(setting)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4800f5b0",
   "metadata": {},
   "source": [
    "---\n",
    "## Trail 3: PatchTST, Dataset:ETTh2,  Metric: 336\n",
    "\n",
    "### Set hyperparameters\n",
    "Set some parameters (Args) for the our experiment like dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89e4ba9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ETTh2,  Prediction Length : 336\n"
     ]
    }
   ],
   "source": [
    "args.pred_len = 336 # prediction sequence length\n",
    "print(f\"Dataset: {args.data},  Prediction Length : {args.pred_len}\") \n",
    "# print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1ea36b",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c57ba01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "train 7969\n",
      "val 2545\n",
      "test 2545\n",
      "\titers: 100, epoch: 1 | loss: 0.4255295\n",
      "\tspeed: 0.0736s/iter; left time: 1825.5453s\n",
      "\titers: 200, epoch: 1 | loss: 0.8666487\n",
      "\tspeed: 0.0592s/iter; left time: 1462.5349s\n",
      "Epoch: 1 cost time: 16.672760009765625\n",
      "Epoch: 1, Steps: 249 | Train Loss: 0.7144450 Vali Loss: 0.4767845 Test Loss: 0.5395549\n",
      "Validation loss decreased (inf --> 0.476785).  Saving model ...\n",
      "Updating learning rate to 0.005\n",
      "\titers: 100, epoch: 2 | loss: 0.5763573\n",
      "\tspeed: 0.1889s/iter; left time: 4638.8387s\n",
      "\titers: 200, epoch: 2 | loss: 0.5859736\n",
      "\tspeed: 0.0609s/iter; left time: 1488.1450s\n",
      "Epoch: 2 cost time: 17.194735288619995\n",
      "Epoch: 2, Steps: 249 | Train Loss: 0.6155907 Vali Loss: 0.4994032 Test Loss: 0.6496858\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0025\n",
      "\titers: 100, epoch: 3 | loss: 0.6061680\n",
      "\tspeed: 0.1642s/iter; left time: 3989.3705s\n",
      "\titers: 200, epoch: 3 | loss: 0.7482429\n",
      "\tspeed: 0.0700s/iter; left time: 1694.9301s\n",
      "Epoch: 3 cost time: 17.705214262008667\n",
      "Epoch: 3, Steps: 249 | Train Loss: 0.5385056 Vali Loss: 0.4794028 Test Loss: 0.5501953\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.00125\n",
      "\titers: 100, epoch: 4 | loss: 0.3285275\n",
      "\tspeed: 0.1629s/iter; left time: 3917.4446s\n",
      "\titers: 200, epoch: 4 | loss: 0.3152619\n",
      "\tspeed: 0.0680s/iter; left time: 1629.6196s\n",
      "Epoch: 4 cost time: 16.499975442886353\n",
      "Epoch: 4, Steps: 249 | Train Loss: 0.5118390 Vali Loss: 0.4880065 Test Loss: 0.4463180\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): PatchTST_backbone(\n",
       "    (backbone): TSTiEncoder(\n",
       "      (W_P): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (encoder): TSTEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-2): 3 x TSTEncoderLayer(\n",
       "            (self_attn): _MultiheadAttention(\n",
       "              (W_Q): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (W_K): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (W_V): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (sdp_attn): _ScaledDotProductAttention(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "                (1): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
       "            (norm_attn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.3, inplace=False)\n",
       "              (3): Linear(in_features=128, out_features=16, bias=True)\n",
       "            )\n",
       "            (dropout_ffn): Dropout(p=0.3, inplace=False)\n",
       "            (norm_ffn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): Flatten_Head(\n",
       "      (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "      (linear): Linear(in_features=656, out_features=336, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exp = Exp_Main\n",
    "setting=f'PatchTST_train_on_{args.data}_{args.pred_len}'\n",
    "# set experiments\n",
    "exp = Exp(args)\n",
    "exp.train(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff270bf",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6c8bc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 2545\n",
      "mse:0.539555013179779, mae:0.5184375643730164, rse:0.5870471000671387\n"
     ]
    }
   ],
   "source": [
    "exp.test(setting)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1b8802",
   "metadata": {},
   "source": [
    "---\n",
    "## Trail 4: PatchTST, Dataset:ETTh2,  Metric: 720\n",
    "\n",
    "### Set hyperparameters\n",
    "Set some parameters (Args) for the our experiment like dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "639d69c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ETTh2,  Prediction Length : 720\n"
     ]
    }
   ],
   "source": [
    "args.pred_len = 720 # prediction sequence length\n",
    "print(f\"Dataset: {args.data},  Prediction Length : {args.pred_len}\") \n",
    "# print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dab366",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1837dd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "train 7585\n",
      "val 2161\n",
      "test 2161\n",
      "\titers: 100, epoch: 1 | loss: 0.7683773\n",
      "\tspeed: 0.0726s/iter; left time: 1714.1322s\n",
      "\titers: 200, epoch: 1 | loss: 0.7943283\n",
      "\tspeed: 0.0760s/iter; left time: 1785.6630s\n",
      "Epoch: 1 cost time: 17.07037663459778\n",
      "Epoch: 1, Steps: 237 | Train Loss: 0.8332328 Vali Loss: 0.6838762 Test Loss: 0.7464288\n",
      "Validation loss decreased (inf --> 0.683876).  Saving model ...\n",
      "Updating learning rate to 0.005\n",
      "\titers: 100, epoch: 2 | loss: 0.8648713\n",
      "\tspeed: 0.1650s/iter; left time: 3855.5516s\n",
      "\titers: 200, epoch: 2 | loss: 0.6552268\n",
      "\tspeed: 0.0740s/iter; left time: 1722.4079s\n",
      "Epoch: 2 cost time: 17.992148399353027\n",
      "Epoch: 2, Steps: 237 | Train Loss: 0.7202576 Vali Loss: 0.6711750 Test Loss: 0.7515456\n",
      "Validation loss decreased (0.683876 --> 0.671175).  Saving model ...\n",
      "Updating learning rate to 0.0025\n",
      "\titers: 100, epoch: 3 | loss: 0.6566624\n",
      "\tspeed: 0.1550s/iter; left time: 3584.3560s\n",
      "\titers: 200, epoch: 3 | loss: 0.5715491\n",
      "\tspeed: 0.0791s/iter; left time: 1821.2650s\n",
      "Epoch: 3 cost time: 17.20760202407837\n",
      "Epoch: 3, Steps: 237 | Train Loss: 0.6358012 Vali Loss: 0.8964043 Test Loss: 0.5429614\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.00125\n",
      "\titers: 100, epoch: 4 | loss: 0.3749033\n",
      "\tspeed: 0.1559s/iter; left time: 3568.1289s\n",
      "\titers: 200, epoch: 4 | loss: 0.3118913\n",
      "\tspeed: 0.0751s/iter; left time: 1712.3613s\n",
      "Epoch: 4 cost time: 17.306087017059326\n",
      "Epoch: 4, Steps: 237 | Train Loss: 0.6156827 Vali Loss: 0.7620929 Test Loss: 0.7660186\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.000625\n",
      "\titers: 100, epoch: 5 | loss: 0.4299654\n",
      "\tspeed: 0.1541s/iter; left time: 3490.4698s\n",
      "\titers: 200, epoch: 5 | loss: 0.6700587\n",
      "\tspeed: 0.0730s/iter; left time: 1646.0539s\n",
      "Epoch: 5 cost time: 17.107882976531982\n",
      "Epoch: 5, Steps: 237 | Train Loss: 0.6034199 Vali Loss: 0.7887890 Test Loss: 0.6156321\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): PatchTST_backbone(\n",
       "    (backbone): TSTiEncoder(\n",
       "      (W_P): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (encoder): TSTEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-2): 3 x TSTEncoderLayer(\n",
       "            (self_attn): _MultiheadAttention(\n",
       "              (W_Q): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (W_K): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (W_V): Linear(in_features=16, out_features=16, bias=True)\n",
       "              (sdp_attn): _ScaledDotProductAttention(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "                (1): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
       "            (norm_attn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.3, inplace=False)\n",
       "              (3): Linear(in_features=128, out_features=16, bias=True)\n",
       "            )\n",
       "            (dropout_ffn): Dropout(p=0.3, inplace=False)\n",
       "            (norm_ffn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): Flatten_Head(\n",
       "      (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "      (linear): Linear(in_features=656, out_features=720, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exp = Exp_Main\n",
    "setting=f'PatchTST_train_on_{args.data}_{args.pred_len}'\n",
    "# set experiments\n",
    "exp = Exp(args)\n",
    "exp.train(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948444aa",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab46427a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 2161\n",
      "mse:0.7515456080436707, mae:0.6049982309341431, rse:0.6930935382843018\n"
     ]
    }
   ],
   "source": [
    "exp.test(setting)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8512f50",
   "metadata": {},
   "source": [
    "---\n",
    "# Working on ETTm1 Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0da3de",
   "metadata": {},
   "source": [
    "## Trail 1: PatchTST, Dataset:ETTm1,  Metric: 96\n",
    "### Set hyperparameters\n",
    "Set some parameters (Args) for the our experiment like dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5df778aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ETTm1,  Prediction Length : 96\n"
     ]
    }
   ],
   "source": [
    "args.data_path = 'ETTm1.csv' # data file\n",
    "args.data = 'ETTm1'  # data\n",
    "args.pred_len = 96 # prediction sequence length\n",
    "args.n_heads = 16 \n",
    "args.d_model = 128 \n",
    "args.d_ff = 256 \n",
    "args.dropout = 0.2\n",
    "args.fc_dropout = 0.2\n",
    "args.patience = 20\n",
    "args.lradj = 'TST'\n",
    "args.pct_start = 0.4\n",
    "\n",
    "print(f\"Dataset: {args.data},  Prediction Length : {args.pred_len}\") \n",
    "# print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444bc3fb",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f07f695f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "train 34129\n",
      "val 11425\n",
      "test 11425\n",
      "\titers: 100, epoch: 1 | loss: 0.3275522\n",
      "\tspeed: 0.0736s/iter; left time: 7834.3638s\n",
      "\titers: 200, epoch: 1 | loss: 0.2828250\n",
      "\tspeed: 0.0780s/iter; left time: 8304.0682s\n",
      "\titers: 300, epoch: 1 | loss: 0.2911699\n",
      "\tspeed: 0.0772s/iter; left time: 8203.4025s\n",
      "\titers: 400, epoch: 1 | loss: 0.3137389\n",
      "\tspeed: 0.0748s/iter; left time: 7947.4658s\n",
      "\titers: 500, epoch: 1 | loss: 0.2675519\n",
      "\tspeed: 0.0760s/iter; left time: 8060.7817s\n",
      "\titers: 600, epoch: 1 | loss: 0.2635594\n",
      "\tspeed: 0.0802s/iter; left time: 8500.1411s\n",
      "\titers: 700, epoch: 1 | loss: 0.2640387\n",
      "\tspeed: 0.0719s/iter; left time: 7613.3111s\n",
      "\titers: 800, epoch: 1 | loss: 0.3039788\n",
      "\tspeed: 0.0731s/iter; left time: 7735.0784s\n",
      "\titers: 900, epoch: 1 | loss: 0.3141021\n",
      "\tspeed: 0.0739s/iter; left time: 7814.4045s\n",
      "\titers: 1000, epoch: 1 | loss: 0.3125711\n",
      "\tspeed: 0.0781s/iter; left time: 8248.5720s\n",
      "Epoch: 1 cost time: 80.67248821258545\n",
      "Epoch: 1, Steps: 1066 | Train Loss: 0.3115152 Vali Loss: 0.4127135 Test Loss: 0.3190654\n",
      "Validation loss decreased (inf --> 0.412714).  Saving model ...\n",
      "Updating learning rate to 0.0002131482726326836\n",
      "\titers: 100, epoch: 2 | loss: 0.2802203\n",
      "\tspeed: 0.5908s/iter; left time: 62290.2848s\n",
      "\titers: 200, epoch: 2 | loss: 0.2765557\n",
      "\tspeed: 0.0661s/iter; left time: 6963.8506s\n",
      "\titers: 300, epoch: 2 | loss: 0.3293008\n",
      "\tspeed: 0.0778s/iter; left time: 8190.0499s\n",
      "\titers: 400, epoch: 2 | loss: 0.2475795\n",
      "\tspeed: 0.0671s/iter; left time: 7053.3308s\n",
      "\titers: 500, epoch: 2 | loss: 0.2968549\n",
      "\tspeed: 0.0759s/iter; left time: 7973.5761s\n",
      "\titers: 600, epoch: 2 | loss: 0.2742549\n",
      "\tspeed: 0.0732s/iter; left time: 7680.5592s\n",
      "\titers: 700, epoch: 2 | loss: 0.2648742\n",
      "\tspeed: 0.0729s/iter; left time: 7639.9328s\n",
      "\titers: 800, epoch: 2 | loss: 0.2417924\n",
      "\tspeed: 0.0761s/iter; left time: 7970.8695s\n",
      "\titers: 900, epoch: 2 | loss: 0.3054906\n",
      "\tspeed: 0.0730s/iter; left time: 7634.8828s\n",
      "\titers: 1000, epoch: 2 | loss: 0.2905052\n",
      "\tspeed: 0.0760s/iter; left time: 7947.2761s\n",
      "Epoch: 2 cost time: 78.08757209777832\n",
      "Epoch: 2, Steps: 1066 | Train Loss: 0.2749499 Vali Loss: 0.4003966 Test Loss: 0.3276266\n",
      "Validation loss decreased (0.412714 --> 0.400397).  Saving model ...\n",
      "Updating learning rate to 0.0002524490263030492\n",
      "\titers: 100, epoch: 3 | loss: 0.3793051\n",
      "\tspeed: 0.5749s/iter; left time: 60006.0176s\n",
      "\titers: 200, epoch: 3 | loss: 0.2609175\n",
      "\tspeed: 0.0739s/iter; left time: 7705.7499s\n",
      "\titers: 300, epoch: 3 | loss: 0.2247029\n",
      "\tspeed: 0.0721s/iter; left time: 7505.6501s\n",
      "\titers: 400, epoch: 3 | loss: 0.3200445\n",
      "\tspeed: 0.0740s/iter; left time: 7702.1760s\n",
      "\titers: 500, epoch: 3 | loss: 0.2856213\n",
      "\tspeed: 0.0779s/iter; left time: 8102.2987s\n",
      "\titers: 600, epoch: 3 | loss: 0.2567218\n",
      "\tspeed: 0.0741s/iter; left time: 7699.2212s\n",
      "\titers: 700, epoch: 3 | loss: 0.2587171\n",
      "\tspeed: 0.0730s/iter; left time: 7578.2481s\n",
      "\titers: 800, epoch: 3 | loss: 0.2590063\n",
      "\tspeed: 0.0779s/iter; left time: 8076.5133s\n",
      "\titers: 900, epoch: 3 | loss: 0.2369958\n",
      "\tspeed: 0.0731s/iter; left time: 7575.1015s\n",
      "\titers: 1000, epoch: 3 | loss: 0.2593962\n",
      "\tspeed: 0.0740s/iter; left time: 7660.9659s\n",
      "Epoch: 3 cost time: 79.28050303459167\n",
      "Epoch: 3, Steps: 1066 | Train Loss: 0.2624148 Vali Loss: 0.4083193 Test Loss: 0.3334459\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Updating learning rate to 0.0003174716468244904\n",
      "\titers: 100, epoch: 4 | loss: 0.2360929\n",
      "\tspeed: 0.5960s/iter; left time: 61565.7989s\n",
      "\titers: 200, epoch: 4 | loss: 0.2062676\n",
      "\tspeed: 0.0769s/iter; left time: 7939.8667s\n",
      "\titers: 300, epoch: 4 | loss: 0.2819315\n",
      "\tspeed: 0.0760s/iter; left time: 7836.2020s\n",
      "\titers: 400, epoch: 4 | loss: 0.2761438\n",
      "\tspeed: 0.0721s/iter; left time: 7425.1595s\n",
      "\titers: 500, epoch: 4 | loss: 0.2741607\n",
      "\tspeed: 0.0748s/iter; left time: 7698.9697s\n",
      "\titers: 600, epoch: 4 | loss: 0.2858879\n",
      "\tspeed: 0.0710s/iter; left time: 7298.9161s\n",
      "\titers: 700, epoch: 4 | loss: 0.2465861\n",
      "\tspeed: 0.0720s/iter; left time: 7393.7230s\n",
      "\titers: 800, epoch: 4 | loss: 0.2145853\n",
      "\tspeed: 0.0769s/iter; left time: 7894.7438s\n",
      "\titers: 900, epoch: 4 | loss: 0.2453938\n",
      "\tspeed: 0.0701s/iter; left time: 7183.2960s\n",
      "\titers: 1000, epoch: 4 | loss: 0.2261206\n",
      "\tspeed: 0.0731s/iter; left time: 7483.5981s\n",
      "Epoch: 4 cost time: 78.39681911468506\n",
      "Epoch: 4, Steps: 1066 | Train Loss: 0.2505316 Vali Loss: 0.4143660 Test Loss: 0.3773171\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Updating learning rate to 0.0004075036882454173\n",
      "\titers: 100, epoch: 5 | loss: 0.2226915\n",
      "\tspeed: 0.5560s/iter; left time: 56843.1079s\n",
      "\titers: 200, epoch: 5 | loss: 0.2686791\n",
      "\tspeed: 0.0718s/iter; left time: 7338.0573s\n",
      "\titers: 300, epoch: 5 | loss: 0.2249096\n",
      "\tspeed: 0.0683s/iter; left time: 6967.0139s\n",
      "\titers: 400, epoch: 5 | loss: 0.2213624\n",
      "\tspeed: 0.0778s/iter; left time: 7929.0892s\n",
      "\titers: 500, epoch: 5 | loss: 0.2464781\n",
      "\tspeed: 0.0689s/iter; left time: 7020.7807s\n",
      "\titers: 600, epoch: 5 | loss: 0.2235555\n",
      "\tspeed: 0.0790s/iter; left time: 8037.1549s\n",
      "\titers: 700, epoch: 5 | loss: 0.2595114\n",
      "\tspeed: 0.0741s/iter; left time: 7526.3364s\n",
      "\titers: 800, epoch: 5 | loss: 0.2349168\n",
      "\tspeed: 0.0702s/iter; left time: 7126.6289s\n",
      "\titers: 900, epoch: 5 | loss: 0.1961721\n",
      "\tspeed: 0.0678s/iter; left time: 6873.2055s\n",
      "\titers: 1000, epoch: 5 | loss: 0.2100321\n",
      "\tspeed: 0.0781s/iter; left time: 7917.2037s\n",
      "Epoch: 5 cost time: 77.52077507972717\n",
      "Epoch: 5, Steps: 1066 | Train Loss: 0.2411986 Vali Loss: 0.4298915 Test Loss: 0.4066765\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Updating learning rate to 0.0005215586790439306\n",
      "\titers: 100, epoch: 6 | loss: 0.2467255\n",
      "\tspeed: 0.5679s/iter; left time: 57458.8852s\n",
      "\titers: 200, epoch: 6 | loss: 0.2051652\n",
      "\tspeed: 0.0730s/iter; left time: 7381.5433s\n",
      "\titers: 300, epoch: 6 | loss: 0.2252595\n",
      "\tspeed: 0.0710s/iter; left time: 7171.2009s\n",
      "\titers: 400, epoch: 6 | loss: 0.2122197\n",
      "\tspeed: 0.0769s/iter; left time: 7754.8965s\n",
      "\titers: 500, epoch: 6 | loss: 0.2349928\n",
      "\tspeed: 0.0731s/iter; left time: 7369.9257s\n",
      "\titers: 600, epoch: 6 | loss: 0.1939392\n",
      "\tspeed: 0.0809s/iter; left time: 8144.1806s\n",
      "\titers: 700, epoch: 6 | loss: 0.2185305\n",
      "\tspeed: 0.0732s/iter; left time: 7364.8903s\n",
      "\titers: 800, epoch: 6 | loss: 0.2860303\n",
      "\tspeed: 0.0747s/iter; left time: 7508.5742s\n",
      "\titers: 900, epoch: 6 | loss: 0.2211073\n",
      "\tspeed: 0.0741s/iter; left time: 7439.0132s\n",
      "\titers: 1000, epoch: 6 | loss: 0.1981808\n",
      "\tspeed: 0.0759s/iter; left time: 7614.6896s\n",
      "Epoch: 6 cost time: 80.00594115257263\n",
      "Epoch: 6, Steps: 1066 | Train Loss: 0.2284249 Vali Loss: 0.4432020 Test Loss: 0.4206519\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Updating learning rate to 0.0006583869307915822\n",
      "\titers: 100, epoch: 7 | loss: 0.2434887\n",
      "\tspeed: 0.5880s/iter; left time: 58864.7710s\n",
      "\titers: 200, epoch: 7 | loss: 0.2031910\n",
      "\tspeed: 0.0741s/iter; left time: 7412.2165s\n",
      "\titers: 300, epoch: 7 | loss: 0.1929023\n",
      "\tspeed: 0.0669s/iter; left time: 6688.5773s\n",
      "\titers: 400, epoch: 7 | loss: 0.2146845\n",
      "\tspeed: 0.0750s/iter; left time: 7487.2401s\n",
      "\titers: 500, epoch: 7 | loss: 0.1903619\n",
      "\tspeed: 0.0770s/iter; left time: 7681.8815s\n",
      "\titers: 600, epoch: 7 | loss: 0.1877664\n",
      "\tspeed: 0.0729s/iter; left time: 7257.2175s\n",
      "\titers: 700, epoch: 7 | loss: 0.1855624\n",
      "\tspeed: 0.0781s/iter; left time: 7770.1092s\n",
      "\titers: 800, epoch: 7 | loss: 0.2146473\n",
      "\tspeed: 0.0720s/iter; left time: 7156.0412s\n",
      "\titers: 900, epoch: 7 | loss: 0.2186357\n",
      "\tspeed: 0.0729s/iter; left time: 7242.7696s\n",
      "\titers: 1000, epoch: 7 | loss: 0.1910217\n",
      "\tspeed: 0.0810s/iter; left time: 8030.7377s\n",
      "Epoch: 7 cost time: 79.40818285942078\n",
      "Epoch: 7, Steps: 1066 | Train Loss: 0.2143862 Vali Loss: 0.4281484 Test Loss: 0.3716198\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Updating learning rate to 0.000816489230856845\n",
      "\titers: 100, epoch: 8 | loss: 0.1828156\n",
      "\tspeed: 0.5910s/iter; left time: 58534.4017s\n",
      "\titers: 200, epoch: 8 | loss: 0.1947179\n",
      "\tspeed: 0.0692s/iter; left time: 6843.9820s\n",
      "\titers: 300, epoch: 8 | loss: 0.2097810\n",
      "\tspeed: 0.0741s/iter; left time: 7321.4002s\n",
      "\titers: 400, epoch: 8 | loss: 0.2054694\n",
      "\tspeed: 0.0707s/iter; left time: 6985.5870s\n",
      "\titers: 500, epoch: 8 | loss: 0.1899536\n",
      "\tspeed: 0.0680s/iter; left time: 6707.2662s\n",
      "\titers: 600, epoch: 8 | loss: 0.2050643\n",
      "\tspeed: 0.0720s/iter; left time: 7094.9020s\n",
      "\titers: 700, epoch: 8 | loss: 0.2172979\n",
      "\tspeed: 0.0691s/iter; left time: 6797.7565s\n",
      "\titers: 800, epoch: 8 | loss: 0.1758556\n",
      "\tspeed: 0.0751s/iter; left time: 7382.0255s\n",
      "\titers: 900, epoch: 8 | loss: 0.1794731\n",
      "\tspeed: 0.0760s/iter; left time: 7470.5649s\n",
      "\titers: 1000, epoch: 8 | loss: 0.2121263\n",
      "\tspeed: 0.0758s/iter; left time: 7437.3378s\n",
      "Epoch: 8 cost time: 77.48488402366638\n",
      "Epoch: 8, Steps: 1066 | Train Loss: 0.1998996 Vali Loss: 0.4257225 Test Loss: 0.3646560\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Updating learning rate to 0.0009941332691187936\n",
      "\titers: 100, epoch: 9 | loss: 0.2133948\n",
      "\tspeed: 0.6012s/iter; left time: 58905.1432s\n",
      "\titers: 200, epoch: 9 | loss: 0.2046735\n",
      "\tspeed: 0.0689s/iter; left time: 6744.3799s\n",
      "\titers: 300, epoch: 9 | loss: 0.2049652\n",
      "\tspeed: 0.0729s/iter; left time: 7127.0750s\n",
      "\titers: 400, epoch: 9 | loss: 0.2051753\n",
      "\tspeed: 0.0709s/iter; left time: 6929.6479s\n",
      "\titers: 500, epoch: 9 | loss: 0.2138372\n",
      "\tspeed: 0.0682s/iter; left time: 6652.7417s\n",
      "\titers: 600, epoch: 9 | loss: 0.1840034\n",
      "\tspeed: 0.0780s/iter; left time: 7603.6741s\n",
      "\titers: 700, epoch: 9 | loss: 0.1878770\n",
      "\tspeed: 0.0740s/iter; left time: 7204.5416s\n",
      "\titers: 800, epoch: 9 | loss: 0.1560651\n",
      "\tspeed: 0.0758s/iter; left time: 7374.9207s\n",
      "\titers: 900, epoch: 9 | loss: 0.1920766\n",
      "\tspeed: 0.0731s/iter; left time: 7099.8558s\n",
      "\titers: 1000, epoch: 9 | loss: 0.1872410\n",
      "\tspeed: 0.0720s/iter; left time: 6989.0994s\n",
      "Epoch: 9 cost time: 77.6000726222992\n",
      "Epoch: 9, Steps: 1066 | Train Loss: 0.1905791 Vali Loss: 0.4099663 Test Loss: 0.3499488\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Updating learning rate to 0.0011893726187052283\n",
      "\titers: 100, epoch: 10 | loss: 0.1683926\n",
      "\tspeed: 0.5762s/iter; left time: 55834.2467s\n",
      "\titers: 200, epoch: 10 | loss: 0.1708343\n",
      "\tspeed: 0.0728s/iter; left time: 7050.2103s\n",
      "\titers: 300, epoch: 10 | loss: 0.2131712\n",
      "\tspeed: 0.0711s/iter; left time: 6872.5643s\n",
      "\titers: 400, epoch: 10 | loss: 0.1839053\n",
      "\tspeed: 0.0710s/iter; left time: 6863.5204s\n",
      "\titers: 500, epoch: 10 | loss: 0.1863604\n",
      "\tspeed: 0.0719s/iter; left time: 6939.6428s\n",
      "\titers: 600, epoch: 10 | loss: 0.1877076\n",
      "\tspeed: 0.0760s/iter; left time: 7325.5995s\n",
      "\titers: 700, epoch: 10 | loss: 0.1722746\n",
      "\tspeed: 0.0750s/iter; left time: 7223.3671s\n",
      "\titers: 800, epoch: 10 | loss: 0.1920228\n",
      "\tspeed: 0.0701s/iter; left time: 6742.1128s\n",
      "\titers: 900, epoch: 10 | loss: 0.2140192\n",
      "\tspeed: 0.0761s/iter; left time: 7312.3389s\n",
      "\titers: 1000, epoch: 10 | loss: 0.2170166\n",
      "\tspeed: 0.0759s/iter; left time: 7288.5928s\n",
      "Epoch: 10 cost time: 78.80707263946533\n",
      "Epoch: 10, Steps: 1066 | Train Loss: 0.1817290 Vali Loss: 0.4250835 Test Loss: 0.3642513\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Updating learning rate to 0.0014000680627853234\n",
      "\titers: 100, epoch: 11 | loss: 0.1917486\n",
      "\tspeed: 0.5509s/iter; left time: 52800.3613s\n",
      "\titers: 200, epoch: 11 | loss: 0.1647348\n",
      "\tspeed: 0.0730s/iter; left time: 6989.0076s\n",
      "\titers: 300, epoch: 11 | loss: 0.1645047\n",
      "\tspeed: 0.0662s/iter; left time: 6326.8907s\n",
      "\titers: 400, epoch: 11 | loss: 0.1618408\n",
      "\tspeed: 0.0719s/iter; left time: 6873.4423s\n",
      "\titers: 500, epoch: 11 | loss: 0.1578779\n",
      "\tspeed: 0.0749s/iter; left time: 7145.6706s\n",
      "\titers: 600, epoch: 11 | loss: 0.1372084\n",
      "\tspeed: 0.0760s/iter; left time: 7249.1410s\n",
      "\titers: 700, epoch: 11 | loss: 0.1517674\n",
      "\tspeed: 0.0700s/iter; left time: 6666.7817s\n",
      "\titers: 800, epoch: 11 | loss: 0.1814056\n",
      "\tspeed: 0.0722s/iter; left time: 6866.3028s\n",
      "\titers: 900, epoch: 11 | loss: 0.1779955\n",
      "\tspeed: 0.0758s/iter; left time: 7207.1865s\n",
      "\titers: 1000, epoch: 11 | loss: 0.1519140\n",
      "\tspeed: 0.0740s/iter; left time: 7025.7735s\n",
      "Epoch: 11 cost time: 77.90327191352844\n",
      "Epoch: 11, Steps: 1066 | Train Loss: 0.1762864 Vali Loss: 0.4424960 Test Loss: 0.3909656\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Updating learning rate to 0.0016239110337413882\n",
      "\titers: 100, epoch: 12 | loss: 0.2039034\n",
      "\tspeed: 0.5632s/iter; left time: 53375.4472s\n",
      "\titers: 200, epoch: 12 | loss: 0.1715868\n",
      "\tspeed: 0.0799s/iter; left time: 7562.3534s\n",
      "\titers: 300, epoch: 12 | loss: 0.1540151\n",
      "\tspeed: 0.0701s/iter; left time: 6628.3167s\n",
      "\titers: 400, epoch: 12 | loss: 0.1669804\n",
      "\tspeed: 0.0700s/iter; left time: 6611.1771s\n",
      "\titers: 500, epoch: 12 | loss: 0.1813938\n",
      "\tspeed: 0.0738s/iter; left time: 6966.5730s\n",
      "\titers: 600, epoch: 12 | loss: 0.1463523\n",
      "\tspeed: 0.0672s/iter; left time: 6337.1701s\n",
      "\titers: 700, epoch: 12 | loss: 0.1617128\n",
      "\tspeed: 0.0728s/iter; left time: 6858.9866s\n",
      "\titers: 800, epoch: 12 | loss: 0.1454540\n",
      "\tspeed: 0.0741s/iter; left time: 6971.3976s\n",
      "\titers: 900, epoch: 12 | loss: 0.1735695\n",
      "\tspeed: 0.0738s/iter; left time: 6939.4121s\n",
      "\titers: 1000, epoch: 12 | loss: 0.1869650\n",
      "\tspeed: 0.0750s/iter; left time: 7040.5722s\n",
      "Epoch: 12 cost time: 78.59418034553528\n",
      "Epoch: 12, Steps: 1066 | Train Loss: 0.1718044 Vali Loss: 0.4661722 Test Loss: 0.3993018\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Updating learning rate to 0.0018584489078992223\n",
      "\titers: 100, epoch: 13 | loss: 0.1848052\n",
      "\tspeed: 0.5823s/iter; left time: 54562.7479s\n",
      "\titers: 200, epoch: 13 | loss: 0.1690487\n",
      "\tspeed: 0.0738s/iter; left time: 6907.3547s\n",
      "\titers: 300, epoch: 13 | loss: 0.1834281\n",
      "\tspeed: 0.0760s/iter; left time: 7107.6417s\n",
      "\titers: 400, epoch: 13 | loss: 0.1425406\n",
      "\tspeed: 0.0750s/iter; left time: 7006.5331s\n",
      "\titers: 500, epoch: 13 | loss: 0.1613511\n",
      "\tspeed: 0.0741s/iter; left time: 6918.6857s\n",
      "\titers: 600, epoch: 13 | loss: 0.1563735\n",
      "\tspeed: 0.0739s/iter; left time: 6890.9450s\n",
      "\titers: 700, epoch: 13 | loss: 0.1835715\n",
      "\tspeed: 0.0709s/iter; left time: 6602.4505s\n",
      "\titers: 800, epoch: 13 | loss: 0.2089414\n",
      "\tspeed: 0.0740s/iter; left time: 6884.7854s\n",
      "\titers: 900, epoch: 13 | loss: 0.1626328\n",
      "\tspeed: 0.0701s/iter; left time: 6516.7453s\n",
      "\titers: 1000, epoch: 13 | loss: 0.1876358\n",
      "\tspeed: 0.0758s/iter; left time: 7032.7802s\n",
      "Epoch: 13 cost time: 78.90834975242615\n",
      "Epoch: 13, Steps: 1066 | Train Loss: 0.1675838 Vali Loss: 0.4430604 Test Loss: 0.3682492\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Updating learning rate to 0.0021011118786653927\n",
      "\titers: 100, epoch: 14 | loss: 0.1370894\n",
      "\tspeed: 0.5632s/iter; left time: 52176.1406s\n",
      "\titers: 200, epoch: 14 | loss: 0.1474842\n",
      "\tspeed: 0.0720s/iter; left time: 6665.6623s\n",
      "\titers: 300, epoch: 14 | loss: 0.1666880\n",
      "\tspeed: 0.0718s/iter; left time: 6635.2687s\n",
      "\titers: 400, epoch: 14 | loss: 0.1776379\n",
      "\tspeed: 0.0811s/iter; left time: 7485.4079s\n",
      "\titers: 500, epoch: 14 | loss: 0.1786469\n",
      "\tspeed: 0.0722s/iter; left time: 6655.6444s\n",
      "\titers: 600, epoch: 14 | loss: 0.1570782\n",
      "\tspeed: 0.0730s/iter; left time: 6727.0209s\n",
      "\titers: 700, epoch: 14 | loss: 0.1516681\n",
      "\tspeed: 0.0740s/iter; left time: 6811.6221s\n",
      "\titers: 800, epoch: 14 | loss: 0.1562009\n",
      "\tspeed: 0.0709s/iter; left time: 6521.2773s\n",
      "\titers: 900, epoch: 14 | loss: 0.1330799\n",
      "\tspeed: 0.0720s/iter; left time: 6608.3425s\n",
      "\titers: 1000, epoch: 14 | loss: 0.1753940\n",
      "\tspeed: 0.0721s/iter; left time: 6616.0324s\n",
      "Epoch: 14 cost time: 77.79263091087341\n",
      "Epoch: 14, Steps: 1066 | Train Loss: 0.1637109 Vali Loss: 0.4524204 Test Loss: 0.3626300\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Updating learning rate to 0.0023492411136253276\n",
      "\titers: 100, epoch: 15 | loss: 0.1569729\n",
      "\tspeed: 0.5899s/iter; left time: 54025.6510s\n",
      "\titers: 200, epoch: 15 | loss: 0.1563287\n",
      "\tspeed: 0.0711s/iter; left time: 6499.5107s\n",
      "\titers: 300, epoch: 15 | loss: 0.1772921\n",
      "\tspeed: 0.0748s/iter; left time: 6838.2736s\n",
      "\titers: 400, epoch: 15 | loss: 0.1529376\n",
      "\tspeed: 0.0712s/iter; left time: 6495.5015s\n",
      "\titers: 500, epoch: 15 | loss: 0.1523217\n",
      "\tspeed: 0.0749s/iter; left time: 6824.6634s\n",
      "\titers: 600, epoch: 15 | loss: 0.1503661\n",
      "\tspeed: 0.0700s/iter; left time: 6378.5405s\n",
      "\titers: 700, epoch: 15 | loss: 0.1738385\n",
      "\tspeed: 0.0720s/iter; left time: 6554.6846s\n",
      "\titers: 800, epoch: 15 | loss: 0.1473478\n",
      "\tspeed: 0.0730s/iter; left time: 6634.4749s\n",
      "\titers: 900, epoch: 15 | loss: 0.1419321\n",
      "\tspeed: 0.0700s/iter; left time: 6350.2177s\n",
      "\titers: 1000, epoch: 15 | loss: 0.1601005\n",
      "\tspeed: 0.0730s/iter; left time: 6615.1899s\n",
      "Epoch: 15 cost time: 77.50085377693176\n",
      "Epoch: 15, Steps: 1066 | Train Loss: 0.1638959 Vali Loss: 0.4622141 Test Loss: 0.3794971\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Updating learning rate to 0.002600117887087863\n",
      "\titers: 100, epoch: 16 | loss: 0.1564515\n",
      "\tspeed: 0.5900s/iter; left time: 53401.2796s\n",
      "\titers: 200, epoch: 16 | loss: 0.1831867\n",
      "\tspeed: 0.0742s/iter; left time: 6704.3188s\n",
      "\titers: 300, epoch: 16 | loss: 0.1344848\n",
      "\tspeed: 0.0719s/iter; left time: 6496.8424s\n",
      "\titers: 400, epoch: 16 | loss: 0.1626166\n",
      "\tspeed: 0.0720s/iter; left time: 6498.0098s\n",
      "\titers: 500, epoch: 16 | loss: 0.1439917\n",
      "\tspeed: 0.0729s/iter; left time: 6568.5728s\n",
      "\titers: 600, epoch: 16 | loss: 0.1533817\n",
      "\tspeed: 0.0761s/iter; left time: 6847.4154s\n",
      "\titers: 700, epoch: 16 | loss: 0.1598750\n",
      "\tspeed: 0.0721s/iter; left time: 6478.4759s\n",
      "\titers: 800, epoch: 16 | loss: 0.1689474\n",
      "\tspeed: 0.0720s/iter; left time: 6462.7033s\n",
      "\titers: 900, epoch: 16 | loss: 0.1763995\n",
      "\tspeed: 0.0781s/iter; left time: 7002.6381s\n",
      "\titers: 1000, epoch: 16 | loss: 0.1745068\n",
      "\tspeed: 0.0720s/iter; left time: 6452.1472s\n",
      "Epoch: 16 cost time: 79.11301279067993\n",
      "Epoch: 16, Steps: 1066 | Train Loss: 0.1636687 Vali Loss: 0.4706776 Test Loss: 0.3836862\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Updating learning rate to 0.0028509933688740906\n",
      "\titers: 100, epoch: 17 | loss: 0.1412736\n",
      "\tspeed: 0.6068s/iter; left time: 54278.4447s\n",
      "\titers: 200, epoch: 17 | loss: 0.1702852\n",
      "\tspeed: 0.0741s/iter; left time: 6619.4525s\n",
      "\titers: 300, epoch: 17 | loss: 0.1578383\n",
      "\tspeed: 0.0748s/iter; left time: 6679.8422s\n",
      "\titers: 400, epoch: 17 | loss: 0.1603831\n",
      "\tspeed: 0.0731s/iter; left time: 6513.6676s\n",
      "\titers: 500, epoch: 17 | loss: 0.1679649\n",
      "\tspeed: 0.0729s/iter; left time: 6494.4788s\n",
      "\titers: 600, epoch: 17 | loss: 0.1354805\n",
      "\tspeed: 0.0791s/iter; left time: 7038.8630s\n",
      "\titers: 700, epoch: 17 | loss: 0.1602233\n",
      "\tspeed: 0.0739s/iter; left time: 6567.4152s\n",
      "\titers: 800, epoch: 17 | loss: 0.1469910\n",
      "\tspeed: 0.0769s/iter; left time: 6827.9483s\n",
      "\titers: 900, epoch: 17 | loss: 0.1532186\n",
      "\tspeed: 0.0671s/iter; left time: 5944.8550s\n",
      "\titers: 1000, epoch: 17 | loss: 0.1723476\n",
      "\tspeed: 0.0811s/iter; left time: 7177.8558s\n",
      "Epoch: 17 cost time: 79.80785369873047\n",
      "Epoch: 17, Steps: 1066 | Train Loss: 0.1624338 Vali Loss: 0.4568088 Test Loss: 0.3726622\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Updating learning rate to 0.0030991187429578564\n",
      "\titers: 100, epoch: 18 | loss: 0.1535118\n",
      "\tspeed: 0.5679s/iter; left time: 50193.0096s\n",
      "\titers: 200, epoch: 18 | loss: 0.1555065\n",
      "\tspeed: 0.0772s/iter; left time: 6812.4822s\n",
      "\titers: 300, epoch: 18 | loss: 0.1533429\n",
      "\tspeed: 0.0758s/iter; left time: 6686.8883s\n",
      "\titers: 400, epoch: 18 | loss: 0.1875198\n",
      "\tspeed: 0.0713s/iter; left time: 6276.3035s\n",
      "\titers: 500, epoch: 18 | loss: 0.1563188\n",
      "\tspeed: 0.0798s/iter; left time: 7019.1898s\n",
      "\titers: 600, epoch: 18 | loss: 0.1862919\n",
      "\tspeed: 0.0722s/iter; left time: 6346.0225s\n",
      "\titers: 700, epoch: 18 | loss: 0.1638351\n",
      "\tspeed: 0.0748s/iter; left time: 6562.0015s\n",
      "\titers: 800, epoch: 18 | loss: 0.1610637\n",
      "\tspeed: 0.0741s/iter; left time: 6499.1604s\n",
      "\titers: 900, epoch: 18 | loss: 0.1702806\n",
      "\tspeed: 0.0720s/iter; left time: 6309.8126s\n",
      "\titers: 1000, epoch: 18 | loss: 0.1734871\n",
      "\tspeed: 0.0759s/iter; left time: 6642.7837s\n",
      "Epoch: 18 cost time: 79.8089611530304\n",
      "Epoch: 18, Steps: 1066 | Train Loss: 0.1614743 Vali Loss: 0.4594934 Test Loss: 0.3692198\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Updating learning rate to 0.003341775325951213\n",
      "\titers: 100, epoch: 19 | loss: 0.1410823\n",
      "\tspeed: 0.5639s/iter; left time: 49233.6237s\n",
      "\titers: 200, epoch: 19 | loss: 0.1705721\n",
      "\tspeed: 0.0720s/iter; left time: 6279.6764s\n",
      "\titers: 300, epoch: 19 | loss: 0.1593917\n",
      "\tspeed: 0.0719s/iter; left time: 6267.4586s\n",
      "\titers: 400, epoch: 19 | loss: 0.1714730\n",
      "\tspeed: 0.0742s/iter; left time: 6454.6662s\n",
      "\titers: 500, epoch: 19 | loss: 0.1912136\n",
      "\tspeed: 0.0711s/iter; left time: 6176.3455s\n",
      "\titers: 600, epoch: 19 | loss: 0.1748223\n",
      "\tspeed: 0.0728s/iter; left time: 6315.7547s\n",
      "\titers: 700, epoch: 19 | loss: 0.1932213\n",
      "\tspeed: 0.0732s/iter; left time: 6349.7870s\n",
      "\titers: 800, epoch: 19 | loss: 0.1471098\n",
      "\tspeed: 0.0798s/iter; left time: 6914.0373s\n",
      "\titers: 900, epoch: 19 | loss: 0.1523000\n",
      "\tspeed: 0.0750s/iter; left time: 6488.8925s\n",
      "\titers: 1000, epoch: 19 | loss: 0.1701801\n",
      "\tspeed: 0.0750s/iter; left time: 6481.4184s\n",
      "Epoch: 19 cost time: 78.80094790458679\n",
      "Epoch: 19, Steps: 1066 | Train Loss: 0.1666230 Vali Loss: 0.4202333 Test Loss: 0.3404121\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Updating learning rate to 0.0035763043554297314\n",
      "\titers: 100, epoch: 20 | loss: 0.1873376\n",
      "\tspeed: 0.5610s/iter; left time: 48385.6506s\n",
      "\titers: 200, epoch: 20 | loss: 0.2012398\n",
      "\tspeed: 0.0770s/iter; left time: 6630.1380s\n",
      "\titers: 300, epoch: 20 | loss: 0.1507544\n",
      "\tspeed: 0.0742s/iter; left time: 6384.9960s\n",
      "\titers: 400, epoch: 20 | loss: 0.1983686\n",
      "\tspeed: 0.0770s/iter; left time: 6615.8527s\n",
      "\titers: 500, epoch: 20 | loss: 0.1563105\n",
      "\tspeed: 0.0688s/iter; left time: 5909.7839s\n",
      "\titers: 600, epoch: 20 | loss: 0.1710557\n",
      "\tspeed: 0.0692s/iter; left time: 5930.9914s\n",
      "\titers: 700, epoch: 20 | loss: 0.1389618\n",
      "\tspeed: 0.0738s/iter; left time: 6323.0531s\n",
      "\titers: 800, epoch: 20 | loss: 0.1772031\n",
      "\tspeed: 0.0740s/iter; left time: 6330.8230s\n",
      "\titers: 900, epoch: 20 | loss: 0.1732502\n",
      "\tspeed: 0.0771s/iter; left time: 6587.7356s\n",
      "\titers: 1000, epoch: 20 | loss: 0.1502925\n",
      "\tspeed: 0.0719s/iter; left time: 6137.0716s\n",
      "Epoch: 20 cost time: 78.37678718566895\n",
      "Epoch: 20, Steps: 1066 | Train Loss: 0.1642155 Vali Loss: 0.4944086 Test Loss: 0.4185844\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Updating learning rate to 0.0038001361217101953\n",
      "\titers: 100, epoch: 21 | loss: 0.1611671\n",
      "\tspeed: 0.5950s/iter; left time: 50684.0013s\n",
      "\titers: 200, epoch: 21 | loss: 0.1544946\n",
      "\tspeed: 0.0780s/iter; left time: 6634.3091s\n",
      "\titers: 300, epoch: 21 | loss: 0.1622364\n",
      "\tspeed: 0.0741s/iter; left time: 6297.1615s\n",
      "\titers: 400, epoch: 21 | loss: 0.1507679\n",
      "\tspeed: 0.0739s/iter; left time: 6271.6974s\n",
      "\titers: 500, epoch: 21 | loss: 0.1654837\n",
      "\tspeed: 0.0720s/iter; left time: 6105.2963s\n",
      "\titers: 600, epoch: 21 | loss: 0.1899615\n",
      "\tspeed: 0.0761s/iter; left time: 6440.0068s\n",
      "\titers: 700, epoch: 21 | loss: 0.1872594\n",
      "\tspeed: 0.0732s/iter; left time: 6189.1589s\n",
      "\titers: 800, epoch: 21 | loss: 0.3561060\n",
      "\tspeed: 0.0760s/iter; left time: 6418.7113s\n",
      "\titers: 900, epoch: 21 | loss: 0.3947048\n",
      "\tspeed: 0.0827s/iter; left time: 6981.6754s\n",
      "\titers: 1000, epoch: 21 | loss: 0.2874443\n",
      "\tspeed: 0.0731s/iter; left time: 6162.5062s\n",
      "Epoch: 21 cost time: 80.90357232093811\n",
      "Epoch: 21, Steps: 1066 | Train Loss: 0.2048231 Vali Loss: 0.4427940 Test Loss: 0.3449990\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Updating learning rate to 0.004010818123886844\n",
      "\titers: 100, epoch: 22 | loss: 0.2900927\n",
      "\tspeed: 0.5461s/iter; left time: 45935.9691s\n",
      "\titers: 200, epoch: 22 | loss: 0.3136406\n",
      "\tspeed: 0.0719s/iter; left time: 6042.8064s\n",
      "\titers: 300, epoch: 22 | loss: 0.3587745\n",
      "\tspeed: 0.0712s/iter; left time: 5971.3647s\n",
      "\titers: 400, epoch: 22 | loss: 0.2611685\n",
      "\tspeed: 0.0739s/iter; left time: 6192.4309s\n",
      "\titers: 500, epoch: 22 | loss: 0.2998900\n",
      "\tspeed: 0.0791s/iter; left time: 6618.9214s\n",
      "\titers: 600, epoch: 22 | loss: 0.3400154\n",
      "\tspeed: 0.0768s/iter; left time: 6421.4937s\n",
      "\titers: 700, epoch: 22 | loss: 0.3723346\n",
      "\tspeed: 0.0761s/iter; left time: 6354.8238s\n",
      "\titers: 800, epoch: 22 | loss: 0.2716795\n",
      "\tspeed: 0.0748s/iter; left time: 6243.2064s\n",
      "\titers: 900, epoch: 22 | loss: 0.2841671\n",
      "\tspeed: 0.0750s/iter; left time: 6248.9150s\n",
      "\titers: 1000, epoch: 22 | loss: 0.3692285\n",
      "\tspeed: 0.0723s/iter; left time: 6013.1298s\n",
      "Epoch: 22 cost time: 80.00088620185852\n",
      "Epoch: 22, Steps: 1066 | Train Loss: 0.3007121 Vali Loss: 0.4510852 Test Loss: 0.3269305\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): PatchTST_backbone(\n",
       "    (backbone): TSTiEncoder(\n",
       "      (W_P): Linear(in_features=16, out_features=128, bias=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (encoder): TSTEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-2): 3 x TSTEncoderLayer(\n",
       "            (self_attn): _MultiheadAttention(\n",
       "              (W_Q): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (W_K): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (W_V): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (sdp_attn): _ScaledDotProductAttention(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (dropout_attn): Dropout(p=0.2, inplace=False)\n",
       "            (norm_attn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.2, inplace=False)\n",
       "              (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "            )\n",
       "            (dropout_ffn): Dropout(p=0.2, inplace=False)\n",
       "            (norm_ffn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): Flatten_Head(\n",
       "      (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "      (linear): Linear(in_features=5248, out_features=96, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exp = Exp_Main\n",
    "setting=f'PatchTST_train_on_{args.data}_{args.pred_len}'\n",
    "# set experiments\n",
    "exp = Exp(args)\n",
    "exp.train(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17a3cc3",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "882369ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 11425\n",
      "mse:0.3276263177394867, mae:0.37977054715156555, rse:0.5446505546569824\n"
     ]
    }
   ],
   "source": [
    "exp.test(setting)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcf89fd",
   "metadata": {},
   "source": [
    "---\n",
    "## Trail 2: PatchTST, Dataset:ETTm1 , Metric: 192\n",
    "### Set hyperparameters\n",
    "Set some parameters (Args) for the our experiment like dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f98b261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ETTm1,  Prediction Length : 192\n"
     ]
    }
   ],
   "source": [
    "args.pred_len = 192 # prediction sequence length\n",
    "\n",
    "print(f\"Dataset: {args.data},  Prediction Length : {args.pred_len}\") \n",
    "# print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa50c03",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b3595636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "train 34033\n",
      "val 11329\n",
      "test 11329\n",
      "\titers: 100, epoch: 1 | loss: 0.3568006\n",
      "\tspeed: 0.0786s/iter; left time: 8344.0066s\n",
      "\titers: 200, epoch: 1 | loss: 0.3742522\n",
      "\tspeed: 0.0761s/iter; left time: 8072.1618s\n",
      "\titers: 300, epoch: 1 | loss: 0.3438635\n",
      "\tspeed: 0.0757s/iter; left time: 8029.4292s\n",
      "\titers: 400, epoch: 1 | loss: 0.3249428\n",
      "\tspeed: 0.0731s/iter; left time: 7738.0330s\n",
      "\titers: 500, epoch: 1 | loss: 0.3478993\n",
      "\tspeed: 0.0720s/iter; left time: 7613.1840s\n",
      "\titers: 600, epoch: 1 | loss: 0.3752334\n",
      "\tspeed: 0.0811s/iter; left time: 8576.8257s\n",
      "\titers: 700, epoch: 1 | loss: 0.3527400\n",
      "\tspeed: 0.0789s/iter; left time: 8330.3545s\n",
      "\titers: 800, epoch: 1 | loss: 0.3734523\n",
      "\tspeed: 0.0811s/iter; left time: 8552.4106s\n",
      "\titers: 900, epoch: 1 | loss: 0.2887919\n",
      "\tspeed: 0.0719s/iter; left time: 7576.1824s\n",
      "\titers: 1000, epoch: 1 | loss: 0.3661746\n",
      "\tspeed: 0.0809s/iter; left time: 8523.2654s\n",
      "Epoch: 1 cost time: 81.9584219455719\n",
      "Epoch: 1, Steps: 1063 | Train Loss: 0.3471995 Vali Loss: 0.5104088 Test Loss: 0.3603534\n",
      "Validation loss decreased (inf --> 0.510409).  Saving model ...\n",
      "Updating learning rate to 0.0002131482749512777\n",
      "\titers: 100, epoch: 2 | loss: 0.2779264\n",
      "\tspeed: 0.5091s/iter; left time: 53520.9413s\n",
      "\titers: 200, epoch: 2 | loss: 0.3689848\n",
      "\tspeed: 0.0800s/iter; left time: 8406.0126s\n",
      "\titers: 300, epoch: 2 | loss: 0.2865221\n",
      "\tspeed: 0.0729s/iter; left time: 7651.5494s\n",
      "\titers: 400, epoch: 2 | loss: 0.2735525\n",
      "\tspeed: 0.0721s/iter; left time: 7561.3466s\n",
      "\titers: 500, epoch: 2 | loss: 0.3330553\n",
      "\tspeed: 0.0759s/iter; left time: 7946.7978s\n",
      "\titers: 600, epoch: 2 | loss: 0.2756630\n",
      "\tspeed: 0.0761s/iter; left time: 7960.4235s\n",
      "\titers: 700, epoch: 2 | loss: 0.3027954\n",
      "\tspeed: 0.0772s/iter; left time: 8067.9895s\n",
      "\titers: 800, epoch: 2 | loss: 0.2908739\n",
      "\tspeed: 0.0828s/iter; left time: 8649.1862s\n",
      "\titers: 900, epoch: 2 | loss: 0.3200671\n",
      "\tspeed: 0.0762s/iter; left time: 7949.3348s\n",
      "\titers: 1000, epoch: 2 | loss: 0.2836098\n",
      "\tspeed: 0.0800s/iter; left time: 8335.9524s\n",
      "Epoch: 2 cost time: 81.7912368774414\n",
      "Epoch: 2, Steps: 1063 | Train Loss: 0.3142048 Vali Loss: 0.5412923 Test Loss: 0.3732130\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Updating learning rate to 0.0002524490355266156\n",
      "\titers: 100, epoch: 3 | loss: 0.2660280\n",
      "\tspeed: 0.5128s/iter; left time: 53373.2668s\n",
      "\titers: 200, epoch: 3 | loss: 0.2714554\n",
      "\tspeed: 0.0692s/iter; left time: 7191.5058s\n",
      "\titers: 300, epoch: 3 | loss: 0.2695146\n",
      "\tspeed: 0.0878s/iter; left time: 9124.3366s\n",
      "\titers: 400, epoch: 3 | loss: 0.2644522\n",
      "\tspeed: 0.0770s/iter; left time: 7990.5095s\n",
      "\titers: 500, epoch: 3 | loss: 0.3015692\n",
      "\tspeed: 0.0700s/iter; left time: 7256.9492s\n",
      "\titers: 600, epoch: 3 | loss: 0.2780676\n",
      "\tspeed: 0.0740s/iter; left time: 7665.7280s\n",
      "\titers: 700, epoch: 3 | loss: 0.3859564\n",
      "\tspeed: 0.0791s/iter; left time: 8182.3278s\n",
      "\titers: 800, epoch: 3 | loss: 0.3723313\n",
      "\tspeed: 0.0749s/iter; left time: 7744.1537s\n",
      "\titers: 900, epoch: 3 | loss: 0.2815448\n",
      "\tspeed: 0.0752s/iter; left time: 7761.6509s\n",
      "\titers: 1000, epoch: 3 | loss: 0.3443213\n",
      "\tspeed: 0.0768s/iter; left time: 7922.2347s\n",
      "Epoch: 3 cost time: 81.21357750892639\n",
      "Epoch: 3, Steps: 1063 | Train Loss: 0.2993400 Vali Loss: 0.5409080 Test Loss: 0.3995766\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Updating learning rate to 0.0003174716673878166\n",
      "\titers: 100, epoch: 4 | loss: 0.2661950\n",
      "\tspeed: 0.5481s/iter; left time: 56457.8577s\n",
      "\titers: 200, epoch: 4 | loss: 0.2808304\n",
      "\tspeed: 0.0809s/iter; left time: 8330.0095s\n",
      "\titers: 300, epoch: 4 | loss: 0.2978196\n",
      "\tspeed: 0.0760s/iter; left time: 7818.3587s\n",
      "\titers: 400, epoch: 4 | loss: 0.3427040\n",
      "\tspeed: 0.0742s/iter; left time: 7616.6587s\n",
      "\titers: 500, epoch: 4 | loss: 0.2795230\n",
      "\tspeed: 0.0858s/iter; left time: 8808.6751s\n",
      "\titers: 600, epoch: 4 | loss: 0.2724379\n",
      "\tspeed: 0.0802s/iter; left time: 8217.2950s\n",
      "\titers: 700, epoch: 4 | loss: 0.2550501\n",
      "\tspeed: 0.0778s/iter; left time: 7971.4463s\n",
      "\titers: 800, epoch: 4 | loss: 0.2589453\n",
      "\tspeed: 0.0742s/iter; left time: 7591.0636s\n",
      "\titers: 900, epoch: 4 | loss: 0.2911274\n",
      "\tspeed: 0.0770s/iter; left time: 7869.0632s\n",
      "\titers: 1000, epoch: 4 | loss: 0.2653646\n",
      "\tspeed: 0.0750s/iter; left time: 7656.5760s\n",
      "Epoch: 4 cost time: 82.10117983818054\n",
      "Epoch: 4, Steps: 1063 | Train Loss: 0.2876126 Vali Loss: 0.5569084 Test Loss: 0.4196323\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Updating learning rate to 0.0004075037243334058\n",
      "\titers: 100, epoch: 5 | loss: 0.2420841\n",
      "\tspeed: 0.5029s/iter; left time: 51274.1622s\n",
      "\titers: 200, epoch: 5 | loss: 0.2474816\n",
      "\tspeed: 0.0850s/iter; left time: 8655.2336s\n",
      "\titers: 300, epoch: 5 | loss: 0.2769677\n",
      "\tspeed: 0.0791s/iter; left time: 8050.5652s\n",
      "\titers: 400, epoch: 5 | loss: 0.2333836\n",
      "\tspeed: 0.0810s/iter; left time: 8228.9628s\n",
      "\titers: 500, epoch: 5 | loss: 0.2805062\n",
      "\tspeed: 0.0778s/iter; left time: 7898.4867s\n",
      "\titers: 600, epoch: 5 | loss: 0.2878655\n",
      "\tspeed: 0.0802s/iter; left time: 8137.8461s\n",
      "\titers: 700, epoch: 5 | loss: 0.2490740\n",
      "\tspeed: 0.0738s/iter; left time: 7484.5101s\n",
      "\titers: 800, epoch: 5 | loss: 0.2375998\n",
      "\tspeed: 0.0770s/iter; left time: 7797.0206s\n",
      "\titers: 900, epoch: 5 | loss: 0.2564925\n",
      "\tspeed: 0.0712s/iter; left time: 7197.1425s\n",
      "\titers: 1000, epoch: 5 | loss: 0.2598336\n",
      "\tspeed: 0.0719s/iter; left time: 7266.6704s\n",
      "Epoch: 5 cost time: 82.40382504463196\n",
      "Epoch: 5, Steps: 1063 | Train Loss: 0.2704648 Vali Loss: 0.5759367 Test Loss: 0.4157702\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Updating learning rate to 0.0005215587344974256\n",
      "\titers: 100, epoch: 6 | loss: 0.2436956\n",
      "\tspeed: 0.5141s/iter; left time: 51864.0952s\n",
      "\titers: 200, epoch: 6 | loss: 0.2340706\n",
      "\tspeed: 0.0710s/iter; left time: 7154.9755s\n",
      "\titers: 300, epoch: 6 | loss: 0.2847250\n",
      "\tspeed: 0.0719s/iter; left time: 7234.4832s\n",
      "\titers: 400, epoch: 6 | loss: 0.2453985\n",
      "\tspeed: 0.0740s/iter; left time: 7444.5826s\n",
      "\titers: 500, epoch: 6 | loss: 0.2217475\n",
      "\tspeed: 0.0730s/iter; left time: 7333.1025s\n",
      "\titers: 600, epoch: 6 | loss: 0.1927641\n",
      "\tspeed: 0.0752s/iter; left time: 7545.6401s\n",
      "\titers: 700, epoch: 6 | loss: 0.2452508\n",
      "\tspeed: 0.0830s/iter; left time: 8325.8339s\n",
      "\titers: 800, epoch: 6 | loss: 0.2412297\n",
      "\tspeed: 0.0758s/iter; left time: 7595.3124s\n",
      "\titers: 900, epoch: 6 | loss: 0.2395217\n",
      "\tspeed: 0.0680s/iter; left time: 6810.6579s\n",
      "\titers: 1000, epoch: 6 | loss: 0.2625208\n",
      "\tspeed: 0.0749s/iter; left time: 7488.1960s\n",
      "Epoch: 6 cost time: 78.40208745002747\n",
      "Epoch: 6, Steps: 1063 | Train Loss: 0.2527828 Vali Loss: 0.5798295 Test Loss: 0.4767106\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Updating learning rate to 0.0006583870090188714\n",
      "\titers: 100, epoch: 7 | loss: 0.2774879\n",
      "\tspeed: 0.4952s/iter; left time: 49427.6358s\n",
      "\titers: 200, epoch: 7 | loss: 0.2609439\n",
      "\tspeed: 0.0719s/iter; left time: 7170.9880s\n",
      "\titers: 300, epoch: 7 | loss: 0.2245341\n",
      "\tspeed: 0.0760s/iter; left time: 7571.2553s\n",
      "\titers: 400, epoch: 7 | loss: 0.2678584\n",
      "\tspeed: 0.0780s/iter; left time: 7763.0346s\n",
      "\titers: 500, epoch: 7 | loss: 0.2405472\n",
      "\tspeed: 0.0732s/iter; left time: 7279.0315s\n",
      "\titers: 600, epoch: 7 | loss: 0.2012967\n",
      "\tspeed: 0.0848s/iter; left time: 8420.5762s\n",
      "\titers: 700, epoch: 7 | loss: 0.2603330\n",
      "\tspeed: 0.0760s/iter; left time: 7541.0785s\n",
      "\titers: 800, epoch: 7 | loss: 0.2259818\n",
      "\tspeed: 0.0792s/iter; left time: 7846.6151s\n",
      "\titers: 900, epoch: 7 | loss: 0.2289079\n",
      "\tspeed: 0.0740s/iter; left time: 7328.1297s\n",
      "\titers: 1000, epoch: 7 | loss: 0.2733035\n",
      "\tspeed: 0.0868s/iter; left time: 8590.0462s\n",
      "Epoch: 7 cost time: 82.02013230323792\n",
      "Epoch: 7, Steps: 1063 | Train Loss: 0.2329065 Vali Loss: 0.5647365 Test Loss: 0.4121667\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Updating learning rate to 0.000816489334752311\n",
      "\titers: 100, epoch: 8 | loss: 0.2196732\n",
      "\tspeed: 0.4930s/iter; left time: 48688.9884s\n",
      "\titers: 200, epoch: 8 | loss: 0.2227060\n",
      "\tspeed: 0.0772s/iter; left time: 7612.6857s\n",
      "\titers: 300, epoch: 8 | loss: 0.2348802\n",
      "\tspeed: 0.0769s/iter; left time: 7583.2522s\n",
      "\titers: 400, epoch: 8 | loss: 0.2060487\n",
      "\tspeed: 0.0768s/iter; left time: 7565.6831s\n",
      "\titers: 500, epoch: 8 | loss: 0.1994896\n",
      "\tspeed: 0.0840s/iter; left time: 8263.4176s\n",
      "\titers: 600, epoch: 8 | loss: 0.2105588\n",
      "\tspeed: 0.0742s/iter; left time: 7291.2692s\n",
      "\titers: 700, epoch: 8 | loss: 0.2232750\n",
      "\tspeed: 0.0758s/iter; left time: 7445.1278s\n",
      "\titers: 800, epoch: 8 | loss: 0.1941409\n",
      "\tspeed: 0.0741s/iter; left time: 7270.9341s\n",
      "\titers: 900, epoch: 8 | loss: 0.2307138\n",
      "\tspeed: 0.0698s/iter; left time: 6842.1385s\n",
      "\titers: 1000, epoch: 8 | loss: 0.2210150\n",
      "\tspeed: 0.0782s/iter; left time: 7649.1275s\n",
      "Epoch: 8 cost time: 81.80307126045227\n",
      "Epoch: 8, Steps: 1063 | Train Loss: 0.2159814 Vali Loss: 0.5828509 Test Loss: 0.4135614\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Updating learning rate to 0.0009941334009900956\n",
      "\titers: 100, epoch: 9 | loss: 0.1959254\n",
      "\tspeed: 0.5240s/iter; left time: 51190.9848s\n",
      "\titers: 200, epoch: 9 | loss: 0.1882301\n",
      "\tspeed: 0.0751s/iter; left time: 7325.9017s\n",
      "\titers: 300, epoch: 9 | loss: 0.1927190\n",
      "\tspeed: 0.0749s/iter; left time: 7301.9753s\n",
      "\titers: 400, epoch: 9 | loss: 0.1858691\n",
      "\tspeed: 0.0769s/iter; left time: 7491.5891s\n",
      "\titers: 500, epoch: 9 | loss: 0.1875697\n",
      "\tspeed: 0.0790s/iter; left time: 7688.3354s\n",
      "\titers: 600, epoch: 9 | loss: 0.1908175\n",
      "\tspeed: 0.0721s/iter; left time: 7009.7495s\n",
      "\titers: 700, epoch: 9 | loss: 0.1933961\n",
      "\tspeed: 0.0799s/iter; left time: 7759.0682s\n",
      "\titers: 800, epoch: 9 | loss: 0.2028714\n",
      "\tspeed: 0.0811s/iter; left time: 7869.7042s\n",
      "\titers: 900, epoch: 9 | loss: 0.1927283\n",
      "\tspeed: 0.0698s/iter; left time: 6763.3050s\n",
      "\titers: 1000, epoch: 9 | loss: 0.1811610\n",
      "\tspeed: 0.0799s/iter; left time: 7738.0777s\n",
      "Epoch: 9 cost time: 81.69959235191345\n",
      "Epoch: 9, Steps: 1063 | Train Loss: 0.2019961 Vali Loss: 0.6126459 Test Loss: 0.4253412\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Updating learning rate to 0.0011893727802102599\n",
      "\titers: 100, epoch: 10 | loss: 0.2112253\n",
      "\tspeed: 0.4832s/iter; left time: 46689.5613s\n",
      "\titers: 200, epoch: 10 | loss: 0.2342324\n",
      "\tspeed: 0.0690s/iter; left time: 6656.7054s\n",
      "\titers: 300, epoch: 10 | loss: 0.2816525\n",
      "\tspeed: 0.0759s/iter; left time: 7317.7911s\n",
      "\titers: 400, epoch: 10 | loss: 0.1692621\n",
      "\tspeed: 0.0812s/iter; left time: 7817.6692s\n",
      "\titers: 500, epoch: 10 | loss: 0.1882166\n",
      "\tspeed: 0.0740s/iter; left time: 7118.0028s\n",
      "\titers: 600, epoch: 10 | loss: 0.2250810\n",
      "\tspeed: 0.0702s/iter; left time: 6744.7065s\n",
      "\titers: 700, epoch: 10 | loss: 0.1877522\n",
      "\tspeed: 0.0807s/iter; left time: 7752.0974s\n",
      "\titers: 800, epoch: 10 | loss: 0.1878058\n",
      "\tspeed: 0.0742s/iter; left time: 7120.7742s\n",
      "\titers: 900, epoch: 10 | loss: 0.2011127\n",
      "\tspeed: 0.0809s/iter; left time: 7750.9630s\n",
      "\titers: 1000, epoch: 10 | loss: 0.2012060\n",
      "\tspeed: 0.0791s/iter; left time: 7571.3546s\n",
      "Epoch: 10 cost time: 81.51186776161194\n",
      "Epoch: 10, Steps: 1063 | Train Loss: 0.1918838 Vali Loss: 0.5967914 Test Loss: 0.4476306\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Updating learning rate to 0.0014000682548800506\n",
      "\titers: 100, epoch: 11 | loss: 0.1779390\n",
      "\tspeed: 0.5130s/iter; left time: 49030.7334s\n",
      "\titers: 200, epoch: 11 | loss: 0.1877789\n",
      "\tspeed: 0.0771s/iter; left time: 7357.0345s\n",
      "\titers: 300, epoch: 11 | loss: 0.1588891\n",
      "\tspeed: 0.0800s/iter; left time: 7630.5711s\n",
      "\titers: 400, epoch: 11 | loss: 0.1855829\n",
      "\tspeed: 0.0770s/iter; left time: 7339.5038s\n",
      "\titers: 500, epoch: 11 | loss: 0.1998020\n",
      "\tspeed: 0.0730s/iter; left time: 6946.6128s\n",
      "\titers: 600, epoch: 11 | loss: 0.1711316\n",
      "\tspeed: 0.0761s/iter; left time: 7239.5424s\n",
      "\titers: 700, epoch: 11 | loss: 0.1821759\n",
      "\tspeed: 0.0780s/iter; left time: 7410.6546s\n",
      "\titers: 800, epoch: 11 | loss: 0.1861739\n",
      "\tspeed: 0.0799s/iter; left time: 7578.4442s\n",
      "\titers: 900, epoch: 11 | loss: 0.1829228\n",
      "\tspeed: 0.0719s/iter; left time: 6818.3549s\n",
      "\titers: 1000, epoch: 11 | loss: 0.1650813\n",
      "\tspeed: 0.0802s/iter; left time: 7590.3054s\n",
      "Epoch: 11 cost time: 82.09014964103699\n",
      "Epoch: 11, Steps: 1063 | Train Loss: 0.1849384 Vali Loss: 0.6206101 Test Loss: 0.4270055\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Updating learning rate to 0.0016239112566395117\n",
      "\titers: 100, epoch: 12 | loss: 0.1757618\n",
      "\tspeed: 0.4810s/iter; left time: 45457.9340s\n",
      "\titers: 200, epoch: 12 | loss: 0.1807228\n",
      "\tspeed: 0.0779s/iter; left time: 7356.3592s\n",
      "\titers: 300, epoch: 12 | loss: 0.1733064\n",
      "\tspeed: 0.0681s/iter; left time: 6423.4823s\n",
      "\titers: 400, epoch: 12 | loss: 0.1956314\n",
      "\tspeed: 0.0819s/iter; left time: 7716.1927s\n",
      "\titers: 500, epoch: 12 | loss: 0.1944956\n",
      "\tspeed: 0.0769s/iter; left time: 7234.5285s\n",
      "\titers: 600, epoch: 12 | loss: 0.1831767\n",
      "\tspeed: 0.0770s/iter; left time: 7241.6062s\n",
      "\titers: 700, epoch: 12 | loss: 0.1721999\n",
      "\tspeed: 0.0681s/iter; left time: 6394.0108s\n",
      "\titers: 800, epoch: 12 | loss: 0.1812951\n",
      "\tspeed: 0.0768s/iter; left time: 7208.3765s\n",
      "\titers: 900, epoch: 12 | loss: 0.1946057\n",
      "\tspeed: 0.0701s/iter; left time: 6566.5409s\n",
      "\titers: 1000, epoch: 12 | loss: 0.1689444\n",
      "\tspeed: 0.0790s/iter; left time: 7393.6944s\n",
      "Epoch: 12 cost time: 79.99645209312439\n",
      "Epoch: 12, Steps: 1063 | Train Loss: 0.1774555 Vali Loss: 0.6034228 Test Loss: 0.4088034\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Updating learning rate to 0.0018584491610444316\n",
      "\titers: 100, epoch: 13 | loss: 0.1984411\n",
      "\tspeed: 0.4961s/iter; left time: 46359.2298s\n",
      "\titers: 200, epoch: 13 | loss: 0.1771385\n",
      "\tspeed: 0.0781s/iter; left time: 7289.2332s\n",
      "\titers: 300, epoch: 13 | loss: 0.2052061\n",
      "\tspeed: 0.0727s/iter; left time: 6782.4752s\n",
      "\titers: 400, epoch: 13 | loss: 0.1443671\n",
      "\tspeed: 0.0741s/iter; left time: 6898.8134s\n",
      "\titers: 500, epoch: 13 | loss: 0.1721027\n",
      "\tspeed: 0.0711s/iter; left time: 6610.9755s\n",
      "\titers: 600, epoch: 13 | loss: 0.1727100\n",
      "\tspeed: 0.0779s/iter; left time: 7244.7909s\n",
      "\titers: 700, epoch: 13 | loss: 0.1744593\n",
      "\tspeed: 0.0912s/iter; left time: 8464.9433s\n",
      "\titers: 800, epoch: 13 | loss: 0.1956881\n",
      "\tspeed: 0.0908s/iter; left time: 8423.2714s\n",
      "\titers: 900, epoch: 13 | loss: 0.1756723\n",
      "\tspeed: 0.0722s/iter; left time: 6687.9912s\n",
      "\titers: 1000, epoch: 13 | loss: 0.1538861\n",
      "\tspeed: 0.0738s/iter; left time: 6833.6310s\n",
      "Epoch: 13 cost time: 82.00665640830994\n",
      "Epoch: 13, Steps: 1063 | Train Loss: 0.1735744 Vali Loss: 0.5816609 Test Loss: 0.4137326\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Updating learning rate to 0.0021011121607168\n",
      "\titers: 100, epoch: 14 | loss: 0.1684309\n",
      "\tspeed: 0.5390s/iter; left time: 49796.7801s\n",
      "\titers: 200, epoch: 14 | loss: 0.1408285\n",
      "\tspeed: 0.0750s/iter; left time: 6918.0299s\n",
      "\titers: 300, epoch: 14 | loss: 0.1893388\n",
      "\tspeed: 0.0809s/iter; left time: 7458.7094s\n",
      "\titers: 400, epoch: 14 | loss: 0.1743665\n",
      "\tspeed: 0.0692s/iter; left time: 6368.4237s\n",
      "\titers: 500, epoch: 14 | loss: 0.1783539\n",
      "\tspeed: 0.0789s/iter; left time: 7258.5032s\n",
      "\titers: 600, epoch: 14 | loss: 0.1640467\n",
      "\tspeed: 0.0802s/iter; left time: 7364.8329s\n",
      "\titers: 700, epoch: 14 | loss: 0.2114006\n",
      "\tspeed: 0.0818s/iter; left time: 7511.8229s\n",
      "\titers: 800, epoch: 14 | loss: 0.1765289\n",
      "\tspeed: 0.0811s/iter; left time: 7432.7532s\n",
      "\titers: 900, epoch: 14 | loss: 0.1840861\n",
      "\tspeed: 0.0759s/iter; left time: 6952.5399s\n",
      "\titers: 1000, epoch: 14 | loss: 0.1774567\n",
      "\tspeed: 0.0781s/iter; left time: 7141.8049s\n",
      "Epoch: 14 cost time: 82.29823684692383\n",
      "Epoch: 14, Steps: 1063 | Train Loss: 0.1714733 Vali Loss: 0.5882182 Test Loss: 0.4116422\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Updating learning rate to 0.0023492414224564567\n",
      "\titers: 100, epoch: 15 | loss: 0.1569324\n",
      "\tspeed: 0.5452s/iter; left time: 49782.6829s\n",
      "\titers: 200, epoch: 15 | loss: 0.1745641\n",
      "\tspeed: 0.0768s/iter; left time: 7005.2619s\n",
      "\titers: 300, epoch: 15 | loss: 0.1616582\n",
      "\tspeed: 0.0772s/iter; left time: 7033.8911s\n",
      "\titers: 400, epoch: 15 | loss: 0.1814486\n",
      "\tspeed: 0.0751s/iter; left time: 6831.1399s\n",
      "\titers: 500, epoch: 15 | loss: 0.1745468\n",
      "\tspeed: 0.0749s/iter; left time: 6807.2293s\n",
      "\titers: 600, epoch: 15 | loss: 0.1764814\n",
      "\tspeed: 0.0799s/iter; left time: 7254.1730s\n",
      "\titers: 700, epoch: 15 | loss: 0.1592401\n",
      "\tspeed: 0.0800s/iter; left time: 7256.5562s\n",
      "\titers: 800, epoch: 15 | loss: 0.1834202\n",
      "\tspeed: 0.0770s/iter; left time: 6978.8915s\n",
      "\titers: 900, epoch: 15 | loss: 0.1588407\n",
      "\tspeed: 0.0709s/iter; left time: 6420.4412s\n",
      "\titers: 1000, epoch: 15 | loss: 0.1637924\n",
      "\tspeed: 0.0782s/iter; left time: 7073.0146s\n",
      "Epoch: 15 cost time: 81.70379519462585\n",
      "Epoch: 15, Steps: 1063 | Train Loss: 0.1677821 Vali Loss: 0.5825539 Test Loss: 0.4130014\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Updating learning rate to 0.0026001182197993907\n",
      "\titers: 100, epoch: 16 | loss: 0.1543787\n",
      "\tspeed: 0.5188s/iter; left time: 46822.4637s\n",
      "\titers: 200, epoch: 16 | loss: 0.1547589\n",
      "\tspeed: 0.0800s/iter; left time: 7212.6427s\n",
      "\titers: 300, epoch: 16 | loss: 0.1724129\n",
      "\tspeed: 0.0740s/iter; left time: 6663.8229s\n",
      "\titers: 400, epoch: 16 | loss: 0.1689853\n",
      "\tspeed: 0.0791s/iter; left time: 7112.3890s\n",
      "\titers: 500, epoch: 16 | loss: 0.1629396\n",
      "\tspeed: 0.0920s/iter; left time: 8266.6113s\n",
      "\titers: 600, epoch: 16 | loss: 0.1550836\n",
      "\tspeed: 0.0811s/iter; left time: 7275.5650s\n",
      "\titers: 700, epoch: 16 | loss: 0.1446676\n",
      "\tspeed: 0.0869s/iter; left time: 7788.9208s\n",
      "\titers: 800, epoch: 16 | loss: 0.1566843\n",
      "\tspeed: 0.0852s/iter; left time: 7627.7341s\n",
      "\titers: 900, epoch: 16 | loss: 0.1518087\n",
      "\tspeed: 0.0829s/iter; left time: 7415.4645s\n",
      "\titers: 1000, epoch: 16 | loss: 0.1572186\n",
      "\tspeed: 0.0830s/iter; left time: 7416.8607s\n",
      "Epoch: 16 cost time: 86.78593564033508\n",
      "Epoch: 16, Steps: 1063 | Train Loss: 0.1658514 Vali Loss: 0.5582886 Test Loss: 0.3950331\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Updating learning rate to 0.0028509937218203023\n",
      "\titers: 100, epoch: 17 | loss: 0.1459892\n",
      "\tspeed: 0.6291s/iter; left time: 56109.5099s\n",
      "\titers: 200, epoch: 17 | loss: 0.1655416\n",
      "\tspeed: 0.0839s/iter; left time: 7475.5315s\n",
      "\titers: 300, epoch: 17 | loss: 0.1536004\n",
      "\tspeed: 0.0840s/iter; left time: 7471.9581s\n",
      "\titers: 400, epoch: 17 | loss: 0.1604896\n",
      "\tspeed: 0.0862s/iter; left time: 7659.5316s\n",
      "\titers: 500, epoch: 17 | loss: 0.1738340\n",
      "\tspeed: 0.0811s/iter; left time: 7198.6419s\n",
      "\titers: 600, epoch: 17 | loss: 0.1728427\n",
      "\tspeed: 0.0868s/iter; left time: 7701.0046s\n",
      "\titers: 700, epoch: 17 | loss: 0.1738045\n",
      "\tspeed: 0.0850s/iter; left time: 7532.5054s\n",
      "\titers: 800, epoch: 17 | loss: 0.1751734\n",
      "\tspeed: 0.0830s/iter; left time: 7342.8005s\n",
      "\titers: 900, epoch: 17 | loss: 0.1635561\n",
      "\tspeed: 0.0811s/iter; left time: 7172.5510s\n",
      "\titers: 1000, epoch: 17 | loss: 0.1451694\n",
      "\tspeed: 0.0859s/iter; left time: 7583.2963s\n",
      "Epoch: 17 cost time: 88.29793977737427\n",
      "Epoch: 17, Steps: 1063 | Train Loss: 0.1686021 Vali Loss: 0.6106212 Test Loss: 0.4076017\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Updating learning rate to 0.0030991191117865995\n",
      "\titers: 100, epoch: 18 | loss: 0.2088697\n",
      "\tspeed: 0.5649s/iter; left time: 49783.1813s\n",
      "\titers: 200, epoch: 18 | loss: 0.1444804\n",
      "\tspeed: 0.0842s/iter; left time: 7410.9883s\n",
      "\titers: 300, epoch: 18 | loss: 0.1534628\n",
      "\tspeed: 0.0790s/iter; left time: 6949.0288s\n",
      "\titers: 400, epoch: 18 | loss: 0.1759659\n",
      "\tspeed: 0.0859s/iter; left time: 7540.4470s\n",
      "\titers: 500, epoch: 18 | loss: 0.1713222\n",
      "\tspeed: 0.0839s/iter; left time: 7363.3802s\n",
      "\titers: 600, epoch: 18 | loss: 0.1760700\n",
      "\tspeed: 0.0932s/iter; left time: 8163.4184s\n",
      "\titers: 700, epoch: 18 | loss: 0.1809987\n",
      "\tspeed: 0.0851s/iter; left time: 7448.4440s\n",
      "\titers: 800, epoch: 18 | loss: 0.1834145\n",
      "\tspeed: 0.0809s/iter; left time: 7073.1272s\n",
      "\titers: 900, epoch: 18 | loss: 0.1600402\n",
      "\tspeed: 0.0931s/iter; left time: 8127.6623s\n",
      "\titers: 1000, epoch: 18 | loss: 0.1429897\n",
      "\tspeed: 0.0809s/iter; left time: 7052.6036s\n",
      "Epoch: 18 cost time: 89.81110644340515\n",
      "Epoch: 18, Steps: 1063 | Train Loss: 0.1698266 Vali Loss: 0.5880069 Test Loss: 0.3946010\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Updating learning rate to 0.00334177570565689\n",
      "\titers: 100, epoch: 19 | loss: 0.1640219\n",
      "\tspeed: 0.6321s/iter; left time: 55037.1118s\n",
      "\titers: 200, epoch: 19 | loss: 0.1607818\n",
      "\tspeed: 0.0948s/iter; left time: 8244.7752s\n",
      "\titers: 300, epoch: 19 | loss: 0.1732134\n",
      "\tspeed: 0.0831s/iter; left time: 7219.9669s\n",
      "\titers: 400, epoch: 19 | loss: 0.1949711\n",
      "\tspeed: 0.0939s/iter; left time: 8151.3120s\n",
      "\titers: 500, epoch: 19 | loss: 0.1557054\n",
      "\tspeed: 0.0822s/iter; left time: 7121.7564s\n",
      "\titers: 600, epoch: 19 | loss: 0.1450247\n",
      "\tspeed: 0.0810s/iter; left time: 7009.5307s\n",
      "\titers: 700, epoch: 19 | loss: 0.1582216\n",
      "\tspeed: 0.0729s/iter; left time: 6300.6218s\n",
      "\titers: 800, epoch: 19 | loss: 0.1648294\n",
      "\tspeed: 0.0800s/iter; left time: 6908.1741s\n",
      "\titers: 900, epoch: 19 | loss: 0.1651199\n",
      "\tspeed: 0.0840s/iter; left time: 7246.6992s\n",
      "\titers: 1000, epoch: 19 | loss: 0.1763553\n",
      "\tspeed: 0.0870s/iter; left time: 7499.6790s\n",
      "Epoch: 19 cost time: 89.81959271430969\n",
      "Epoch: 19, Steps: 1063 | Train Loss: 0.1690185 Vali Loss: 0.6053147 Test Loss: 0.4268753\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Updating learning rate to 0.0035763047404187174\n",
      "\titers: 100, epoch: 20 | loss: 0.1539327\n",
      "\tspeed: 0.6501s/iter; left time: 55907.9161s\n",
      "\titers: 200, epoch: 20 | loss: 0.1427766\n",
      "\tspeed: 0.0880s/iter; left time: 7557.9276s\n",
      "\titers: 300, epoch: 20 | loss: 0.1881067\n",
      "\tspeed: 0.0749s/iter; left time: 6427.7061s\n",
      "\titers: 400, epoch: 20 | loss: 0.1606808\n",
      "\tspeed: 0.0640s/iter; left time: 5489.2739s\n",
      "\titers: 500, epoch: 20 | loss: 0.1559288\n",
      "\tspeed: 0.0640s/iter; left time: 5475.3936s\n",
      "\titers: 600, epoch: 20 | loss: 0.1482820\n",
      "\tspeed: 0.0631s/iter; left time: 5394.2327s\n",
      "\titers: 700, epoch: 20 | loss: 0.1664101\n",
      "\tspeed: 0.0628s/iter; left time: 5366.9830s\n",
      "\titers: 800, epoch: 20 | loss: 0.1494803\n",
      "\tspeed: 0.0611s/iter; left time: 5211.5754s\n",
      "\titers: 900, epoch: 20 | loss: 0.1435640\n",
      "\tspeed: 0.0671s/iter; left time: 5717.1277s\n",
      "\titers: 1000, epoch: 20 | loss: 0.1620674\n",
      "\tspeed: 0.0708s/iter; left time: 6027.9284s\n",
      "Epoch: 20 cost time: 75.40897965431213\n",
      "Epoch: 20, Steps: 1063 | Train Loss: 0.1672206 Vali Loss: 0.6353060 Test Loss: 0.4141305\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Updating learning rate to 0.0038001365058778274\n",
      "\titers: 100, epoch: 21 | loss: 0.1892517\n",
      "\tspeed: 0.7320s/iter; left time: 62180.5952s\n",
      "\titers: 200, epoch: 21 | loss: 0.1848821\n",
      "\tspeed: 0.0819s/iter; left time: 6951.4878s\n",
      "\titers: 300, epoch: 21 | loss: 0.2075070\n",
      "\tspeed: 0.0841s/iter; left time: 7130.3306s\n",
      "\titers: 400, epoch: 21 | loss: 0.1905235\n",
      "\tspeed: 0.0639s/iter; left time: 5404.5290s\n",
      "\titers: 500, epoch: 21 | loss: 0.1504932\n",
      "\tspeed: 0.0621s/iter; left time: 5252.4362s\n",
      "\titers: 600, epoch: 21 | loss: 0.1643521\n",
      "\tspeed: 0.0609s/iter; left time: 5140.1458s\n",
      "\titers: 700, epoch: 21 | loss: 0.1592557\n",
      "\tspeed: 0.0792s/iter; left time: 6681.9078s\n",
      "\titers: 800, epoch: 21 | loss: 0.1418712\n",
      "\tspeed: 0.0808s/iter; left time: 6809.7041s\n",
      "\titers: 900, epoch: 21 | loss: 0.1927442\n",
      "\tspeed: 0.0812s/iter; left time: 6829.4115s\n",
      "\titers: 1000, epoch: 21 | loss: 0.1888201\n",
      "\tspeed: 0.0868s/iter; left time: 7292.4746s\n",
      "Epoch: 21 cost time: 82.51279640197754\n",
      "Epoch: 21, Steps: 1063 | Train Loss: 0.1691176 Vali Loss: 0.5762702 Test Loss: 0.4052424\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): PatchTST_backbone(\n",
       "    (backbone): TSTiEncoder(\n",
       "      (W_P): Linear(in_features=16, out_features=128, bias=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (encoder): TSTEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-2): 3 x TSTEncoderLayer(\n",
       "            (self_attn): _MultiheadAttention(\n",
       "              (W_Q): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (W_K): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (W_V): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (sdp_attn): _ScaledDotProductAttention(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (dropout_attn): Dropout(p=0.2, inplace=False)\n",
       "            (norm_attn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.2, inplace=False)\n",
       "              (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "            )\n",
       "            (dropout_ffn): Dropout(p=0.2, inplace=False)\n",
       "            (norm_ffn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): Flatten_Head(\n",
       "      (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "      (linear): Linear(in_features=5248, out_features=192, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exp = Exp_Main\n",
    "setting=f'PatchTST_train_on_{args.data}_{args.pred_len}'\n",
    "# set experiments\n",
    "exp = Exp(args)\n",
    "exp.train(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f139aff",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0128b13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 11329\n",
      "mse:0.36035341024398804, mae:0.3956582248210907, rse:0.571427583694458\n"
     ]
    }
   ],
   "source": [
    "exp.test(setting)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460a66ce",
   "metadata": {},
   "source": [
    "---\n",
    "## Trail 3: PatchTST, Dataset:ETTm1,  Metric: 336\n",
    "\n",
    "### Set hyperparameters\n",
    "Set some parameters (Args) for the our experiment like dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "328c3afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ETTm2,  Prediction Length : 336\n"
     ]
    }
   ],
   "source": [
    "args.pred_len = 336 # prediction sequence length\n",
    "print(f\"Dataset: {args.data},  Prediction Length : {args.pred_len}\") \n",
    "# print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3954503",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5b52925a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "train 33889\n",
      "val 11185\n",
      "test 11185\n",
      "\titers: 100, epoch: 1 | loss: 0.3282336\n",
      "\tspeed: 0.0783s/iter; left time: 8281.5136s\n",
      "\titers: 200, epoch: 1 | loss: 0.2279086\n",
      "\tspeed: 0.0801s/iter; left time: 8462.1668s\n",
      "\titers: 300, epoch: 1 | loss: 0.4095321\n",
      "\tspeed: 0.0790s/iter; left time: 8342.7958s\n",
      "\titers: 400, epoch: 1 | loss: 0.4098197\n",
      "\tspeed: 0.0813s/iter; left time: 8571.9696s\n",
      "\titers: 500, epoch: 1 | loss: 0.2569183\n",
      "\tspeed: 0.0800s/iter; left time: 8427.6906s\n",
      "\titers: 600, epoch: 1 | loss: 0.2969300\n",
      "\tspeed: 0.0878s/iter; left time: 9243.4873s\n",
      "\titers: 700, epoch: 1 | loss: 0.5525036\n",
      "\tspeed: 0.0819s/iter; left time: 8620.2352s\n",
      "\titers: 800, epoch: 1 | loss: 0.4619457\n",
      "\tspeed: 0.0781s/iter; left time: 8206.4157s\n",
      "\titers: 900, epoch: 1 | loss: 0.3152940\n",
      "\tspeed: 0.0861s/iter; left time: 9039.8930s\n",
      "\titers: 1000, epoch: 1 | loss: 0.3613250\n",
      "\tspeed: 0.0819s/iter; left time: 8590.5206s\n",
      "Epoch: 1 cost time: 86.13871335983276\n",
      "Epoch: 1, Steps: 1059 | Train Loss: 0.3985891 Vali Loss: 0.2208271 Test Loss: 0.2994208\n",
      "Validation loss decreased (inf --> 0.220827).  Saving model ...\n",
      "Updating learning rate to 0.00021314827806317212\n",
      "\titers: 100, epoch: 2 | loss: 0.3670580\n",
      "\tspeed: 0.5830s/iter; left time: 61068.8472s\n",
      "\titers: 200, epoch: 2 | loss: 0.3054243\n",
      "\tspeed: 0.0692s/iter; left time: 7239.1408s\n",
      "\titers: 300, epoch: 2 | loss: 0.2758588\n",
      "\tspeed: 0.0838s/iter; left time: 8762.8298s\n",
      "\titers: 400, epoch: 2 | loss: 0.4116607\n",
      "\tspeed: 0.0800s/iter; left time: 8357.5580s\n",
      "\titers: 500, epoch: 2 | loss: 0.4431009\n",
      "\tspeed: 0.0801s/iter; left time: 8353.1959s\n",
      "\titers: 600, epoch: 2 | loss: 0.3902486\n",
      "\tspeed: 0.0780s/iter; left time: 8132.6356s\n",
      "\titers: 700, epoch: 2 | loss: 0.2762005\n",
      "\tspeed: 0.0761s/iter; left time: 7923.0154s\n",
      "\titers: 800, epoch: 2 | loss: 0.2776138\n",
      "\tspeed: 0.0828s/iter; left time: 8612.6348s\n",
      "\titers: 900, epoch: 2 | loss: 0.3067027\n",
      "\tspeed: 0.0842s/iter; left time: 8749.8747s\n",
      "\titers: 1000, epoch: 2 | loss: 0.3776691\n",
      "\tspeed: 0.0881s/iter; left time: 9144.9187s\n",
      "Epoch: 2 cost time: 85.02841925621033\n",
      "Epoch: 2, Steps: 1059 | Train Loss: 0.3401242 Vali Loss: 0.3236305 Test Loss: 0.5927778\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Updating learning rate to 0.00025244904790599956\n",
      "\titers: 100, epoch: 3 | loss: 0.3617867\n",
      "\tspeed: 0.5418s/iter; left time: 56170.9440s\n",
      "\titers: 200, epoch: 3 | loss: 0.3289358\n",
      "\tspeed: 0.0820s/iter; left time: 8493.3949s\n",
      "\titers: 300, epoch: 3 | loss: 0.3500592\n",
      "\tspeed: 0.0830s/iter; left time: 8589.8296s\n",
      "\titers: 400, epoch: 3 | loss: 0.3240978\n",
      "\tspeed: 0.0809s/iter; left time: 8367.6572s\n",
      "\titers: 500, epoch: 3 | loss: 0.2157134\n",
      "\tspeed: 0.0812s/iter; left time: 8385.8326s\n",
      "\titers: 600, epoch: 3 | loss: 0.2354617\n",
      "\tspeed: 0.0790s/iter; left time: 8148.1048s\n",
      "\titers: 700, epoch: 3 | loss: 0.2501615\n",
      "\tspeed: 0.0741s/iter; left time: 7643.2923s\n",
      "\titers: 800, epoch: 3 | loss: 0.2661166\n",
      "\tspeed: 0.0818s/iter; left time: 8424.5798s\n",
      "\titers: 900, epoch: 3 | loss: 0.4056252\n",
      "\tspeed: 0.0800s/iter; left time: 8234.8995s\n",
      "\titers: 1000, epoch: 3 | loss: 0.4282835\n",
      "\tspeed: 0.0710s/iter; left time: 7292.8945s\n",
      "Epoch: 3 cost time: 84.111745595932\n",
      "Epoch: 3, Steps: 1059 | Train Loss: 0.3197636 Vali Loss: 0.2599282 Test Loss: 0.4231032\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Updating learning rate to 0.00031747169498682476\n",
      "\titers: 100, epoch: 4 | loss: 0.3197621\n",
      "\tspeed: 0.5690s/iter; left time: 58391.2318s\n",
      "\titers: 200, epoch: 4 | loss: 0.3959524\n",
      "\tspeed: 0.0780s/iter; left time: 7993.9475s\n",
      "\titers: 300, epoch: 4 | loss: 0.2109678\n",
      "\tspeed: 0.0790s/iter; left time: 8090.4021s\n",
      "\titers: 400, epoch: 4 | loss: 0.2012012\n",
      "\tspeed: 0.0820s/iter; left time: 8390.7064s\n",
      "\titers: 500, epoch: 4 | loss: 0.2616621\n",
      "\tspeed: 0.0802s/iter; left time: 8198.8537s\n",
      "\titers: 600, epoch: 4 | loss: 0.2680535\n",
      "\tspeed: 0.0829s/iter; left time: 8465.3338s\n",
      "\titers: 700, epoch: 4 | loss: 0.3313548\n",
      "\tspeed: 0.0801s/iter; left time: 8169.1130s\n",
      "\titers: 800, epoch: 4 | loss: 0.3182451\n",
      "\tspeed: 0.0769s/iter; left time: 7842.8982s\n",
      "\titers: 900, epoch: 4 | loss: 0.3865127\n",
      "\tspeed: 0.0828s/iter; left time: 8435.5031s\n",
      "\titers: 1000, epoch: 4 | loss: 0.2039965\n",
      "\tspeed: 0.0891s/iter; left time: 9065.9751s\n",
      "Epoch: 4 cost time: 85.59177017211914\n",
      "Epoch: 4, Steps: 1059 | Train Loss: 0.3027506 Vali Loss: 0.2283089 Test Loss: 0.3293645\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Updating learning rate to 0.0004075037727687943\n",
      "\titers: 100, epoch: 5 | loss: 0.3588360\n",
      "\tspeed: 0.5771s/iter; left time: 58615.4397s\n",
      "\titers: 200, epoch: 5 | loss: 0.2198385\n",
      "\tspeed: 0.0810s/iter; left time: 8219.7881s\n",
      "\titers: 300, epoch: 5 | loss: 0.2086194\n",
      "\tspeed: 0.0729s/iter; left time: 7394.4463s\n",
      "\titers: 400, epoch: 5 | loss: 0.2468919\n",
      "\tspeed: 0.0878s/iter; left time: 8893.7435s\n",
      "\titers: 500, epoch: 5 | loss: 0.3706571\n",
      "\tspeed: 0.0802s/iter; left time: 8114.7258s\n",
      "\titers: 600, epoch: 5 | loss: 0.3160971\n",
      "\tspeed: 0.0927s/iter; left time: 9372.3430s\n",
      "\titers: 700, epoch: 5 | loss: 0.2498258\n",
      "\tspeed: 0.0840s/iter; left time: 8481.0981s\n",
      "\titers: 800, epoch: 5 | loss: 0.4568297\n",
      "\tspeed: 0.0760s/iter; left time: 7665.5143s\n",
      "\titers: 900, epoch: 5 | loss: 0.2065678\n",
      "\tspeed: 0.0781s/iter; left time: 7869.1230s\n",
      "\titers: 1000, epoch: 5 | loss: 0.3520910\n",
      "\tspeed: 0.0850s/iter; left time: 8554.1974s\n",
      "Epoch: 5 cost time: 87.60957837104797\n",
      "Epoch: 5, Steps: 1059 | Train Loss: 0.2942141 Vali Loss: 0.2605723 Test Loss: 0.4135559\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Updating learning rate to 0.0005215588089241743\n",
      "\titers: 100, epoch: 6 | loss: 0.2250656\n",
      "\tspeed: 0.5972s/iter; left time: 60017.2925s\n",
      "\titers: 200, epoch: 6 | loss: 0.2689886\n",
      "\tspeed: 0.0798s/iter; left time: 8015.9678s\n",
      "\titers: 300, epoch: 6 | loss: 0.1955096\n",
      "\tspeed: 0.0760s/iter; left time: 7623.9121s\n",
      "\titers: 400, epoch: 6 | loss: 0.3152502\n",
      "\tspeed: 0.0850s/iter; left time: 8517.8251s\n",
      "\titers: 500, epoch: 6 | loss: 0.2533580\n",
      "\tspeed: 0.0840s/iter; left time: 8407.8253s\n",
      "\titers: 600, epoch: 6 | loss: 0.2240587\n",
      "\tspeed: 0.0849s/iter; left time: 8495.0823s\n",
      "\titers: 700, epoch: 6 | loss: 0.2857721\n",
      "\tspeed: 0.0823s/iter; left time: 8218.4646s\n",
      "\titers: 800, epoch: 6 | loss: 0.2731105\n",
      "\tspeed: 0.0888s/iter; left time: 8863.0104s\n",
      "\titers: 900, epoch: 6 | loss: 0.3556812\n",
      "\tspeed: 0.0841s/iter; left time: 8386.4870s\n",
      "\titers: 1000, epoch: 6 | loss: 0.3676096\n",
      "\tspeed: 0.0839s/iter; left time: 8355.4070s\n",
      "Epoch: 6 cost time: 87.50416588783264\n",
      "Epoch: 6, Steps: 1059 | Train Loss: 0.2789737 Vali Loss: 0.2803112 Test Loss: 0.4236954\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Updating learning rate to 0.0006583871140114009\n",
      "\titers: 100, epoch: 7 | loss: 0.2873247\n",
      "\tspeed: 0.5683s/iter; left time: 56514.2460s\n",
      "\titers: 200, epoch: 7 | loss: 0.2395715\n",
      "\tspeed: 0.0746s/iter; left time: 7416.2461s\n",
      "\titers: 300, epoch: 7 | loss: 0.2948902\n",
      "\tspeed: 0.0832s/iter; left time: 8261.1060s\n",
      "\titers: 400, epoch: 7 | loss: 0.2225853\n",
      "\tspeed: 0.0848s/iter; left time: 8404.0147s\n",
      "\titers: 500, epoch: 7 | loss: 0.2453200\n",
      "\tspeed: 0.0832s/iter; left time: 8242.1057s\n",
      "\titers: 600, epoch: 7 | loss: 0.2125858\n",
      "\tspeed: 0.0899s/iter; left time: 8900.2115s\n",
      "\titers: 700, epoch: 7 | loss: 0.2509520\n",
      "\tspeed: 0.0850s/iter; left time: 8403.3166s\n",
      "\titers: 800, epoch: 7 | loss: 0.2331079\n",
      "\tspeed: 0.0739s/iter; left time: 7295.9769s\n",
      "\titers: 900, epoch: 7 | loss: 0.2245138\n",
      "\tspeed: 0.0770s/iter; left time: 7597.2302s\n",
      "\titers: 1000, epoch: 7 | loss: 0.2583169\n",
      "\tspeed: 0.0811s/iter; left time: 7994.1970s\n",
      "Epoch: 7 cost time: 85.30864644050598\n",
      "Epoch: 7, Steps: 1059 | Train Loss: 0.2652488 Vali Loss: 0.2623482 Test Loss: 0.3698255\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Updating learning rate to 0.0008164894741953064\n",
      "\titers: 100, epoch: 8 | loss: 0.3041045\n",
      "\tspeed: 0.6009s/iter; left time: 59117.7228s\n",
      "\titers: 200, epoch: 8 | loss: 0.2255790\n",
      "\tspeed: 0.0780s/iter; left time: 7666.7412s\n",
      "\titers: 300, epoch: 8 | loss: 0.2733005\n",
      "\tspeed: 0.0810s/iter; left time: 7954.1858s\n",
      "\titers: 400, epoch: 8 | loss: 0.1879789\n",
      "\tspeed: 0.0940s/iter; left time: 9224.5782s\n",
      "\titers: 500, epoch: 8 | loss: 0.1564069\n",
      "\tspeed: 0.0821s/iter; left time: 8046.5841s\n",
      "\titers: 600, epoch: 8 | loss: 0.2834275\n",
      "\tspeed: 0.0878s/iter; left time: 8596.5704s\n",
      "\titers: 700, epoch: 8 | loss: 0.3095355\n",
      "\tspeed: 0.0751s/iter; left time: 7339.8347s\n",
      "\titers: 800, epoch: 8 | loss: 0.4133489\n",
      "\tspeed: 0.0722s/iter; left time: 7048.8829s\n",
      "\titers: 900, epoch: 8 | loss: 0.2317099\n",
      "\tspeed: 0.0799s/iter; left time: 7802.1451s\n",
      "\titers: 1000, epoch: 8 | loss: 0.3179289\n",
      "\tspeed: 0.0788s/iter; left time: 7685.3162s\n",
      "Epoch: 8 cost time: 85.5971622467041\n",
      "Epoch: 8, Steps: 1059 | Train Loss: 0.2509467 Vali Loss: 0.2993739 Test Loss: 0.5840428\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Updating learning rate to 0.0009941335779807756\n",
      "\titers: 100, epoch: 9 | loss: 0.2075262\n",
      "\tspeed: 0.5651s/iter; left time: 55003.4162s\n",
      "\titers: 200, epoch: 9 | loss: 0.2569948\n",
      "\tspeed: 0.0930s/iter; left time: 9043.0870s\n",
      "\titers: 300, epoch: 9 | loss: 0.3340322\n",
      "\tspeed: 0.0819s/iter; left time: 7952.4765s\n",
      "\titers: 400, epoch: 9 | loss: 0.2500681\n",
      "\tspeed: 0.0811s/iter; left time: 7867.8533s\n",
      "\titers: 500, epoch: 9 | loss: 0.3177054\n",
      "\tspeed: 0.0859s/iter; left time: 8330.8516s\n",
      "\titers: 600, epoch: 9 | loss: 0.2248775\n",
      "\tspeed: 0.0790s/iter; left time: 7645.4885s\n",
      "\titers: 700, epoch: 9 | loss: 0.2443716\n",
      "\tspeed: 0.0852s/iter; left time: 8238.6847s\n",
      "\titers: 800, epoch: 9 | loss: 0.4126876\n",
      "\tspeed: 0.0868s/iter; left time: 8383.8943s\n",
      "\titers: 900, epoch: 9 | loss: 0.2412097\n",
      "\tspeed: 0.0881s/iter; left time: 8504.6071s\n",
      "\titers: 1000, epoch: 9 | loss: 0.2167160\n",
      "\tspeed: 0.0839s/iter; left time: 8092.5663s\n",
      "Epoch: 9 cost time: 89.81039786338806\n",
      "Epoch: 9, Steps: 1059 | Train Loss: 0.2462065 Vali Loss: 0.3065989 Test Loss: 0.5732268\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Updating learning rate to 0.0011893729969737607\n",
      "\titers: 100, epoch: 10 | loss: 0.1897876\n",
      "\tspeed: 0.5462s/iter; left time: 52583.6778s\n",
      "\titers: 200, epoch: 10 | loss: 0.2125138\n",
      "\tspeed: 0.0868s/iter; left time: 8350.2779s\n",
      "\titers: 300, epoch: 10 | loss: 0.2508188\n",
      "\tspeed: 0.0749s/iter; left time: 7198.8153s\n",
      "\titers: 400, epoch: 10 | loss: 0.2849262\n",
      "\tspeed: 0.0763s/iter; left time: 7324.2675s\n",
      "\titers: 500, epoch: 10 | loss: 0.3119540\n",
      "\tspeed: 0.0807s/iter; left time: 7735.0394s\n",
      "\titers: 600, epoch: 10 | loss: 0.3151567\n",
      "\tspeed: 0.0790s/iter; left time: 7565.9497s\n",
      "\titers: 700, epoch: 10 | loss: 0.2748163\n",
      "\tspeed: 0.0801s/iter; left time: 7663.4797s\n",
      "\titers: 800, epoch: 10 | loss: 0.2013887\n",
      "\tspeed: 0.0789s/iter; left time: 7542.9260s\n",
      "\titers: 900, epoch: 10 | loss: 0.3710778\n",
      "\tspeed: 0.0842s/iter; left time: 8037.2100s\n",
      "\titers: 1000, epoch: 10 | loss: 0.1740348\n",
      "\tspeed: 0.0888s/iter; left time: 8473.5833s\n",
      "Epoch: 10 cost time: 85.60092687606812\n",
      "Epoch: 10, Steps: 1059 | Train Loss: 0.2435331 Vali Loss: 0.3187050 Test Loss: 0.5106399\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Updating learning rate to 0.0014000685126994198\n",
      "\titers: 100, epoch: 11 | loss: 0.2137381\n",
      "\tspeed: 0.5711s/iter; left time: 54377.1853s\n",
      "\titers: 200, epoch: 11 | loss: 0.3110507\n",
      "\tspeed: 0.0800s/iter; left time: 7612.7037s\n",
      "\titers: 300, epoch: 11 | loss: 0.3990988\n",
      "\tspeed: 0.0828s/iter; left time: 7870.0447s\n",
      "\titers: 400, epoch: 11 | loss: 0.3533678\n",
      "\tspeed: 0.0812s/iter; left time: 7702.9665s\n",
      "\titers: 500, epoch: 11 | loss: 0.2269673\n",
      "\tspeed: 0.0838s/iter; left time: 7943.0262s\n",
      "\titers: 600, epoch: 11 | loss: 0.5645147\n",
      "\tspeed: 0.0821s/iter; left time: 7772.9074s\n",
      "\titers: 700, epoch: 11 | loss: 0.3447816\n",
      "\tspeed: 0.0822s/iter; left time: 7776.6825s\n",
      "\titers: 800, epoch: 11 | loss: 0.3242893\n",
      "\tspeed: 0.0838s/iter; left time: 7919.1044s\n",
      "\titers: 900, epoch: 11 | loss: 0.2662111\n",
      "\tspeed: 0.0769s/iter; left time: 7264.7308s\n",
      "\titers: 1000, epoch: 11 | loss: 0.4125897\n",
      "\tspeed: 0.0782s/iter; left time: 7377.1432s\n",
      "Epoch: 11 cost time: 86.40171456336975\n",
      "Epoch: 11, Steps: 1059 | Train Loss: 0.3427721 Vali Loss: 0.2786908 Test Loss: 0.4630337\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Updating learning rate to 0.001623911555801565\n",
      "\titers: 100, epoch: 12 | loss: 0.2850485\n",
      "\tspeed: 0.5528s/iter; left time: 52051.0881s\n",
      "\titers: 200, epoch: 12 | loss: 0.2821870\n",
      "\tspeed: 0.0849s/iter; left time: 7988.0333s\n",
      "\titers: 300, epoch: 12 | loss: 0.3475740\n",
      "\tspeed: 0.0780s/iter; left time: 7328.1726s\n",
      "\titers: 400, epoch: 12 | loss: 0.3606841\n",
      "\tspeed: 0.0810s/iter; left time: 7602.1379s\n",
      "\titers: 500, epoch: 12 | loss: 0.3900989\n",
      "\tspeed: 0.0761s/iter; left time: 7130.6349s\n",
      "\titers: 600, epoch: 12 | loss: 0.5045059\n",
      "\tspeed: 0.0780s/iter; left time: 7304.9147s\n",
      "\titers: 700, epoch: 12 | loss: 0.5086565\n",
      "\tspeed: 0.0780s/iter; left time: 7296.8414s\n",
      "\titers: 800, epoch: 12 | loss: 0.2993958\n",
      "\tspeed: 0.0952s/iter; left time: 8896.3962s\n",
      "\titers: 900, epoch: 12 | loss: 0.2741661\n",
      "\tspeed: 0.0820s/iter; left time: 7651.9947s\n",
      "\titers: 1000, epoch: 12 | loss: 0.3329946\n",
      "\tspeed: 0.0910s/iter; left time: 8481.3552s\n",
      "Epoch: 12 cost time: 87.19804835319519\n",
      "Epoch: 12, Steps: 1059 | Train Loss: 0.3411962 Vali Loss: 0.2800100 Test Loss: 0.3572460\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Updating learning rate to 0.0018584495008025182\n",
      "\titers: 100, epoch: 13 | loss: 0.2085931\n",
      "\tspeed: 0.5240s/iter; left time: 48776.4711s\n",
      "\titers: 200, epoch: 13 | loss: 0.2550389\n",
      "\tspeed: 0.0772s/iter; left time: 7178.1517s\n",
      "\titers: 300, epoch: 13 | loss: 0.4391340\n",
      "\tspeed: 0.0787s/iter; left time: 7308.8501s\n",
      "\titers: 400, epoch: 13 | loss: 0.3056428\n",
      "\tspeed: 0.0872s/iter; left time: 8090.4034s\n",
      "\titers: 500, epoch: 13 | loss: 0.3184952\n",
      "\tspeed: 0.0770s/iter; left time: 7134.4998s\n",
      "\titers: 600, epoch: 13 | loss: 0.2910114\n",
      "\tspeed: 0.0829s/iter; left time: 7676.4102s\n",
      "\titers: 700, epoch: 13 | loss: 0.2274268\n",
      "\tspeed: 0.0819s/iter; left time: 7579.3133s\n",
      "\titers: 800, epoch: 13 | loss: 0.3681464\n",
      "\tspeed: 0.0790s/iter; left time: 7298.2854s\n",
      "\titers: 900, epoch: 13 | loss: 0.3588055\n",
      "\tspeed: 0.0821s/iter; left time: 7580.5538s\n",
      "\titers: 1000, epoch: 13 | loss: 0.3177410\n",
      "\tspeed: 0.0859s/iter; left time: 7915.9736s\n",
      "Epoch: 13 cost time: 86.49913239479065\n",
      "Epoch: 13, Steps: 1059 | Train Loss: 0.3690709 Vali Loss: 0.2618636 Test Loss: 0.3376532\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Updating learning rate to 0.00210111253927125\n",
      "\titers: 100, epoch: 14 | loss: 0.3654813\n",
      "\tspeed: 0.5752s/iter; left time: 52940.9866s\n",
      "\titers: 200, epoch: 14 | loss: 0.3878570\n",
      "\tspeed: 0.0779s/iter; left time: 7160.7884s\n",
      "\titers: 300, epoch: 14 | loss: 0.5142137\n",
      "\tspeed: 0.0739s/iter; left time: 6784.2909s\n",
      "\titers: 400, epoch: 14 | loss: 0.3612573\n",
      "\tspeed: 0.0730s/iter; left time: 6696.5697s\n",
      "\titers: 500, epoch: 14 | loss: 0.2293673\n",
      "\tspeed: 0.0822s/iter; left time: 7531.3951s\n",
      "\titers: 600, epoch: 14 | loss: 0.3471519\n",
      "\tspeed: 0.0780s/iter; left time: 7136.7470s\n",
      "\titers: 700, epoch: 14 | loss: 0.4222451\n",
      "\tspeed: 0.0791s/iter; left time: 7234.8000s\n",
      "\titers: 800, epoch: 14 | loss: 0.2809289\n",
      "\tspeed: 0.0789s/iter; left time: 7202.9210s\n",
      "\titers: 900, epoch: 14 | loss: 0.2726845\n",
      "\tspeed: 0.0869s/iter; left time: 7930.6430s\n",
      "\titers: 1000, epoch: 14 | loss: 0.4738874\n",
      "\tspeed: 0.0831s/iter; left time: 7575.5044s\n",
      "Epoch: 14 cost time: 82.8972396850586\n",
      "Epoch: 14, Steps: 1059 | Train Loss: 0.3787329 Vali Loss: 0.2578463 Test Loss: 0.3741827\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Updating learning rate to 0.0023492418369532235\n",
      "\titers: 100, epoch: 15 | loss: 0.3047683\n",
      "\tspeed: 0.5621s/iter; left time: 51134.2591s\n",
      "\titers: 200, epoch: 15 | loss: 0.3393832\n",
      "\tspeed: 0.0799s/iter; left time: 7257.9709s\n",
      "\titers: 300, epoch: 15 | loss: 0.4812902\n",
      "\tspeed: 0.0899s/iter; left time: 8164.1427s\n",
      "\titers: 400, epoch: 15 | loss: 0.3114836\n",
      "\tspeed: 0.0851s/iter; left time: 7712.5161s\n",
      "\titers: 500, epoch: 15 | loss: 0.2607006\n",
      "\tspeed: 0.0789s/iter; left time: 7144.5394s\n",
      "\titers: 600, epoch: 15 | loss: 0.4652574\n",
      "\tspeed: 0.0872s/iter; left time: 7884.9497s\n",
      "\titers: 700, epoch: 15 | loss: 0.2364174\n",
      "\tspeed: 0.0840s/iter; left time: 7594.0172s\n",
      "\titers: 800, epoch: 15 | loss: 0.2737934\n",
      "\tspeed: 0.0788s/iter; left time: 7114.8810s\n",
      "\titers: 900, epoch: 15 | loss: 0.3313393\n",
      "\tspeed: 0.0751s/iter; left time: 6770.8009s\n",
      "\titers: 1000, epoch: 15 | loss: 0.3648170\n",
      "\tspeed: 0.0811s/iter; left time: 7301.5939s\n",
      "Epoch: 15 cost time: 88.49126768112183\n",
      "Epoch: 15, Steps: 1059 | Train Loss: 0.3696250 Vali Loss: 0.2565551 Test Loss: 0.3446040\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Updating learning rate to 0.0026001186663471548\n",
      "\titers: 100, epoch: 16 | loss: 0.5866277\n",
      "\tspeed: 0.5769s/iter; left time: 51868.3207s\n",
      "\titers: 200, epoch: 16 | loss: 0.2500032\n",
      "\tspeed: 0.0812s/iter; left time: 7289.3337s\n",
      "\titers: 300, epoch: 16 | loss: 0.2529336\n",
      "\tspeed: 0.0749s/iter; left time: 6719.6371s\n",
      "\titers: 400, epoch: 16 | loss: 0.2318962\n",
      "\tspeed: 0.0820s/iter; left time: 7348.9195s\n",
      "\titers: 500, epoch: 16 | loss: 0.3721711\n",
      "\tspeed: 0.0801s/iter; left time: 7173.2125s\n",
      "\titers: 600, epoch: 16 | loss: 0.6023726\n",
      "\tspeed: 0.0788s/iter; left time: 7049.2128s\n",
      "\titers: 700, epoch: 16 | loss: 0.5787463\n",
      "\tspeed: 0.0730s/iter; left time: 6516.8868s\n",
      "\titers: 800, epoch: 16 | loss: 0.5143262\n",
      "\tspeed: 0.0831s/iter; left time: 7411.1792s\n",
      "\titers: 900, epoch: 16 | loss: 0.4485917\n",
      "\tspeed: 0.0820s/iter; left time: 7307.5762s\n",
      "\titers: 1000, epoch: 16 | loss: 0.5941263\n",
      "\tspeed: 0.0869s/iter; left time: 7738.1809s\n",
      "Epoch: 16 cost time: 84.6911551952362\n",
      "Epoch: 16, Steps: 1059 | Train Loss: 0.4001597 Vali Loss: 0.2645169 Test Loss: 0.3596774\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Updating learning rate to 0.002850994195525979\n",
      "\titers: 100, epoch: 17 | loss: 0.4634283\n",
      "\tspeed: 0.5690s/iter; left time: 50560.2949s\n",
      "\titers: 200, epoch: 17 | loss: 0.4142852\n",
      "\tspeed: 0.0822s/iter; left time: 7291.9377s\n",
      "\titers: 300, epoch: 17 | loss: 0.4975849\n",
      "\tspeed: 0.0749s/iter; left time: 6640.7116s\n",
      "\titers: 400, epoch: 17 | loss: 0.3022008\n",
      "\tspeed: 0.0741s/iter; left time: 6563.6210s\n",
      "\titers: 500, epoch: 17 | loss: 0.3478420\n",
      "\tspeed: 0.0809s/iter; left time: 7153.8872s\n",
      "\titers: 600, epoch: 17 | loss: 0.4278312\n",
      "\tspeed: 0.0792s/iter; left time: 6998.2526s\n",
      "\titers: 700, epoch: 17 | loss: 0.3135591\n",
      "\tspeed: 0.0808s/iter; left time: 7131.1666s\n",
      "\titers: 800, epoch: 17 | loss: 0.4661202\n",
      "\tspeed: 0.0832s/iter; left time: 7332.7259s\n",
      "\titers: 900, epoch: 17 | loss: 0.4247773\n",
      "\tspeed: 0.0768s/iter; left time: 6764.6560s\n",
      "\titers: 1000, epoch: 17 | loss: 0.4242018\n",
      "\tspeed: 0.0840s/iter; left time: 7391.3305s\n",
      "Epoch: 17 cost time: 85.7157301902771\n",
      "Epoch: 17, Steps: 1059 | Train Loss: 0.3830238 Vali Loss: 0.2561834 Test Loss: 0.3438164\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Updating learning rate to 0.0030991196068089547\n",
      "\titers: 100, epoch: 18 | loss: 0.5043335\n",
      "\tspeed: 0.6159s/iter; left time: 54075.6926s\n",
      "\titers: 200, epoch: 18 | loss: 0.4410506\n",
      "\tspeed: 0.0822s/iter; left time: 7210.6955s\n",
      "\titers: 300, epoch: 18 | loss: 0.3823005\n",
      "\tspeed: 0.0809s/iter; left time: 7085.6289s\n",
      "\titers: 400, epoch: 18 | loss: 0.5482053\n",
      "\tspeed: 0.0789s/iter; left time: 6907.3152s\n",
      "\titers: 500, epoch: 18 | loss: 0.3549235\n",
      "\tspeed: 0.0909s/iter; left time: 7947.9265s\n",
      "\titers: 600, epoch: 18 | loss: 0.2908378\n",
      "\tspeed: 0.0882s/iter; left time: 7696.0963s\n",
      "\titers: 700, epoch: 18 | loss: 0.4140699\n",
      "\tspeed: 0.0779s/iter; left time: 6791.5256s\n",
      "\titers: 800, epoch: 18 | loss: 0.2665312\n",
      "\tspeed: 0.0840s/iter; left time: 7317.0876s\n",
      "\titers: 900, epoch: 18 | loss: 0.3044877\n",
      "\tspeed: 0.0901s/iter; left time: 7834.5554s\n",
      "\titers: 1000, epoch: 18 | loss: 0.4181105\n",
      "\tspeed: 0.0830s/iter; left time: 7208.4529s\n",
      "Epoch: 18 cost time: 89.20706057548523\n",
      "Epoch: 18, Steps: 1059 | Train Loss: 0.3745147 Vali Loss: 0.2837009 Test Loss: 0.3608643\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Updating learning rate to 0.0033417762152776753\n",
      "\titers: 100, epoch: 19 | loss: 0.5691792\n",
      "\tspeed: 0.5920s/iter; left time: 51349.8878s\n",
      "\titers: 200, epoch: 19 | loss: 0.4711328\n",
      "\tspeed: 0.0820s/iter; left time: 7103.9273s\n",
      "\titers: 300, epoch: 19 | loss: 0.6101173\n",
      "\tspeed: 0.0772s/iter; left time: 6680.3074s\n",
      "\titers: 400, epoch: 19 | loss: 0.3116964\n",
      "\tspeed: 0.0730s/iter; left time: 6311.5178s\n",
      "\titers: 500, epoch: 19 | loss: 0.3088861\n",
      "\tspeed: 0.0720s/iter; left time: 6214.8617s\n",
      "\titers: 600, epoch: 19 | loss: 0.3855740\n",
      "\tspeed: 0.0787s/iter; left time: 6790.6797s\n",
      "\titers: 700, epoch: 19 | loss: 0.3952381\n",
      "\tspeed: 0.0822s/iter; left time: 7084.4991s\n",
      "\titers: 800, epoch: 19 | loss: 0.6109670\n",
      "\tspeed: 0.0820s/iter; left time: 7058.1269s\n",
      "\titers: 900, epoch: 19 | loss: 0.7506006\n",
      "\tspeed: 0.0838s/iter; left time: 7200.2688s\n",
      "\titers: 1000, epoch: 19 | loss: 0.3725430\n",
      "\tspeed: 0.0791s/iter; left time: 6791.6420s\n",
      "Epoch: 19 cost time: 85.09944200515747\n",
      "Epoch: 19, Steps: 1059 | Train Loss: 0.3788513 Vali Loss: 0.2862954 Test Loss: 0.5392683\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Updating learning rate to 0.0035763052571304655\n",
      "\titers: 100, epoch: 20 | loss: 0.2213628\n",
      "\tspeed: 0.5299s/iter; left time: 45400.2125s\n",
      "\titers: 200, epoch: 20 | loss: 0.6177810\n",
      "\tspeed: 0.0770s/iter; left time: 6593.5245s\n",
      "\titers: 300, epoch: 20 | loss: 0.3821143\n",
      "\tspeed: 0.0811s/iter; left time: 6931.3141s\n",
      "\titers: 400, epoch: 20 | loss: 0.2991962\n",
      "\tspeed: 0.0739s/iter; left time: 6310.1761s\n",
      "\titers: 500, epoch: 20 | loss: 0.6369640\n",
      "\tspeed: 0.0850s/iter; left time: 7245.4783s\n",
      "\titers: 600, epoch: 20 | loss: 0.2579190\n",
      "\tspeed: 0.0810s/iter; left time: 6899.2270s\n",
      "\titers: 700, epoch: 20 | loss: 0.5152680\n",
      "\tspeed: 0.0860s/iter; left time: 7317.2020s\n",
      "\titers: 800, epoch: 20 | loss: 0.4401860\n",
      "\tspeed: 0.0871s/iter; left time: 7401.8101s\n",
      "\titers: 900, epoch: 20 | loss: 0.4630665\n",
      "\tspeed: 0.0808s/iter; left time: 6861.2863s\n",
      "\titers: 1000, epoch: 20 | loss: 0.3205886\n",
      "\tspeed: 0.0870s/iter; left time: 7375.9029s\n",
      "Epoch: 20 cost time: 85.92198371887207\n",
      "Epoch: 20, Steps: 1059 | Train Loss: 0.3744905 Vali Loss: 0.2563412 Test Loss: 0.3702399\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Updating learning rate to 0.0038001370214871813\n",
      "\titers: 100, epoch: 21 | loss: 0.3137132\n",
      "\tspeed: 0.5482s/iter; left time: 46393.1669s\n",
      "\titers: 200, epoch: 21 | loss: 0.2976525\n",
      "\tspeed: 0.0839s/iter; left time: 7090.2782s\n",
      "\titers: 300, epoch: 21 | loss: 0.3826657\n",
      "\tspeed: 0.0900s/iter; left time: 7598.7581s\n",
      "\titers: 400, epoch: 21 | loss: 0.2372934\n",
      "\tspeed: 0.0850s/iter; left time: 7169.2081s\n",
      "\titers: 500, epoch: 21 | loss: 0.2952076\n",
      "\tspeed: 0.0721s/iter; left time: 6071.0607s\n",
      "\titers: 600, epoch: 21 | loss: 0.3766428\n",
      "\tspeed: 0.0800s/iter; left time: 6727.2939s\n",
      "\titers: 700, epoch: 21 | loss: 0.4891574\n",
      "\tspeed: 0.0830s/iter; left time: 6973.8920s\n",
      "\titers: 800, epoch: 21 | loss: 0.3243622\n",
      "\tspeed: 0.0860s/iter; left time: 7216.1111s\n",
      "\titers: 900, epoch: 21 | loss: 0.2273216\n",
      "\tspeed: 0.0841s/iter; left time: 7045.7284s\n",
      "\titers: 1000, epoch: 21 | loss: 0.3565981\n",
      "\tspeed: 0.0927s/iter; left time: 7763.8511s\n",
      "Epoch: 21 cost time: 88.50495767593384\n",
      "Epoch: 21, Steps: 1059 | Train Loss: 0.3820288 Vali Loss: 0.2672234 Test Loss: 0.3497247\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): PatchTST_backbone(\n",
       "    (backbone): TSTiEncoder(\n",
       "      (W_P): Linear(in_features=16, out_features=128, bias=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (encoder): TSTEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-2): 3 x TSTEncoderLayer(\n",
       "            (self_attn): _MultiheadAttention(\n",
       "              (W_Q): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (W_K): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (W_V): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (sdp_attn): _ScaledDotProductAttention(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (dropout_attn): Dropout(p=0.2, inplace=False)\n",
       "            (norm_attn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.2, inplace=False)\n",
       "              (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "            )\n",
       "            (dropout_ffn): Dropout(p=0.2, inplace=False)\n",
       "            (norm_ffn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): Flatten_Head(\n",
       "      (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "      (linear): Linear(in_features=5248, out_features=336, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exp = Exp_Main\n",
    "setting=f'PatchTST_train_on_{args.data}_{args.pred_len}'\n",
    "# set experiments\n",
    "exp = Exp(args)\n",
    "exp.train(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f68b6c5",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "19d7ca95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 11185\n",
      "mse:0.29942047595977783, mae:0.35299360752105713, rse:0.44180169701576233\n"
     ]
    }
   ],
   "source": [
    "exp.test(setting)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a632fbf",
   "metadata": {},
   "source": [
    "---\n",
    "## Trail 4: PatchTST, Dataset:ETTm1,  Metric: 720\n",
    "\n",
    "### Set hyperparameters\n",
    "Set some parameters (Args) for the our experiment like dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d639a92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ETTm2,  Prediction Length : 720\n"
     ]
    }
   ],
   "source": [
    "args.pred_len = 720 # prediction sequence length\n",
    "print(f\"Dataset: {args.data},  Prediction Length : {args.pred_len}\") \n",
    "# print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aafca5",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "03470ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "train 33505\n",
      "val 10801\n",
      "test 10801\n",
      "\titers: 100, epoch: 1 | loss: 0.5727623\n",
      "\tspeed: 0.0841s/iter; left time: 8800.4818s\n",
      "\titers: 200, epoch: 1 | loss: 0.3959309\n",
      "\tspeed: 0.0908s/iter; left time: 9492.0281s\n",
      "\titers: 300, epoch: 1 | loss: 0.4451066\n",
      "\tspeed: 0.0772s/iter; left time: 8059.9810s\n",
      "\titers: 400, epoch: 1 | loss: 0.4637458\n",
      "\tspeed: 0.0878s/iter; left time: 9161.6836s\n",
      "\titers: 500, epoch: 1 | loss: 0.6901796\n",
      "\tspeed: 0.0839s/iter; left time: 8742.3562s\n",
      "\titers: 600, epoch: 1 | loss: 0.6514398\n",
      "\tspeed: 0.0910s/iter; left time: 9474.4076s\n",
      "\titers: 700, epoch: 1 | loss: 0.6205701\n",
      "\tspeed: 0.0861s/iter; left time: 8955.4781s\n",
      "\titers: 800, epoch: 1 | loss: 0.3094168\n",
      "\tspeed: 0.0850s/iter; left time: 8828.5576s\n",
      "\titers: 900, epoch: 1 | loss: 0.3135817\n",
      "\tspeed: 0.0810s/iter; left time: 8404.1996s\n",
      "\titers: 1000, epoch: 1 | loss: 0.2895051\n",
      "\tspeed: 0.0860s/iter; left time: 8919.2385s\n",
      "Epoch: 1 cost time: 89.50925374031067\n",
      "Epoch: 1, Steps: 1047 | Train Loss: 0.5030201 Vali Loss: 0.3659404 Test Loss: 0.6324620\n",
      "Validation loss decreased (inf --> 0.365940).  Saving model ...\n",
      "Updating learning rate to 0.00021314828754152686\n",
      "\titers: 100, epoch: 2 | loss: 0.6024516\n",
      "\tspeed: 0.6780s/iter; left time: 70210.8874s\n",
      "\titers: 200, epoch: 2 | loss: 0.5198910\n",
      "\tspeed: 0.0851s/iter; left time: 8799.5546s\n",
      "\titers: 300, epoch: 2 | loss: 0.4007424\n",
      "\tspeed: 0.0909s/iter; left time: 9391.1029s\n",
      "\titers: 400, epoch: 2 | loss: 0.6356310\n",
      "\tspeed: 0.0851s/iter; left time: 8782.4795s\n",
      "\titers: 500, epoch: 2 | loss: 0.4372536\n",
      "\tspeed: 0.1022s/iter; left time: 10538.5652s\n",
      "\titers: 600, epoch: 2 | loss: 0.5160304\n",
      "\tspeed: 0.0840s/iter; left time: 8658.0039s\n",
      "\titers: 700, epoch: 2 | loss: 0.3453483\n",
      "\tspeed: 0.0938s/iter; left time: 9656.8256s\n",
      "\titers: 800, epoch: 2 | loss: 0.3573263\n",
      "\tspeed: 0.0812s/iter; left time: 8349.6188s\n",
      "\titers: 900, epoch: 2 | loss: 0.2759623\n",
      "\tspeed: 0.0778s/iter; left time: 7997.6892s\n",
      "\titers: 1000, epoch: 2 | loss: 0.4232332\n",
      "\tspeed: 0.0800s/iter; left time: 8207.3487s\n",
      "Epoch: 2 cost time: 90.32624220848083\n",
      "Epoch: 2, Steps: 1047 | Train Loss: 0.4468830 Vali Loss: 0.4229331 Test Loss: 0.8184609\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Updating learning rate to 0.00025244908561171224\n",
      "\titers: 100, epoch: 3 | loss: 0.4077955\n",
      "\tspeed: 0.6871s/iter; left time: 70435.8933s\n",
      "\titers: 200, epoch: 3 | loss: 0.3926370\n",
      "\tspeed: 0.0831s/iter; left time: 8509.1942s\n",
      "\titers: 300, epoch: 3 | loss: 0.5944671\n",
      "\tspeed: 0.0949s/iter; left time: 9712.5155s\n",
      "\titers: 400, epoch: 3 | loss: 0.4706616\n",
      "\tspeed: 0.0889s/iter; left time: 9086.9963s\n",
      "\titers: 500, epoch: 3 | loss: 0.4916405\n",
      "\tspeed: 0.0839s/iter; left time: 8570.2615s\n",
      "\titers: 600, epoch: 3 | loss: 0.3997899\n",
      "\tspeed: 0.0811s/iter; left time: 8273.0237s\n",
      "\titers: 700, epoch: 3 | loss: 0.4241509\n",
      "\tspeed: 0.0811s/iter; left time: 8263.6036s\n",
      "\titers: 800, epoch: 3 | loss: 0.3032883\n",
      "\tspeed: 0.0840s/iter; left time: 8555.1795s\n",
      "\titers: 900, epoch: 3 | loss: 0.4069796\n",
      "\tspeed: 0.0878s/iter; left time: 8934.8601s\n",
      "\titers: 1000, epoch: 3 | loss: 0.3677536\n",
      "\tspeed: 0.0871s/iter; left time: 8848.8966s\n",
      "Epoch: 3 cost time: 89.89698076248169\n",
      "Epoch: 3, Steps: 1047 | Train Loss: 0.4096870 Vali Loss: 0.3301034 Test Loss: 0.4749093\n",
      "Validation loss decreased (0.365940 --> 0.330103).  Saving model ...\n",
      "Updating learning rate to 0.00031747177904919207\n",
      "\titers: 100, epoch: 4 | loss: 0.2454139\n",
      "\tspeed: 0.6089s/iter; left time: 61778.8028s\n",
      "\titers: 200, epoch: 4 | loss: 0.4302333\n",
      "\tspeed: 0.0910s/iter; left time: 9223.5390s\n",
      "\titers: 300, epoch: 4 | loss: 0.4575485\n",
      "\tspeed: 0.0920s/iter; left time: 9315.9302s\n",
      "\titers: 400, epoch: 4 | loss: 0.3652599\n",
      "\tspeed: 0.0970s/iter; left time: 9809.0214s\n",
      "\titers: 500, epoch: 4 | loss: 0.3397553\n",
      "\tspeed: 0.0832s/iter; left time: 8407.8580s\n",
      "\titers: 600, epoch: 4 | loss: 0.2419828\n",
      "\tspeed: 0.0748s/iter; left time: 7556.6340s\n",
      "\titers: 700, epoch: 4 | loss: 0.3122914\n",
      "\tspeed: 0.0890s/iter; left time: 8980.8305s\n",
      "\titers: 800, epoch: 4 | loss: 0.3015200\n",
      "\tspeed: 0.0781s/iter; left time: 7866.0802s\n",
      "\titers: 900, epoch: 4 | loss: 0.5041518\n",
      "\tspeed: 0.0849s/iter; left time: 8544.0706s\n",
      "\titers: 1000, epoch: 4 | loss: 0.4221726\n",
      "\tspeed: 0.0760s/iter; left time: 7642.6831s\n",
      "Epoch: 4 cost time: 89.04255843162537\n",
      "Epoch: 4, Steps: 1047 | Train Loss: 0.3854151 Vali Loss: 0.3182993 Test Loss: 0.4332471\n",
      "Validation loss decreased (0.330103 --> 0.318299).  Saving model ...\n",
      "Updating learning rate to 0.00040750392029559844\n",
      "\titers: 100, epoch: 5 | loss: 0.4892164\n",
      "\tspeed: 0.7262s/iter; left time: 72916.3440s\n",
      "\titers: 200, epoch: 5 | loss: 0.5817896\n",
      "\tspeed: 0.0850s/iter; left time: 8527.1438s\n",
      "\titers: 300, epoch: 5 | loss: 0.2955339\n",
      "\tspeed: 0.0800s/iter; left time: 8016.0709s\n",
      "\titers: 400, epoch: 5 | loss: 0.3056167\n",
      "\tspeed: 0.0850s/iter; left time: 8511.3479s\n",
      "\titers: 500, epoch: 5 | loss: 0.3822889\n",
      "\tspeed: 0.0838s/iter; left time: 8382.3309s\n",
      "\titers: 600, epoch: 5 | loss: 0.3821335\n",
      "\tspeed: 0.0830s/iter; left time: 8293.7351s\n",
      "\titers: 700, epoch: 5 | loss: 0.2348769\n",
      "\tspeed: 0.0889s/iter; left time: 8876.9066s\n",
      "\titers: 800, epoch: 5 | loss: 0.2164531\n",
      "\tspeed: 0.0792s/iter; left time: 7899.8039s\n",
      "\titers: 900, epoch: 5 | loss: 0.3196470\n",
      "\tspeed: 0.0900s/iter; left time: 8963.5588s\n",
      "\titers: 1000, epoch: 5 | loss: 0.3590310\n",
      "\tspeed: 0.0790s/iter; left time: 7863.9360s\n",
      "Epoch: 5 cost time: 88.1394910812378\n",
      "Epoch: 5, Steps: 1047 | Train Loss: 0.3648998 Vali Loss: 0.3656868 Test Loss: 0.5467814\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Updating learning rate to 0.0005215590356166906\n",
      "\titers: 100, epoch: 6 | loss: 0.3528166\n",
      "\tspeed: 0.6520s/iter; left time: 64784.0083s\n",
      "\titers: 200, epoch: 6 | loss: 0.3898734\n",
      "\tspeed: 0.0910s/iter; left time: 9034.8086s\n",
      "\titers: 300, epoch: 6 | loss: 0.2527631\n",
      "\tspeed: 0.0858s/iter; left time: 8506.1087s\n",
      "\titers: 400, epoch: 6 | loss: 0.3516999\n",
      "\tspeed: 0.0822s/iter; left time: 8142.2824s\n",
      "\titers: 500, epoch: 6 | loss: 0.4205886\n",
      "\tspeed: 0.0899s/iter; left time: 8894.3675s\n",
      "\titers: 600, epoch: 6 | loss: 0.3673335\n",
      "\tspeed: 0.0920s/iter; left time: 9095.1938s\n",
      "\titers: 700, epoch: 6 | loss: 0.2535410\n",
      "\tspeed: 0.0910s/iter; left time: 8988.6247s\n",
      "\titers: 800, epoch: 6 | loss: 0.2914156\n",
      "\tspeed: 0.0830s/iter; left time: 8190.6931s\n",
      "\titers: 900, epoch: 6 | loss: 0.2851585\n",
      "\tspeed: 0.0911s/iter; left time: 8980.6566s\n",
      "\titers: 1000, epoch: 6 | loss: 0.3002209\n",
      "\tspeed: 0.0859s/iter; left time: 8454.8654s\n",
      "Epoch: 6 cost time: 91.50483560562134\n",
      "Epoch: 6, Steps: 1047 | Train Loss: 0.3392912 Vali Loss: 0.3687264 Test Loss: 0.5286897\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Updating learning rate to 0.0006583874338026178\n",
      "\titers: 100, epoch: 7 | loss: 0.3098263\n",
      "\tspeed: 0.8040s/iter; left time: 79052.7049s\n",
      "\titers: 200, epoch: 7 | loss: 0.3026689\n",
      "\tspeed: 0.0860s/iter; left time: 8443.7543s\n",
      "\titers: 300, epoch: 7 | loss: 0.4062686\n",
      "\tspeed: 0.0830s/iter; left time: 8143.2418s\n",
      "\titers: 400, epoch: 7 | loss: 0.2945237\n",
      "\tspeed: 0.0811s/iter; left time: 7949.1742s\n",
      "\titers: 500, epoch: 7 | loss: 0.2522735\n",
      "\tspeed: 0.0859s/iter; left time: 8415.3116s\n",
      "\titers: 600, epoch: 7 | loss: 0.3692832\n",
      "\tspeed: 0.1060s/iter; left time: 10369.9835s\n",
      "\titers: 700, epoch: 7 | loss: 0.4139069\n",
      "\tspeed: 0.0962s/iter; left time: 9404.0328s\n",
      "\titers: 800, epoch: 7 | loss: 0.3158358\n",
      "\tspeed: 0.0959s/iter; left time: 9358.8156s\n",
      "\titers: 900, epoch: 7 | loss: 0.3822815\n",
      "\tspeed: 0.0948s/iter; left time: 9247.9786s\n",
      "\titers: 1000, epoch: 7 | loss: 0.2521721\n",
      "\tspeed: 0.1052s/iter; left time: 10246.1127s\n",
      "Epoch: 7 cost time: 96.69909954071045\n",
      "Epoch: 7, Steps: 1047 | Train Loss: 0.3161507 Vali Loss: 0.3982590 Test Loss: 0.6160612\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Updating learning rate to 0.0008164898989173816\n",
      "\titers: 100, epoch: 8 | loss: 0.2982109\n",
      "\tspeed: 1.6209s/iter; left time: 157673.0113s\n",
      "\titers: 200, epoch: 8 | loss: 0.2341566\n",
      "\tspeed: 0.1061s/iter; left time: 10312.2631s\n",
      "\titers: 300, epoch: 8 | loss: 0.3750539\n",
      "\tspeed: 0.0988s/iter; left time: 9595.0363s\n",
      "\titers: 400, epoch: 8 | loss: 0.2430131\n",
      "\tspeed: 0.0970s/iter; left time: 9404.9847s\n",
      "\titers: 500, epoch: 8 | loss: 0.2111243\n",
      "\tspeed: 0.1041s/iter; left time: 10087.3011s\n",
      "\titers: 600, epoch: 8 | loss: 0.2234830\n",
      "\tspeed: 0.1057s/iter; left time: 10231.9769s\n",
      "\titers: 700, epoch: 8 | loss: 0.3587863\n",
      "\tspeed: 0.0910s/iter; left time: 8797.1037s\n",
      "\titers: 800, epoch: 8 | loss: 0.2909471\n",
      "\tspeed: 0.1072s/iter; left time: 10350.5118s\n",
      "\titers: 900, epoch: 8 | loss: 0.2508832\n",
      "\tspeed: 0.1021s/iter; left time: 9845.9743s\n",
      "\titers: 1000, epoch: 8 | loss: 0.2069986\n",
      "\tspeed: 0.1090s/iter; left time: 10503.4337s\n",
      "Epoch: 8 cost time: 108.39809250831604\n",
      "Epoch: 8, Steps: 1047 | Train Loss: 0.2934728 Vali Loss: 0.3804089 Test Loss: 0.5666999\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Updating learning rate to 0.0009941341170673574\n",
      "\titers: 100, epoch: 9 | loss: 0.2922932\n",
      "\tspeed: 1.6650s/iter; left time: 160213.6197s\n",
      "\titers: 200, epoch: 9 | loss: 0.5379821\n",
      "\tspeed: 0.1008s/iter; left time: 9687.5832s\n",
      "\titers: 300, epoch: 9 | loss: 0.3681124\n",
      "\tspeed: 0.0942s/iter; left time: 9047.9182s\n",
      "\titers: 400, epoch: 9 | loss: 0.3019423\n",
      "\tspeed: 0.1029s/iter; left time: 9872.7762s\n",
      "\titers: 500, epoch: 9 | loss: 0.3359388\n",
      "\tspeed: 0.1000s/iter; left time: 9580.9914s\n",
      "\titers: 600, epoch: 9 | loss: 0.3286778\n",
      "\tspeed: 0.0951s/iter; left time: 9103.0896s\n",
      "\titers: 700, epoch: 9 | loss: 0.2705097\n",
      "\tspeed: 0.1060s/iter; left time: 10133.7026s\n",
      "\titers: 800, epoch: 9 | loss: 0.2373617\n",
      "\tspeed: 0.1018s/iter; left time: 9724.7682s\n",
      "\titers: 900, epoch: 9 | loss: 0.2198608\n",
      "\tspeed: 0.1031s/iter; left time: 9840.6123s\n",
      "\titers: 1000, epoch: 9 | loss: 0.2025104\n",
      "\tspeed: 0.0990s/iter; left time: 9434.0885s\n",
      "Epoch: 9 cost time: 104.52755284309387\n",
      "Epoch: 9, Steps: 1047 | Train Loss: 0.2825523 Vali Loss: 0.3866888 Test Loss: 0.5620360\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Updating learning rate to 0.0011893736572022714\n",
      "\titers: 100, epoch: 10 | loss: 0.2995658\n",
      "\tspeed: 1.5809s/iter; left time: 150467.6925s\n",
      "\titers: 200, epoch: 10 | loss: 0.2623810\n",
      "\tspeed: 0.0935s/iter; left time: 8885.9366s\n",
      "\titers: 300, epoch: 10 | loss: 0.2736113\n",
      "\tspeed: 0.1028s/iter; left time: 9767.1966s\n",
      "\titers: 400, epoch: 10 | loss: 0.2929876\n",
      "\tspeed: 0.0987s/iter; left time: 9364.2239s\n",
      "\titers: 500, epoch: 10 | loss: 0.2236423\n",
      "\tspeed: 0.0834s/iter; left time: 7907.3122s\n",
      "\titers: 600, epoch: 10 | loss: 0.2001512\n",
      "\tspeed: 0.0937s/iter; left time: 8872.6348s\n",
      "\titers: 700, epoch: 10 | loss: 0.3477477\n",
      "\tspeed: 0.0991s/iter; left time: 9376.4314s\n",
      "\titers: 800, epoch: 10 | loss: 0.3504718\n",
      "\tspeed: 0.1049s/iter; left time: 9913.5297s\n",
      "\titers: 900, epoch: 10 | loss: 0.2546217\n",
      "\tspeed: 0.1068s/iter; left time: 10078.4015s\n",
      "\titers: 1000, epoch: 10 | loss: 0.3038741\n",
      "\tspeed: 0.1092s/iter; left time: 10292.5901s\n",
      "Epoch: 10 cost time: 102.9073576927185\n",
      "Epoch: 10, Steps: 1047 | Train Loss: 0.2776656 Vali Loss: 0.3943429 Test Loss: 0.5309609\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Updating learning rate to 0.0014000692979778168\n",
      "\titers: 100, epoch: 11 | loss: 0.2042207\n",
      "\tspeed: 1.5883s/iter; left time: 149506.8509s\n",
      "\titers: 200, epoch: 11 | loss: 0.2213015\n",
      "\tspeed: 0.0928s/iter; left time: 8723.3042s\n",
      "\titers: 300, epoch: 11 | loss: 0.2251744\n",
      "\tspeed: 0.0990s/iter; left time: 9295.2471s\n",
      "\titers: 400, epoch: 11 | loss: 0.2981899\n",
      "\tspeed: 0.0959s/iter; left time: 8999.9355s\n",
      "\titers: 500, epoch: 11 | loss: 0.3002785\n",
      "\tspeed: 0.1092s/iter; left time: 10231.9206s\n",
      "\titers: 600, epoch: 11 | loss: 0.2769928\n",
      "\tspeed: 0.0979s/iter; left time: 9165.7168s\n",
      "\titers: 700, epoch: 11 | loss: 0.2481456\n",
      "\tspeed: 0.0960s/iter; left time: 8975.7405s\n",
      "\titers: 800, epoch: 11 | loss: 0.4286927\n",
      "\tspeed: 0.0930s/iter; left time: 8684.5289s\n",
      "\titers: 900, epoch: 11 | loss: 0.4327002\n",
      "\tspeed: 0.1012s/iter; left time: 9444.6405s\n",
      "\titers: 1000, epoch: 11 | loss: 0.2378519\n",
      "\tspeed: 0.0971s/iter; left time: 9049.9781s\n",
      "Epoch: 11 cost time: 103.69055199623108\n",
      "Epoch: 11, Steps: 1047 | Train Loss: 0.2825620 Vali Loss: 0.4051983 Test Loss: 0.5048028\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Updating learning rate to 0.0016239124670034398\n",
      "\titers: 100, epoch: 12 | loss: 0.3062634\n",
      "\tspeed: 1.4768s/iter; left time: 137471.0527s\n",
      "\titers: 200, epoch: 12 | loss: 0.2078788\n",
      "\tspeed: 0.0911s/iter; left time: 8473.1082s\n",
      "\titers: 300, epoch: 12 | loss: 0.2940844\n",
      "\tspeed: 0.0927s/iter; left time: 8608.6726s\n",
      "\titers: 400, epoch: 12 | loss: 0.2408867\n",
      "\tspeed: 0.1062s/iter; left time: 9856.0611s\n",
      "\titers: 500, epoch: 12 | loss: 0.2957436\n",
      "\tspeed: 0.0948s/iter; left time: 8784.2659s\n",
      "\titers: 600, epoch: 12 | loss: 0.3687497\n",
      "\tspeed: 0.1052s/iter; left time: 9742.9298s\n",
      "\titers: 700, epoch: 12 | loss: 0.2761080\n",
      "\tspeed: 0.1039s/iter; left time: 9610.0641s\n",
      "\titers: 800, epoch: 12 | loss: 0.2130084\n",
      "\tspeed: 0.0919s/iter; left time: 8490.1383s\n",
      "\titers: 900, epoch: 12 | loss: 0.2850111\n",
      "\tspeed: 0.0893s/iter; left time: 8237.8838s\n",
      "\titers: 1000, epoch: 12 | loss: 0.2493996\n",
      "\tspeed: 0.0878s/iter; left time: 8089.8740s\n",
      "Epoch: 12 cost time: 100.9911413192749\n",
      "Epoch: 12, Steps: 1047 | Train Loss: 0.2843526 Vali Loss: 0.3771557 Test Loss: 0.4528027\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Updating learning rate to 0.0018584505356536792\n",
      "\titers: 100, epoch: 13 | loss: 0.2929486\n",
      "\tspeed: 1.4599s/iter; left time: 134367.7155s\n",
      "\titers: 200, epoch: 13 | loss: 0.4871186\n",
      "\tspeed: 0.0972s/iter; left time: 8938.9605s\n",
      "\titers: 300, epoch: 13 | loss: 0.3118544\n",
      "\tspeed: 0.1059s/iter; left time: 9726.8780s\n",
      "\titers: 400, epoch: 13 | loss: 0.2474070\n",
      "\tspeed: 0.1060s/iter; left time: 9724.0941s\n",
      "\titers: 500, epoch: 13 | loss: 0.4182213\n",
      "\tspeed: 0.0909s/iter; left time: 8325.7672s\n",
      "\titers: 600, epoch: 13 | loss: 0.4205710\n",
      "\tspeed: 0.1030s/iter; left time: 9427.9683s\n",
      "\titers: 700, epoch: 13 | loss: 0.6747372\n",
      "\tspeed: 0.0933s/iter; left time: 8529.7435s\n",
      "\titers: 800, epoch: 13 | loss: 0.3788764\n",
      "\tspeed: 0.0947s/iter; left time: 8651.6226s\n",
      "\titers: 900, epoch: 13 | loss: 0.3160067\n",
      "\tspeed: 0.0971s/iter; left time: 8861.0668s\n",
      "\titers: 1000, epoch: 13 | loss: 0.3000460\n",
      "\tspeed: 0.0981s/iter; left time: 8944.2164s\n",
      "Epoch: 13 cost time: 103.09919738769531\n",
      "Epoch: 13, Steps: 1047 | Train Loss: 0.3752990 Vali Loss: 0.3401677 Test Loss: 0.4578810\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Updating learning rate to 0.0021011136922901613\n",
      "\titers: 100, epoch: 14 | loss: 0.2826489\n",
      "\tspeed: 1.4269s/iter; left time: 129832.1526s\n",
      "\titers: 200, epoch: 14 | loss: 0.3938650\n",
      "\tspeed: 0.0979s/iter; left time: 8897.1290s\n",
      "\titers: 300, epoch: 14 | loss: 0.4374208\n",
      "\tspeed: 0.0940s/iter; left time: 8530.5316s\n",
      "\titers: 400, epoch: 14 | loss: 0.4700328\n",
      "\tspeed: 0.1052s/iter; left time: 9536.3282s\n",
      "\titers: 500, epoch: 14 | loss: 0.3462920\n",
      "\tspeed: 0.0951s/iter; left time: 8612.8602s\n",
      "\titers: 600, epoch: 14 | loss: 0.2830606\n",
      "\tspeed: 0.0868s/iter; left time: 7851.8536s\n",
      "\titers: 700, epoch: 14 | loss: 0.4653580\n",
      "\tspeed: 0.0893s/iter; left time: 8070.2172s\n",
      "\titers: 800, epoch: 14 | loss: 0.3960440\n",
      "\tspeed: 0.0939s/iter; left time: 8476.6211s\n",
      "\titers: 900, epoch: 14 | loss: 0.9793423\n",
      "\tspeed: 0.0980s/iter; left time: 8838.1093s\n",
      "\titers: 1000, epoch: 14 | loss: 0.3884501\n",
      "\tspeed: 0.0912s/iter; left time: 8212.2126s\n",
      "Epoch: 14 cost time: 100.2122130393982\n",
      "Epoch: 14, Steps: 1047 | Train Loss: 0.4304925 Vali Loss: 0.3427641 Test Loss: 0.4923786\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Updating learning rate to 0.002349243099446893\n",
      "\titers: 100, epoch: 15 | loss: 0.3596205\n",
      "\tspeed: 1.4910s/iter; left time: 134103.4357s\n",
      "\titers: 200, epoch: 15 | loss: 0.3628664\n",
      "\tspeed: 0.0939s/iter; left time: 8437.1842s\n",
      "\titers: 300, epoch: 15 | loss: 0.3464804\n",
      "\tspeed: 0.0961s/iter; left time: 8628.0842s\n",
      "\titers: 400, epoch: 15 | loss: 0.3589118\n",
      "\tspeed: 0.0920s/iter; left time: 8244.7221s\n",
      "\titers: 500, epoch: 15 | loss: 0.5393586\n",
      "\tspeed: 0.0958s/iter; left time: 8578.5302s\n",
      "\titers: 600, epoch: 15 | loss: 0.3182715\n",
      "\tspeed: 0.0982s/iter; left time: 8781.4306s\n",
      "\titers: 700, epoch: 15 | loss: 0.2770712\n",
      "\tspeed: 0.1039s/iter; left time: 9287.1844s\n",
      "\titers: 800, epoch: 15 | loss: 0.2996056\n",
      "\tspeed: 0.0931s/iter; left time: 8305.7649s\n",
      "\titers: 900, epoch: 15 | loss: 0.5843515\n",
      "\tspeed: 0.0989s/iter; left time: 8813.0597s\n",
      "\titers: 1000, epoch: 15 | loss: 0.5094331\n",
      "\tspeed: 0.0911s/iter; left time: 8112.5999s\n",
      "Epoch: 15 cost time: 100.00467610359192\n",
      "Epoch: 15, Steps: 1047 | Train Loss: 0.4445459 Vali Loss: 0.3269891 Test Loss: 0.4622108\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Updating learning rate to 0.0026001200264632028\n",
      "\titers: 100, epoch: 16 | loss: 0.5489950\n",
      "\tspeed: 4.5190s/iter; left time: 401721.4940s\n",
      "\titers: 200, epoch: 16 | loss: 0.5798835\n",
      "\tspeed: 0.1007s/iter; left time: 8941.4229s\n",
      "\titers: 300, epoch: 16 | loss: 0.3162572\n",
      "\tspeed: 0.2501s/iter; left time: 22185.7652s\n",
      "\titers: 400, epoch: 16 | loss: 0.5672004\n",
      "\tspeed: 0.1010s/iter; left time: 8949.3490s\n",
      "\titers: 500, epoch: 16 | loss: 0.3160404\n",
      "\tspeed: 0.1070s/iter; left time: 9469.5373s\n",
      "\titers: 600, epoch: 16 | loss: 0.2953266\n",
      "\tspeed: 0.0992s/iter; left time: 8765.4893s\n",
      "\titers: 700, epoch: 16 | loss: 0.5192811\n",
      "\tspeed: 0.0989s/iter; left time: 8732.4155s\n",
      "\titers: 800, epoch: 16 | loss: 0.6867062\n",
      "\tspeed: 0.1020s/iter; left time: 8999.6811s\n",
      "\titers: 900, epoch: 16 | loss: 0.4683177\n",
      "\tspeed: 0.0860s/iter; left time: 7578.3958s\n",
      "\titers: 1000, epoch: 16 | loss: 0.7374802\n",
      "\tspeed: 0.1040s/iter; left time: 9149.7798s\n",
      "Epoch: 16 cost time: 120.7117292881012\n",
      "Epoch: 16, Steps: 1047 | Train Loss: 0.4484503 Vali Loss: 0.3576714 Test Loss: 0.7006714\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Updating learning rate to 0.0028509956383608033\n",
      "\titers: 100, epoch: 17 | loss: 0.7342919\n",
      "\tspeed: 2.0538s/iter; left time: 180425.1262s\n",
      "\titers: 200, epoch: 17 | loss: 0.4738090\n",
      "\tspeed: 0.0891s/iter; left time: 7820.3484s\n",
      "\titers: 300, epoch: 17 | loss: 0.4305528\n",
      "\tspeed: 0.0970s/iter; left time: 8501.9842s\n",
      "\titers: 400, epoch: 17 | loss: 0.4322767\n",
      "\tspeed: 0.1078s/iter; left time: 9438.9200s\n",
      "\titers: 500, epoch: 17 | loss: 0.4671702\n",
      "\tspeed: 0.0995s/iter; left time: 8698.4582s\n",
      "\titers: 600, epoch: 17 | loss: 0.7939951\n",
      "\tspeed: 0.0958s/iter; left time: 8364.8890s\n",
      "\titers: 700, epoch: 17 | loss: 0.4894454\n",
      "\tspeed: 0.0941s/iter; left time: 8210.9603s\n",
      "\titers: 800, epoch: 17 | loss: 0.4152768\n",
      "\tspeed: 0.1049s/iter; left time: 9142.8950s\n",
      "\titers: 900, epoch: 17 | loss: 0.4124726\n",
      "\tspeed: 0.0897s/iter; left time: 7812.0553s\n",
      "\titers: 1000, epoch: 17 | loss: 0.5252645\n",
      "\tspeed: 0.0992s/iter; left time: 8628.4827s\n",
      "Epoch: 17 cost time: 102.21151733398438\n",
      "Epoch: 17, Steps: 1047 | Train Loss: 0.4624318 Vali Loss: 0.4012063 Test Loss: 0.6716000\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Updating learning rate to 0.00309912111457104\n",
      "\titers: 100, epoch: 18 | loss: 0.5274376\n",
      "\tspeed: 1.8940s/iter; left time: 164405.7633s\n",
      "\titers: 200, epoch: 18 | loss: 0.4000486\n",
      "\tspeed: 0.0999s/iter; left time: 8663.8601s\n",
      "\titers: 300, epoch: 18 | loss: 0.2671764\n",
      "\tspeed: 0.1128s/iter; left time: 9769.1637s\n",
      "\titers: 400, epoch: 18 | loss: 0.4003001\n",
      "\tspeed: 0.0980s/iter; left time: 8477.6381s\n",
      "\titers: 500, epoch: 18 | loss: 0.5461223\n",
      "\tspeed: 0.1062s/iter; left time: 9177.8264s\n",
      "\titers: 600, epoch: 18 | loss: 0.3514372\n",
      "\tspeed: 0.0962s/iter; left time: 8302.3702s\n",
      "\titers: 700, epoch: 18 | loss: 0.4015288\n",
      "\tspeed: 0.1007s/iter; left time: 8680.6540s\n",
      "\titers: 800, epoch: 18 | loss: 0.6145174\n",
      "\tspeed: 0.0921s/iter; left time: 7930.8921s\n",
      "\titers: 900, epoch: 18 | loss: 0.4433508\n",
      "\tspeed: 0.1039s/iter; left time: 8937.2163s\n",
      "\titers: 1000, epoch: 18 | loss: 0.3032906\n",
      "\tspeed: 0.0948s/iter; left time: 8147.1785s\n",
      "Epoch: 18 cost time: 104.71479296684265\n",
      "Epoch: 18, Steps: 1047 | Train Loss: 0.4844289 Vali Loss: 0.3672250 Test Loss: 0.7435495\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Updating learning rate to 0.0033417777675042544\n",
      "\titers: 100, epoch: 19 | loss: 0.4327689\n",
      "\tspeed: 1.9910s/iter; left time: 170738.4840s\n",
      "\titers: 200, epoch: 19 | loss: 0.5050200\n",
      "\tspeed: 0.1020s/iter; left time: 8736.9622s\n",
      "\titers: 300, epoch: 19 | loss: 0.5991127\n",
      "\tspeed: 0.1241s/iter; left time: 10615.2628s\n",
      "\titers: 400, epoch: 19 | loss: 0.2948429\n",
      "\tspeed: 0.4970s/iter; left time: 42470.2553s\n",
      "\titers: 500, epoch: 19 | loss: 0.6439035\n",
      "\tspeed: 0.5021s/iter; left time: 42859.4714s\n",
      "\titers: 600, epoch: 19 | loss: 0.6007438\n",
      "\tspeed: 0.6409s/iter; left time: 54638.1726s\n",
      "\titers: 700, epoch: 19 | loss: 0.3844509\n",
      "\tspeed: 0.7759s/iter; left time: 66073.8785s\n",
      "\titers: 800, epoch: 19 | loss: 0.6492168\n",
      "\tspeed: 0.7800s/iter; left time: 66344.3090s\n",
      "\titers: 900, epoch: 19 | loss: 0.4305687\n",
      "\tspeed: 0.7871s/iter; left time: 66866.7212s\n",
      "\titers: 1000, epoch: 19 | loss: 0.4576522\n",
      "\tspeed: 0.7709s/iter; left time: 65417.7848s\n",
      "Epoch: 19 cost time: 543.1035747528076\n",
      "Epoch: 19, Steps: 1047 | Train Loss: 0.4888355 Vali Loss: 0.3587880 Test Loss: 0.5089481\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Updating learning rate to 0.00357630683095492\n",
      "\titers: 100, epoch: 20 | loss: 0.5561060\n",
      "\tspeed: 4.2762s/iter; left time: 362225.0238s\n",
      "\titers: 200, epoch: 20 | loss: 0.3100060\n",
      "\tspeed: 0.5049s/iter; left time: 42719.5515s\n",
      "\titers: 300, epoch: 20 | loss: 0.4927349\n",
      "\tspeed: 0.5039s/iter; left time: 42587.2467s\n",
      "\titers: 400, epoch: 20 | loss: 0.6563458\n",
      "\tspeed: 0.4960s/iter; left time: 41867.9704s\n",
      "\titers: 500, epoch: 20 | loss: 0.2956635\n",
      "\tspeed: 0.4959s/iter; left time: 41811.3914s\n",
      "\titers: 600, epoch: 20 | loss: 0.6493428\n",
      "\tspeed: 0.4961s/iter; left time: 41778.6673s\n",
      "\titers: 700, epoch: 20 | loss: 0.3556698\n",
      "\tspeed: 0.5138s/iter; left time: 43218.6098s\n",
      "\titers: 800, epoch: 20 | loss: 0.4495547\n",
      "\tspeed: 0.6012s/iter; left time: 50502.3746s\n",
      "\titers: 900, epoch: 20 | loss: 0.3633720\n",
      "\tspeed: 0.4929s/iter; left time: 41357.5110s\n",
      "\titers: 1000, epoch: 20 | loss: 0.4935452\n",
      "\tspeed: 0.5000s/iter; left time: 41906.7524s\n",
      "Epoch: 20 cost time: 534.1908941268921\n",
      "Epoch: 20, Steps: 1047 | Train Loss: 0.4816176 Vali Loss: 0.3965977 Test Loss: 0.7857918\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Updating learning rate to 0.003800138591953792\n",
      "\titers: 100, epoch: 21 | loss: 0.3203167\n",
      "\tspeed: 7.6950s/iter; left time: 643770.9185s\n",
      "\titers: 200, epoch: 21 | loss: 0.7319555\n",
      "\tspeed: 0.4931s/iter; left time: 41202.9909s\n",
      "\titers: 300, epoch: 21 | loss: 0.4547115\n",
      "\tspeed: 0.5009s/iter; left time: 41804.6221s\n",
      "\titers: 400, epoch: 21 | loss: 0.5006692\n",
      "\tspeed: 0.4960s/iter; left time: 41345.1303s\n",
      "\titers: 500, epoch: 21 | loss: 0.4990842\n",
      "\tspeed: 0.5001s/iter; left time: 41640.1722s\n",
      "\titers: 600, epoch: 21 | loss: 0.4017521\n",
      "\tspeed: 0.4889s/iter; left time: 40658.5891s\n",
      "\titers: 700, epoch: 21 | loss: 0.5076317\n",
      "\tspeed: 0.4980s/iter; left time: 41363.0783s\n",
      "\titers: 800, epoch: 21 | loss: 0.3964236\n",
      "\tspeed: 0.4930s/iter; left time: 40899.6414s\n",
      "\titers: 900, epoch: 21 | loss: 0.3602584\n",
      "\tspeed: 0.5070s/iter; left time: 42009.1325s\n",
      "\titers: 1000, epoch: 21 | loss: 0.3458498\n",
      "\tspeed: 0.5140s/iter; left time: 42541.2145s\n",
      "Epoch: 21 cost time: 523.7079606056213\n",
      "\titers: 100, epoch: 22 | loss: 0.4978485\n",
      "\tspeed: 7.6720s/iter; left time: 633814.9031s\n",
      "\titers: 200, epoch: 22 | loss: 0.4510589\n",
      "\tspeed: 0.4959s/iter; left time: 40922.2340s\n",
      "\titers: 300, epoch: 22 | loss: 0.4959122\n",
      "\tspeed: 0.4970s/iter; left time: 40960.3927s\n",
      "\titers: 400, epoch: 22 | loss: 0.7906929\n",
      "\tspeed: 0.4893s/iter; left time: 40272.5105s\n",
      "\titers: 500, epoch: 22 | loss: 0.6896003\n",
      "\tspeed: 0.4028s/iter; left time: 33114.2319s\n",
      "\titers: 600, epoch: 22 | loss: 0.4180407\n",
      "\tspeed: 0.1022s/iter; left time: 8391.0676s\n",
      "\titers: 700, epoch: 22 | loss: 0.5739185\n",
      "\tspeed: 0.1148s/iter; left time: 9415.0093s\n",
      "\titers: 800, epoch: 22 | loss: 0.4538939\n",
      "\tspeed: 0.1060s/iter; left time: 8681.8299s\n",
      "\titers: 900, epoch: 22 | loss: 0.3097430\n",
      "\tspeed: 0.1102s/iter; left time: 9019.8543s\n",
      "\titers: 1000, epoch: 22 | loss: 0.4487143\n",
      "\tspeed: 0.1107s/iter; left time: 9048.0254s\n",
      "Epoch: 22 cost time: 299.4996757507324\n",
      "Epoch: 22, Steps: 1047 | Train Loss: 0.4695998 Vali Loss: 0.4259141 Test Loss: 0.8177708\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Updating learning rate to 0.004206044273273908\n",
      "\titers: 100, epoch: 23 | loss: 0.5055663\n",
      "\tspeed: 1.9142s/iter; left time: 156134.7370s\n",
      "\titers: 200, epoch: 23 | loss: 0.4878703\n",
      "\tspeed: 0.1048s/iter; left time: 8538.9730s\n",
      "\titers: 300, epoch: 23 | loss: 0.4114213\n",
      "\tspeed: 0.1170s/iter; left time: 9521.1321s\n",
      "\titers: 400, epoch: 23 | loss: 0.6363377\n",
      "\tspeed: 0.1052s/iter; left time: 8546.1809s\n",
      "\titers: 500, epoch: 23 | loss: 0.5210236\n",
      "\tspeed: 0.1100s/iter; left time: 8930.9906s\n",
      "\titers: 600, epoch: 23 | loss: 0.3031089\n",
      "\tspeed: 0.0980s/iter; left time: 7941.8243s\n",
      "\titers: 700, epoch: 23 | loss: 0.6080542\n",
      "\tspeed: 0.1052s/iter; left time: 8514.5928s\n",
      "\titers: 800, epoch: 23 | loss: 0.3307139\n",
      "\tspeed: 0.0957s/iter; left time: 7736.2815s\n",
      "\titers: 900, epoch: 23 | loss: 0.3503897\n",
      "\tspeed: 0.1080s/iter; left time: 8724.1394s\n",
      "\titers: 1000, epoch: 23 | loss: 0.3572225\n",
      "\tspeed: 0.1050s/iter; left time: 8471.5505s\n",
      "Epoch: 23 cost time: 111.21440100669861\n",
      "Epoch: 23, Steps: 1047 | Train Loss: 0.4684232 Vali Loss: 0.3696862 Test Loss: 0.7130026\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Updating learning rate to 0.004383670723084539\n",
      "\titers: 100, epoch: 24 | loss: 0.4838562\n",
      "\tspeed: 1.9152s/iter; left time: 154210.1004s\n",
      "\titers: 200, epoch: 24 | loss: 0.4429936\n",
      "\tspeed: 0.1008s/iter; left time: 8105.4626s\n",
      "\titers: 300, epoch: 24 | loss: 0.3242338\n",
      "\tspeed: 0.1050s/iter; left time: 8434.6159s\n",
      "\titers: 400, epoch: 24 | loss: 0.2624928\n",
      "\tspeed: 0.1303s/iter; left time: 10453.6058s\n",
      "\titers: 500, epoch: 24 | loss: 0.4167992\n",
      "\tspeed: 0.1020s/iter; left time: 8173.9140s\n",
      "\titers: 600, epoch: 24 | loss: 0.3987016\n",
      "\tspeed: 0.1060s/iter; left time: 8478.9781s\n",
      "\titers: 700, epoch: 24 | loss: 0.4894606\n",
      "\tspeed: 0.1088s/iter; left time: 8697.9997s\n",
      "\titers: 800, epoch: 24 | loss: 0.4547515\n",
      "\tspeed: 0.1099s/iter; left time: 8770.0837s\n",
      "\titers: 900, epoch: 24 | loss: 0.5064567\n",
      "\tspeed: 0.1181s/iter; left time: 9414.3467s\n",
      "\titers: 1000, epoch: 24 | loss: 0.4676825\n",
      "\tspeed: 0.1061s/iter; left time: 8445.6992s\n",
      "Epoch: 24 cost time: 115.217125415802\n",
      "Epoch: 24, Steps: 1047 | Train Loss: 0.4689294 Vali Loss: 0.3995590 Test Loss: 0.7267100\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): PatchTST_backbone(\n",
       "    (backbone): TSTiEncoder(\n",
       "      (W_P): Linear(in_features=16, out_features=128, bias=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (encoder): TSTEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-2): 3 x TSTEncoderLayer(\n",
       "            (self_attn): _MultiheadAttention(\n",
       "              (W_Q): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (W_K): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (W_V): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (sdp_attn): _ScaledDotProductAttention(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (dropout_attn): Dropout(p=0.2, inplace=False)\n",
       "            (norm_attn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.2, inplace=False)\n",
       "              (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "            )\n",
       "            (dropout_ffn): Dropout(p=0.2, inplace=False)\n",
       "            (norm_ffn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): Flatten_Head(\n",
       "      (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "      (linear): Linear(in_features=5248, out_features=720, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exp = Exp_Main\n",
    "setting=f'PatchTST_train_on_{args.data}_{args.pred_len}'\n",
    "# set experiments\n",
    "exp = Exp(args)\n",
    "exp.train(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52d19da",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7463a690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 10801\n",
      "mse:0.4332469403743744, mae:0.4294425845146179, rse:0.528854250907898\n"
     ]
    }
   ],
   "source": [
    "exp.test(setting)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4109cbc6",
   "metadata": {},
   "source": [
    "---\n",
    "# Working on ETTm2 Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d0d423",
   "metadata": {},
   "source": [
    "## Trail 1: PatchTST, Dataset:ETTm2,  Metric: 96\n",
    "### Set hyperparameters\n",
    "Set some parameters (Args) for the our experiment like dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f94e0dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ETTm2,  Prediction Length : 96\n"
     ]
    }
   ],
   "source": [
    "args.data_path = 'ETTm2.csv' # data file\n",
    "args.data = 'ETTm2'  # data\n",
    "args.pred_len = 96 # prediction sequence length\n",
    "print(f\"Dataset: {args.data},  Prediction Length : {args.pred_len}\") \n",
    "# print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffcd637",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f68becd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "train 34129\n",
      "val 11425\n",
      "test 11425\n",
      "\titers: 100, epoch: 1 | loss: 0.2986088\n",
      "\tspeed: 0.0775s/iter; left time: 8252.6501s\n",
      "\titers: 200, epoch: 1 | loss: 0.2189520\n",
      "\tspeed: 0.0761s/iter; left time: 8093.1558s\n",
      "\titers: 300, epoch: 1 | loss: 0.2698198\n",
      "\tspeed: 0.0727s/iter; left time: 7728.7875s\n",
      "\titers: 400, epoch: 1 | loss: 0.5238720\n",
      "\tspeed: 0.0830s/iter; left time: 8813.3957s\n",
      "\titers: 500, epoch: 1 | loss: 0.2177546\n",
      "\tspeed: 0.0730s/iter; left time: 7746.8619s\n",
      "\titers: 600, epoch: 1 | loss: 0.2002172\n",
      "\tspeed: 0.0753s/iter; left time: 7982.5597s\n",
      "\titers: 700, epoch: 1 | loss: 0.2478255\n",
      "\tspeed: 0.0777s/iter; left time: 8231.2701s\n",
      "\titers: 800, epoch: 1 | loss: 0.3425599\n",
      "\tspeed: 0.0781s/iter; left time: 8262.8083s\n",
      "\titers: 900, epoch: 1 | loss: 0.3695400\n",
      "\tspeed: 0.0839s/iter; left time: 8872.0942s\n",
      "\titers: 1000, epoch: 1 | loss: 0.1490627\n",
      "\tspeed: 0.0749s/iter; left time: 7914.3217s\n",
      "Epoch: 1 cost time: 82.24881148338318\n",
      "Epoch: 1, Steps: 1066 | Train Loss: 0.2849889 Vali Loss: 0.2099577 Test Loss: 0.4052075\n",
      "Validation loss decreased (inf --> 0.209958).  Saving model ...\n",
      "Updating learning rate to 0.0002131482726326836\n",
      "\titers: 100, epoch: 2 | loss: 0.2623660\n",
      "\tspeed: 0.8123s/iter; left time: 85642.8541s\n",
      "\titers: 200, epoch: 2 | loss: 0.3231488\n",
      "\tspeed: 0.0760s/iter; left time: 8005.1661s\n",
      "\titers: 300, epoch: 2 | loss: 0.2467601\n",
      "\tspeed: 0.0780s/iter; left time: 8205.9697s\n",
      "\titers: 400, epoch: 2 | loss: 0.1362661\n",
      "\tspeed: 0.0757s/iter; left time: 7960.4109s\n",
      "\titers: 500, epoch: 2 | loss: 0.1596793\n",
      "\tspeed: 0.0850s/iter; left time: 8928.0719s\n",
      "\titers: 600, epoch: 2 | loss: 0.3120453\n",
      "\tspeed: 0.0800s/iter; left time: 8399.2245s\n",
      "\titers: 700, epoch: 2 | loss: 0.1555978\n",
      "\tspeed: 0.0810s/iter; left time: 8496.0964s\n",
      "\titers: 800, epoch: 2 | loss: 0.1445718\n",
      "\tspeed: 0.0811s/iter; left time: 8489.6954s\n",
      "\titers: 900, epoch: 2 | loss: 0.1335078\n",
      "\tspeed: 0.0800s/iter; left time: 8371.5190s\n",
      "\titers: 1000, epoch: 2 | loss: 0.1801109\n",
      "\tspeed: 0.0790s/iter; left time: 8257.8509s\n",
      "Epoch: 2 cost time: 85.00753617286682\n",
      "Epoch: 2, Steps: 1066 | Train Loss: 0.2287638 Vali Loss: 0.1619703 Test Loss: 0.2946424\n",
      "Validation loss decreased (0.209958 --> 0.161970).  Saving model ...\n",
      "Updating learning rate to 0.0002524490263030492\n",
      "\titers: 100, epoch: 3 | loss: 0.3012899\n",
      "\tspeed: 0.8190s/iter; left time: 85478.2400s\n",
      "\titers: 200, epoch: 3 | loss: 0.1742261\n",
      "\tspeed: 0.0849s/iter; left time: 8847.4284s\n",
      "\titers: 300, epoch: 3 | loss: 0.2057223\n",
      "\tspeed: 0.0792s/iter; left time: 8246.4930s\n",
      "\titers: 400, epoch: 3 | loss: 0.1763839\n",
      "\tspeed: 0.0880s/iter; left time: 9155.6473s\n",
      "\titers: 500, epoch: 3 | loss: 0.3003002\n",
      "\tspeed: 0.0819s/iter; left time: 8519.8557s\n",
      "\titers: 600, epoch: 3 | loss: 0.1144489\n",
      "\tspeed: 0.0892s/iter; left time: 9263.3487s\n",
      "\titers: 700, epoch: 3 | loss: 0.2732310\n",
      "\tspeed: 0.0847s/iter; left time: 8793.0194s\n",
      "\titers: 800, epoch: 3 | loss: 0.1742587\n",
      "\tspeed: 0.0830s/iter; left time: 8606.5292s\n",
      "\titers: 900, epoch: 3 | loss: 0.3101521\n",
      "\tspeed: 0.0852s/iter; left time: 8827.7096s\n",
      "\titers: 1000, epoch: 3 | loss: 0.2144040\n",
      "\tspeed: 0.0869s/iter; left time: 8987.8234s\n",
      "Epoch: 3 cost time: 90.48695802688599\n",
      "Epoch: 3, Steps: 1066 | Train Loss: 0.2164935 Vali Loss: 0.1272870 Test Loss: 0.1950858\n",
      "Validation loss decreased (0.161970 --> 0.127287).  Saving model ...\n",
      "Updating learning rate to 0.0003174716468244904\n",
      "\titers: 100, epoch: 4 | loss: 0.3104403\n",
      "\tspeed: 0.8291s/iter; left time: 85648.6450s\n",
      "\titers: 200, epoch: 4 | loss: 0.1633864\n",
      "\tspeed: 0.0830s/iter; left time: 8565.3418s\n",
      "\titers: 300, epoch: 4 | loss: 0.1916842\n",
      "\tspeed: 0.0828s/iter; left time: 8534.5636s\n",
      "\titers: 400, epoch: 4 | loss: 0.1716954\n",
      "\tspeed: 0.0774s/iter; left time: 7976.8335s\n",
      "\titers: 500, epoch: 4 | loss: 0.1642539\n",
      "\tspeed: 0.0778s/iter; left time: 8006.1375s\n",
      "\titers: 600, epoch: 4 | loss: 0.1838986\n",
      "\tspeed: 0.0758s/iter; left time: 7788.4273s\n",
      "\titers: 700, epoch: 4 | loss: 0.1577928\n",
      "\tspeed: 0.0862s/iter; left time: 8848.1157s\n",
      "\titers: 800, epoch: 4 | loss: 0.2569227\n",
      "\tspeed: 0.0821s/iter; left time: 8423.9106s\n",
      "\titers: 900, epoch: 4 | loss: 0.1154114\n",
      "\tspeed: 0.0769s/iter; left time: 7878.9978s\n",
      "\titers: 1000, epoch: 4 | loss: 0.2287025\n",
      "\tspeed: 0.0789s/iter; left time: 8078.3499s\n",
      "Epoch: 4 cost time: 85.70261931419373\n",
      "Epoch: 4, Steps: 1066 | Train Loss: 0.1995677 Vali Loss: 0.2289771 Test Loss: 0.4284606\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Updating learning rate to 0.0004075036882454173\n",
      "\titers: 100, epoch: 5 | loss: 0.1977475\n",
      "\tspeed: 0.7993s/iter; left time: 81718.7988s\n",
      "\titers: 200, epoch: 5 | loss: 0.1752112\n",
      "\tspeed: 0.0769s/iter; left time: 7853.4183s\n",
      "\titers: 300, epoch: 5 | loss: 0.1863215\n",
      "\tspeed: 0.0800s/iter; left time: 8158.2641s\n",
      "\titers: 400, epoch: 5 | loss: 0.2885852\n",
      "\tspeed: 0.0739s/iter; left time: 7530.5347s\n",
      "\titers: 500, epoch: 5 | loss: 0.1745493\n",
      "\tspeed: 0.0770s/iter; left time: 7845.9646s\n",
      "\titers: 600, epoch: 5 | loss: 0.1780202\n",
      "\tspeed: 0.0799s/iter; left time: 8132.9232s\n",
      "\titers: 700, epoch: 5 | loss: 0.2782275\n",
      "\tspeed: 0.0772s/iter; left time: 7849.5411s\n",
      "\titers: 800, epoch: 5 | loss: 0.1370241\n",
      "\tspeed: 0.0810s/iter; left time: 8224.7816s\n",
      "\titers: 900, epoch: 5 | loss: 0.1236662\n",
      "\tspeed: 0.0819s/iter; left time: 8309.9117s\n",
      "\titers: 1000, epoch: 5 | loss: 0.2177379\n",
      "\tspeed: 0.0778s/iter; left time: 7887.4917s\n",
      "Epoch: 5 cost time: 82.89682531356812\n",
      "Epoch: 5, Steps: 1066 | Train Loss: 0.1968625 Vali Loss: 0.1690471 Test Loss: 0.2388145\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Updating learning rate to 0.0005215586790439306\n",
      "\titers: 100, epoch: 6 | loss: 0.2390271\n",
      "\tspeed: 0.7961s/iter; left time: 80544.5672s\n",
      "\titers: 200, epoch: 6 | loss: 0.2043356\n",
      "\tspeed: 0.0842s/iter; left time: 8506.5377s\n",
      "\titers: 300, epoch: 6 | loss: 0.1621872\n",
      "\tspeed: 0.0759s/iter; left time: 7661.2982s\n",
      "\titers: 400, epoch: 6 | loss: 0.2480923\n",
      "\tspeed: 0.0750s/iter; left time: 7564.8154s\n",
      "\titers: 500, epoch: 6 | loss: 0.1571534\n",
      "\tspeed: 0.0919s/iter; left time: 9259.0763s\n",
      "\titers: 600, epoch: 6 | loss: 0.2215870\n",
      "\tspeed: 0.2360s/iter; left time: 23754.9481s\n",
      "\titers: 700, epoch: 6 | loss: 0.2223002\n",
      "\tspeed: 0.2641s/iter; left time: 26565.7946s\n",
      "\titers: 800, epoch: 6 | loss: 0.3397714\n",
      "\tspeed: 0.2659s/iter; left time: 26718.9124s\n",
      "\titers: 900, epoch: 6 | loss: 0.2602022\n",
      "\tspeed: 0.2649s/iter; left time: 26587.3777s\n",
      "\titers: 1000, epoch: 6 | loss: 0.1775864\n",
      "\tspeed: 0.2652s/iter; left time: 26588.7967s\n",
      "Epoch: 6 cost time: 187.58947253227234\n",
      "Epoch: 6, Steps: 1066 | Train Loss: 0.1975397 Vali Loss: 0.1408421 Test Loss: 0.2014807\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Updating learning rate to 0.0006583869307915822\n",
      "\titers: 100, epoch: 7 | loss: 0.1421614\n",
      "\tspeed: 2.1539s/iter; left time: 215615.5894s\n",
      "\titers: 200, epoch: 7 | loss: 0.1347939\n",
      "\tspeed: 0.2621s/iter; left time: 26213.2285s\n",
      "\titers: 300, epoch: 7 | loss: 0.1820995\n",
      "\tspeed: 0.2719s/iter; left time: 27166.9728s\n",
      "\titers: 400, epoch: 7 | loss: 0.1605198\n",
      "\tspeed: 0.2659s/iter; left time: 26537.7497s\n",
      "\titers: 500, epoch: 7 | loss: 0.2327824\n",
      "\tspeed: 0.2671s/iter; left time: 26635.0815s\n",
      "\titers: 600, epoch: 7 | loss: 0.1765490\n",
      "\tspeed: 0.2680s/iter; left time: 26692.8018s\n",
      "\titers: 700, epoch: 7 | loss: 0.1681942\n",
      "\tspeed: 0.2639s/iter; left time: 26260.3266s\n",
      "\titers: 800, epoch: 7 | loss: 0.2567911\n",
      "\tspeed: 0.2651s/iter; left time: 26352.2612s\n",
      "\titers: 900, epoch: 7 | loss: 0.1849465\n",
      "\tspeed: 0.2660s/iter; left time: 26413.1638s\n",
      "\titers: 1000, epoch: 7 | loss: 0.1621261\n",
      "\tspeed: 0.2619s/iter; left time: 25979.7122s\n",
      "Epoch: 7 cost time: 284.3994801044464\n",
      "Epoch: 7, Steps: 1066 | Train Loss: 0.1908977 Vali Loss: 0.1524140 Test Loss: 0.2318953\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Updating learning rate to 0.000816489230856845\n",
      "\titers: 100, epoch: 8 | loss: 0.3266895\n",
      "\tspeed: 2.1601s/iter; left time: 213930.7087s\n",
      "\titers: 200, epoch: 8 | loss: 0.2356823\n",
      "\tspeed: 0.2621s/iter; left time: 25928.6463s\n",
      "\titers: 300, epoch: 8 | loss: 0.1451575\n",
      "\tspeed: 0.4510s/iter; left time: 44572.0185s\n",
      "\titers: 400, epoch: 8 | loss: 0.3269343\n",
      "\tspeed: 0.4710s/iter; left time: 46503.0128s\n",
      "\titers: 500, epoch: 8 | loss: 0.1911950\n",
      "\tspeed: 0.4650s/iter; left time: 45862.4400s\n",
      "\titers: 600, epoch: 8 | loss: 0.2091859\n",
      "\tspeed: 0.4462s/iter; left time: 43965.3055s\n",
      "\titers: 700, epoch: 8 | loss: 0.2279664\n",
      "\tspeed: 0.4480s/iter; left time: 44096.7448s\n",
      "\titers: 800, epoch: 8 | loss: 0.2069039\n",
      "\tspeed: 0.4609s/iter; left time: 45323.0444s\n",
      "\titers: 900, epoch: 8 | loss: 0.1521674\n",
      "\tspeed: 0.4640s/iter; left time: 45580.4162s\n",
      "\titers: 1000, epoch: 8 | loss: 0.2453538\n",
      "\tspeed: 0.4581s/iter; left time: 44955.2891s\n",
      "Epoch: 8 cost time: 449.60721254348755\n",
      "Epoch: 8, Steps: 1066 | Train Loss: 0.2002724 Vali Loss: 0.1432686 Test Loss: 0.2231292\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Updating learning rate to 0.0009941332691187936\n",
      "\titers: 100, epoch: 9 | loss: 0.1314011\n",
      "\tspeed: 3.7920s/iter; left time: 371513.9599s\n",
      "\titers: 200, epoch: 9 | loss: 0.2620167\n",
      "\tspeed: 0.4710s/iter; left time: 46102.9495s\n",
      "\titers: 300, epoch: 9 | loss: 0.3247759\n",
      "\tspeed: 0.4689s/iter; left time: 45850.3642s\n",
      "\titers: 400, epoch: 9 | loss: 0.1429665\n",
      "\tspeed: 0.4491s/iter; left time: 43860.2618s\n",
      "\titers: 500, epoch: 9 | loss: 0.1269651\n",
      "\tspeed: 0.4520s/iter; left time: 44098.1640s\n",
      "\titers: 600, epoch: 9 | loss: 0.2617268\n",
      "\tspeed: 0.4411s/iter; left time: 42995.7462s\n",
      "\titers: 700, epoch: 9 | loss: 0.2212171\n",
      "\tspeed: 0.4619s/iter; left time: 44972.5365s\n",
      "\titers: 800, epoch: 9 | loss: 0.1755985\n",
      "\tspeed: 0.4691s/iter; left time: 45632.1666s\n",
      "\titers: 900, epoch: 9 | loss: 0.1736959\n",
      "\tspeed: 0.4629s/iter; left time: 44976.8542s\n",
      "\titers: 1000, epoch: 9 | loss: 0.1984487\n",
      "\tspeed: 0.4661s/iter; left time: 45249.8006s\n",
      "Epoch: 9 cost time: 487.8100709915161\n",
      "Epoch: 9, Steps: 1066 | Train Loss: 0.1924495 Vali Loss: 0.1382771 Test Loss: 0.2089268\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Updating learning rate to 0.0011893726187052283\n",
      "\titers: 100, epoch: 10 | loss: 0.1909500\n",
      "\tspeed: 3.8310s/iter; left time: 371249.9632s\n",
      "\titers: 200, epoch: 10 | loss: 0.2687954\n",
      "\tspeed: 0.4669s/iter; left time: 45199.5846s\n",
      "\titers: 300, epoch: 10 | loss: 0.3644606\n",
      "\tspeed: 0.4581s/iter; left time: 44303.5976s\n",
      "\titers: 400, epoch: 10 | loss: 0.3501205\n",
      "\tspeed: 0.4639s/iter; left time: 44814.8710s\n",
      "\titers: 500, epoch: 10 | loss: 0.2845208\n",
      "\tspeed: 0.4680s/iter; left time: 45160.5556s\n",
      "\titers: 600, epoch: 10 | loss: 0.1323508\n",
      "\tspeed: 0.4441s/iter; left time: 42817.3615s\n",
      "\titers: 700, epoch: 10 | loss: 0.2039878\n",
      "\tspeed: 0.4680s/iter; left time: 45069.4625s\n",
      "\titers: 800, epoch: 10 | loss: 0.3216565\n",
      "\tspeed: 0.4700s/iter; left time: 45220.2237s\n",
      "\titers: 900, epoch: 10 | loss: 0.2263369\n",
      "\tspeed: 0.4659s/iter; left time: 44780.4623s\n",
      "\titers: 1000, epoch: 10 | loss: 0.1590343\n",
      "\tspeed: 0.4559s/iter; left time: 43772.0787s\n",
      "Epoch: 10 cost time: 492.71343326568604\n",
      "Epoch: 10, Steps: 1066 | Train Loss: 0.2244222 Vali Loss: 0.1437503 Test Loss: 0.2209134\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Updating learning rate to 0.0014000680627853234\n",
      "\titers: 100, epoch: 11 | loss: 0.1043266\n",
      "\tspeed: 3.8892s/iter; left time: 372743.4565s\n",
      "\titers: 200, epoch: 11 | loss: 0.1334067\n",
      "\tspeed: 0.4628s/iter; left time: 44309.4267s\n",
      "\titers: 300, epoch: 11 | loss: 0.4211203\n",
      "\tspeed: 0.4660s/iter; left time: 44569.1975s\n",
      "\titers: 400, epoch: 11 | loss: 0.2205209\n",
      "\tspeed: 0.4631s/iter; left time: 44246.1625s\n",
      "\titers: 500, epoch: 11 | loss: 0.1174513\n",
      "\tspeed: 0.4540s/iter; left time: 43327.3888s\n",
      "\titers: 600, epoch: 11 | loss: 0.3150668\n",
      "\tspeed: 0.4489s/iter; left time: 42798.8562s\n",
      "\titers: 700, epoch: 11 | loss: 0.2850769\n",
      "\tspeed: 0.4571s/iter; left time: 43539.1703s\n",
      "\titers: 800, epoch: 11 | loss: 0.1541231\n",
      "\tspeed: 0.4600s/iter; left time: 43761.6335s\n",
      "\titers: 900, epoch: 11 | loss: 0.1506207\n",
      "\tspeed: 0.4590s/iter; left time: 43624.5057s\n",
      "\titers: 1000, epoch: 11 | loss: 0.1757446\n",
      "\tspeed: 0.4661s/iter; left time: 44247.9199s\n",
      "Epoch: 11 cost time: 492.8037066459656\n",
      "Epoch: 11, Steps: 1066 | Train Loss: 0.2228608 Vali Loss: 0.1716110 Test Loss: 0.3180439\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Updating learning rate to 0.0016239110337413882\n",
      "\titers: 100, epoch: 12 | loss: 0.1659685\n",
      "\tspeed: 3.8928s/iter; left time: 368944.3421s\n",
      "\titers: 200, epoch: 12 | loss: 0.2414374\n",
      "\tspeed: 0.4681s/iter; left time: 44313.6814s\n",
      "\titers: 300, epoch: 12 | loss: 0.2953342\n",
      "\tspeed: 0.4720s/iter; left time: 44641.5660s\n",
      "\titers: 400, epoch: 12 | loss: 0.4394885\n",
      "\tspeed: 0.4730s/iter; left time: 44687.2203s\n",
      "\titers: 500, epoch: 12 | loss: 0.2376986\n",
      "\tspeed: 0.4640s/iter; left time: 43792.0571s\n",
      "\titers: 600, epoch: 12 | loss: 0.2631288\n",
      "\tspeed: 0.4750s/iter; left time: 44776.2941s\n",
      "\titers: 700, epoch: 12 | loss: 0.2341637\n",
      "\tspeed: 0.4311s/iter; left time: 40594.1452s\n",
      "\titers: 800, epoch: 12 | loss: 0.2252078\n",
      "\tspeed: 0.4599s/iter; left time: 43269.3585s\n",
      "\titers: 900, epoch: 12 | loss: 0.1232284\n",
      "\tspeed: 0.4659s/iter; left time: 43784.2598s\n",
      "\titers: 1000, epoch: 12 | loss: 0.1679908\n",
      "\tspeed: 0.4721s/iter; left time: 44322.2002s\n",
      "Epoch: 12 cost time: 495.11067247390747\n",
      "Epoch: 12, Steps: 1066 | Train Loss: 0.2463458 Vali Loss: 0.1564204 Test Loss: 0.2313395\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Updating learning rate to 0.0018584489078992223\n",
      "\titers: 100, epoch: 13 | loss: 0.1717861\n",
      "\tspeed: 3.8479s/iter; left time: 360580.0455s\n",
      "\titers: 200, epoch: 13 | loss: 0.2111439\n",
      "\tspeed: 0.4571s/iter; left time: 42786.0085s\n",
      "\titers: 300, epoch: 13 | loss: 0.4181379\n",
      "\tspeed: 0.4490s/iter; left time: 41982.2721s\n",
      "\titers: 400, epoch: 13 | loss: 0.2809423\n",
      "\tspeed: 0.4731s/iter; left time: 44188.6706s\n",
      "\titers: 500, epoch: 13 | loss: 0.1577017\n",
      "\tspeed: 0.4640s/iter; left time: 43293.8288s\n",
      "\titers: 600, epoch: 13 | loss: 0.4743578\n",
      "\tspeed: 0.4741s/iter; left time: 44188.3780s\n",
      "\titers: 700, epoch: 13 | loss: 0.2293548\n",
      "\tspeed: 0.4689s/iter; left time: 43654.7844s\n",
      "\titers: 800, epoch: 13 | loss: 0.1530747\n",
      "\tspeed: 0.4531s/iter; left time: 42143.3912s\n",
      "\titers: 900, epoch: 13 | loss: 0.2673109\n",
      "\tspeed: 0.4480s/iter; left time: 41625.8835s\n",
      "\titers: 1000, epoch: 13 | loss: 0.2119351\n",
      "\tspeed: 0.4639s/iter; left time: 43051.8561s\n",
      "Epoch: 13 cost time: 491.9738657474518\n",
      "Epoch: 13, Steps: 1066 | Train Loss: 0.2716551 Vali Loss: 0.2482302 Test Loss: 0.4559485\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Updating learning rate to 0.0021011118786653927\n",
      "\titers: 100, epoch: 14 | loss: 0.2036072\n",
      "\tspeed: 2.8620s/iter; left time: 265145.2200s\n",
      "\titers: 200, epoch: 14 | loss: 0.1845652\n",
      "\tspeed: 0.3241s/iter; left time: 29991.3253s\n",
      "\titers: 300, epoch: 14 | loss: 0.4038287\n",
      "\tspeed: 0.4260s/iter; left time: 39380.6527s\n",
      "\titers: 400, epoch: 14 | loss: 0.1609787\n",
      "\tspeed: 0.4759s/iter; left time: 43950.4395s\n",
      "\titers: 500, epoch: 14 | loss: 0.2183379\n",
      "\tspeed: 0.4749s/iter; left time: 43807.1299s\n",
      "\titers: 600, epoch: 14 | loss: 0.2743112\n",
      "\tspeed: 0.4711s/iter; left time: 43412.9772s\n",
      "\titers: 700, epoch: 14 | loss: 0.2098520\n",
      "\tspeed: 0.4660s/iter; left time: 42890.3306s\n",
      "\titers: 800, epoch: 14 | loss: 0.3820725\n",
      "\tspeed: 0.4671s/iter; left time: 42942.3461s\n",
      "\titers: 900, epoch: 14 | loss: 0.2132735\n",
      "\tspeed: 0.4819s/iter; left time: 44257.1522s\n",
      "\titers: 1000, epoch: 14 | loss: 0.2091483\n",
      "\tspeed: 0.4830s/iter; left time: 44308.7231s\n",
      "Epoch: 14 cost time: 471.000834941864\n",
      "Epoch: 14, Steps: 1066 | Train Loss: 0.2588452 Vali Loss: 0.2114965 Test Loss: 0.2792774\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Updating learning rate to 0.0023492411136253276\n",
      "\titers: 100, epoch: 15 | loss: 0.2376577\n",
      "\tspeed: 3.9981s/iter; left time: 366132.8135s\n",
      "\titers: 200, epoch: 15 | loss: 0.2554750\n",
      "\tspeed: 0.5409s/iter; left time: 49481.5609s\n",
      "\titers: 300, epoch: 15 | loss: 0.3308360\n",
      "\tspeed: 0.5621s/iter; left time: 51360.0560s\n",
      "\titers: 400, epoch: 15 | loss: 0.1914976\n",
      "\tspeed: 0.5350s/iter; left time: 48832.8272s\n",
      "\titers: 500, epoch: 15 | loss: 0.3021390\n",
      "\tspeed: 0.5289s/iter; left time: 48225.3090s\n",
      "\titers: 600, epoch: 15 | loss: 0.1603930\n",
      "\tspeed: 0.5240s/iter; left time: 47727.3714s\n",
      "\titers: 700, epoch: 15 | loss: 0.2335278\n",
      "\tspeed: 0.5210s/iter; left time: 47398.9202s\n",
      "\titers: 800, epoch: 15 | loss: 0.2302040\n",
      "\tspeed: 0.5180s/iter; left time: 47078.6798s\n",
      "\titers: 900, epoch: 15 | loss: 0.2579897\n",
      "\tspeed: 0.5240s/iter; left time: 47563.1967s\n",
      "\titers: 1000, epoch: 15 | loss: 0.4929122\n",
      "\tspeed: 0.5151s/iter; left time: 46711.9994s\n",
      "Epoch: 15 cost time: 565.9965188503265\n",
      "Epoch: 15, Steps: 1066 | Train Loss: 0.2673493 Vali Loss: 0.1830707 Test Loss: 0.2919258\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Updating learning rate to 0.002600117887087863\n",
      "\titers: 100, epoch: 16 | loss: 0.1893391\n",
      "\tspeed: 3.9918s/iter; left time: 361304.4344s\n",
      "\titers: 200, epoch: 16 | loss: 0.2267130\n",
      "\tspeed: 0.4731s/iter; left time: 42774.2170s\n",
      "\titers: 300, epoch: 16 | loss: 0.1762957\n",
      "\tspeed: 0.4770s/iter; left time: 43076.6712s\n",
      "\titers: 400, epoch: 16 | loss: 0.2534854\n",
      "\tspeed: 0.4530s/iter; left time: 40867.4522s\n",
      "\titers: 500, epoch: 16 | loss: 0.4412418\n",
      "\tspeed: 0.4740s/iter; left time: 42713.8282s\n",
      "\titers: 600, epoch: 16 | loss: 0.2452725\n",
      "\tspeed: 0.4629s/iter; left time: 41669.4287s\n",
      "\titers: 700, epoch: 16 | loss: 0.1893738\n",
      "\tspeed: 0.4609s/iter; left time: 41444.3552s\n",
      "\titers: 800, epoch: 16 | loss: 0.2601926\n",
      "\tspeed: 0.4721s/iter; left time: 42403.8362s\n",
      "\titers: 900, epoch: 16 | loss: 0.3347006\n",
      "\tspeed: 0.4630s/iter; left time: 41531.9276s\n",
      "\titers: 1000, epoch: 16 | loss: 0.2204792\n",
      "\tspeed: 0.4729s/iter; left time: 42375.3126s\n",
      "Epoch: 16 cost time: 499.69405150413513\n",
      "Epoch: 16, Steps: 1066 | Train Loss: 0.2860422 Vali Loss: 0.1989406 Test Loss: 0.3202507\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Updating learning rate to 0.0028509933688740906\n",
      "\titers: 100, epoch: 17 | loss: 0.5345525\n",
      "\tspeed: 2.6191s/iter; left time: 234264.8325s\n",
      "\titers: 200, epoch: 17 | loss: 0.2078852\n",
      "\tspeed: 0.2651s/iter; left time: 23681.0574s\n",
      "\titers: 300, epoch: 17 | loss: 0.5673416\n",
      "\tspeed: 0.2699s/iter; left time: 24090.0310s\n",
      "\titers: 400, epoch: 17 | loss: 0.3532003\n",
      "\tspeed: 0.2710s/iter; left time: 24154.7863s\n",
      "\titers: 500, epoch: 17 | loss: 0.2853062\n",
      "\tspeed: 0.2741s/iter; left time: 24407.3002s\n",
      "\titers: 600, epoch: 17 | loss: 0.2476515\n",
      "\tspeed: 0.2650s/iter; left time: 23568.1352s\n",
      "\titers: 700, epoch: 17 | loss: 0.2295499\n",
      "\tspeed: 0.2649s/iter; left time: 23533.7581s\n",
      "\titers: 800, epoch: 17 | loss: 0.4085859\n",
      "\tspeed: 0.2631s/iter; left time: 23352.2456s\n",
      "\titers: 900, epoch: 17 | loss: 0.2396139\n",
      "\tspeed: 0.2671s/iter; left time: 23674.2031s\n",
      "\titers: 1000, epoch: 17 | loss: 0.2454523\n",
      "\tspeed: 0.2689s/iter; left time: 23805.4822s\n",
      "Epoch: 17 cost time: 284.49635195732117\n",
      "Epoch: 17, Steps: 1066 | Train Loss: 0.2756459 Vali Loss: 0.1819532 Test Loss: 0.2423022\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Updating learning rate to 0.0030991187429578564\n",
      "\titers: 100, epoch: 18 | loss: 0.3119348\n",
      "\tspeed: 2.9690s/iter; left time: 262398.0699s\n",
      "\titers: 200, epoch: 18 | loss: 0.1973820\n",
      "\tspeed: 0.4140s/iter; left time: 36550.6573s\n",
      "\titers: 300, epoch: 18 | loss: 0.2497191\n",
      "\tspeed: 0.4140s/iter; left time: 36503.0949s\n",
      "\titers: 400, epoch: 18 | loss: 0.2718412\n",
      "\tspeed: 0.4160s/iter; left time: 36638.4223s\n",
      "\titers: 500, epoch: 18 | loss: 0.2290253\n",
      "\tspeed: 0.4221s/iter; left time: 37132.6064s\n",
      "\titers: 600, epoch: 18 | loss: 0.4405615\n",
      "\tspeed: 0.4109s/iter; left time: 36112.3026s\n",
      "\titers: 700, epoch: 18 | loss: 0.3351813\n",
      "\tspeed: 0.4140s/iter; left time: 36344.6746s\n",
      "\titers: 800, epoch: 18 | loss: 0.2355337\n",
      "\tspeed: 0.4140s/iter; left time: 36297.1419s\n",
      "\titers: 900, epoch: 18 | loss: 0.1822532\n",
      "\tspeed: 0.3810s/iter; left time: 33364.1184s\n",
      "\titers: 1000, epoch: 18 | loss: 0.2139062\n",
      "\tspeed: 0.2672s/iter; left time: 23371.0253s\n",
      "Epoch: 18 cost time: 414.80179500579834\n",
      "Epoch: 18, Steps: 1066 | Train Loss: 0.2652238 Vali Loss: 0.2524862 Test Loss: 0.5206528\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Updating learning rate to 0.003341775325951213\n",
      "\titers: 100, epoch: 19 | loss: 0.4394006\n",
      "\tspeed: 2.6399s/iter; left time: 230499.3669s\n",
      "\titers: 200, epoch: 19 | loss: 0.3222133\n",
      "\tspeed: 0.2789s/iter; left time: 24323.9414s\n",
      "\titers: 300, epoch: 19 | loss: 0.2704137\n",
      "\tspeed: 0.2730s/iter; left time: 23780.1845s\n",
      "\titers: 400, epoch: 19 | loss: 0.3901059\n",
      "\tspeed: 0.2791s/iter; left time: 24286.7306s\n",
      "\titers: 500, epoch: 19 | loss: 0.3046368\n",
      "\tspeed: 0.2780s/iter; left time: 24161.2926s\n",
      "\titers: 600, epoch: 19 | loss: 0.3035545\n",
      "\tspeed: 0.2790s/iter; left time: 24221.3565s\n",
      "\titers: 700, epoch: 19 | loss: 0.1874596\n",
      "\tspeed: 0.2760s/iter; left time: 23936.9469s\n",
      "\titers: 800, epoch: 19 | loss: 0.2247351\n",
      "\tspeed: 0.2749s/iter; left time: 23809.6729s\n",
      "\titers: 900, epoch: 19 | loss: 0.2190988\n",
      "\tspeed: 0.2761s/iter; left time: 23885.7454s\n",
      "\titers: 1000, epoch: 19 | loss: 0.2707915\n",
      "\tspeed: 0.2760s/iter; left time: 23845.8476s\n",
      "Epoch: 19 cost time: 294.2967736721039\n",
      "Epoch: 19, Steps: 1066 | Train Loss: 0.2710572 Vali Loss: 0.1892835 Test Loss: 0.3016997\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Updating learning rate to 0.0035763043554297314\n",
      "\titers: 100, epoch: 20 | loss: 0.2117171\n",
      "\tspeed: 2.1690s/iter; left time: 187069.5447s\n",
      "\titers: 200, epoch: 20 | loss: 0.1726866\n",
      "\tspeed: 0.2720s/iter; left time: 23435.0296s\n",
      "\titers: 300, epoch: 20 | loss: 0.3039850\n",
      "\tspeed: 0.2749s/iter; left time: 23658.1852s\n",
      "\titers: 400, epoch: 20 | loss: 0.2580447\n",
      "\tspeed: 0.2750s/iter; left time: 23636.2637s\n",
      "\titers: 500, epoch: 20 | loss: 0.2527491\n",
      "\tspeed: 0.2801s/iter; left time: 24042.8950s\n",
      "\titers: 600, epoch: 20 | loss: 0.2306198\n",
      "\tspeed: 0.2800s/iter; left time: 24007.9242s\n",
      "\titers: 700, epoch: 20 | loss: 0.2330405\n",
      "\tspeed: 0.2760s/iter; left time: 23635.9427s\n",
      "\titers: 800, epoch: 20 | loss: 0.2122389\n",
      "\tspeed: 0.2760s/iter; left time: 23612.6521s\n",
      "\titers: 900, epoch: 20 | loss: 0.2337476\n",
      "\tspeed: 0.2710s/iter; left time: 23154.6443s\n",
      "\titers: 1000, epoch: 20 | loss: 0.2447263\n",
      "\tspeed: 0.2769s/iter; left time: 23635.1523s\n",
      "Epoch: 20 cost time: 294.20402097702026\n",
      "Epoch: 20, Steps: 1066 | Train Loss: 0.2676569 Vali Loss: 0.1926913 Test Loss: 0.2642385\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Updating learning rate to 0.0038001361217101953\n",
      "\titers: 100, epoch: 21 | loss: 0.1957992\n",
      "\tspeed: 2.1810s/iter; left time: 185778.0930s\n",
      "\titers: 200, epoch: 21 | loss: 0.2134422\n",
      "\tspeed: 0.2650s/iter; left time: 22547.5987s\n",
      "\titers: 300, epoch: 21 | loss: 0.7960088\n",
      "\tspeed: 0.2709s/iter; left time: 23025.1674s\n",
      "\titers: 400, epoch: 21 | loss: 0.3323655\n",
      "\tspeed: 0.2761s/iter; left time: 23436.3278s\n",
      "\titers: 500, epoch: 21 | loss: 0.1806756\n",
      "\tspeed: 0.2779s/iter; left time: 23564.6777s\n",
      "\titers: 600, epoch: 21 | loss: 0.1712127\n",
      "\tspeed: 0.2779s/iter; left time: 23536.5686s\n",
      "\titers: 700, epoch: 21 | loss: 0.2469489\n",
      "\tspeed: 0.2800s/iter; left time: 23682.8792s\n",
      "\titers: 800, epoch: 21 | loss: 0.2713534\n",
      "\tspeed: 0.2701s/iter; left time: 22817.1408s\n",
      "\titers: 900, epoch: 21 | loss: 0.1884659\n",
      "\tspeed: 0.2710s/iter; left time: 22864.6603s\n",
      "\titers: 1000, epoch: 21 | loss: 0.2533419\n",
      "\tspeed: 0.2750s/iter; left time: 23179.1685s\n",
      "Epoch: 21 cost time: 291.3894066810608\n",
      "Epoch: 21, Steps: 1066 | Train Loss: 0.2664154 Vali Loss: 0.1906554 Test Loss: 0.2679572\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Updating learning rate to 0.004010818123886844\n",
      "\titers: 100, epoch: 22 | loss: 0.2430350\n",
      "\tspeed: 2.1760s/iter; left time: 183032.0885s\n",
      "\titers: 200, epoch: 22 | loss: 0.3731807\n",
      "\tspeed: 0.2721s/iter; left time: 22856.5098s\n",
      "\titers: 300, epoch: 22 | loss: 0.2487144\n",
      "\tspeed: 0.2680s/iter; left time: 22488.3881s\n",
      "\titers: 400, epoch: 22 | loss: 0.1862456\n",
      "\tspeed: 0.2759s/iter; left time: 23124.0794s\n",
      "\titers: 500, epoch: 22 | loss: 0.5277009\n",
      "\tspeed: 0.2702s/iter; left time: 22620.0191s\n",
      "\titers: 600, epoch: 22 | loss: 0.2616296\n",
      "\tspeed: 0.2699s/iter; left time: 22565.3272s\n",
      "\titers: 700, epoch: 22 | loss: 0.2574030\n",
      "\tspeed: 0.2720s/iter; left time: 22720.0524s\n",
      "\titers: 800, epoch: 22 | loss: 0.1782667\n",
      "\tspeed: 0.2749s/iter; left time: 22932.5489s\n",
      "\titers: 900, epoch: 22 | loss: 0.3333224\n",
      "\tspeed: 0.2810s/iter; left time: 23412.1488s\n",
      "\titers: 1000, epoch: 22 | loss: 0.2319219\n",
      "\tspeed: 0.2731s/iter; left time: 22728.2397s\n",
      "Epoch: 22 cost time: 290.7987322807312\n",
      "Epoch: 22, Steps: 1066 | Train Loss: 0.2662281 Vali Loss: 0.1908246 Test Loss: 0.3027450\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Updating learning rate to 0.004206041941623496\n",
      "\titers: 100, epoch: 23 | loss: 0.2856872\n",
      "\tspeed: 2.1770s/iter; left time: 180798.8577s\n",
      "\titers: 200, epoch: 23 | loss: 0.3491185\n",
      "\tspeed: 0.2689s/iter; left time: 22308.6500s\n",
      "\titers: 300, epoch: 23 | loss: 0.3366828\n",
      "\tspeed: 0.2739s/iter; left time: 22693.8199s\n",
      "\titers: 400, epoch: 23 | loss: 0.2652519\n",
      "\tspeed: 0.2702s/iter; left time: 22355.3075s\n",
      "\titers: 500, epoch: 23 | loss: 0.1966667\n",
      "\tspeed: 0.2698s/iter; left time: 22298.7160s\n",
      "\titers: 600, epoch: 23 | loss: 0.3015938\n",
      "\tspeed: 0.2732s/iter; left time: 22548.6290s\n",
      "\titers: 700, epoch: 23 | loss: 0.6052324\n",
      "\tspeed: 0.2801s/iter; left time: 23097.4871s\n",
      "\titers: 800, epoch: 23 | loss: 0.2284927\n",
      "\tspeed: 0.2778s/iter; left time: 22874.9259s\n",
      "\titers: 900, epoch: 23 | loss: 0.2578394\n",
      "\tspeed: 0.2769s/iter; left time: 22775.9086s\n",
      "\titers: 1000, epoch: 23 | loss: 0.1582117\n",
      "\tspeed: 0.2750s/iter; left time: 22593.1643s\n",
      "Epoch: 23 cost time: 293.2971839904785\n",
      "Epoch: 23, Steps: 1066 | Train Loss: 0.2777782 Vali Loss: 0.1934243 Test Loss: 0.2866743\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): PatchTST_backbone(\n",
       "    (backbone): TSTiEncoder(\n",
       "      (W_P): Linear(in_features=16, out_features=128, bias=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (encoder): TSTEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-2): 3 x TSTEncoderLayer(\n",
       "            (self_attn): _MultiheadAttention(\n",
       "              (W_Q): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (W_K): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (W_V): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (sdp_attn): _ScaledDotProductAttention(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (dropout_attn): Dropout(p=0.2, inplace=False)\n",
       "            (norm_attn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.2, inplace=False)\n",
       "              (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "            )\n",
       "            (dropout_ffn): Dropout(p=0.2, inplace=False)\n",
       "            (norm_ffn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): Flatten_Head(\n",
       "      (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "      (linear): Linear(in_features=5248, out_features=96, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exp = Exp_Main\n",
    "setting=f'PatchTST_train_on_{args.data}_{args.pred_len}'\n",
    "# set experiments\n",
    "exp = Exp(args)\n",
    "exp.train(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd9c1e1",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8207eaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 11425\n",
      "mse:0.19508586823940277, mae:0.2823296785354614, rse:0.3580951392650604\n"
     ]
    }
   ],
   "source": [
    "exp.test(setting)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bd3286",
   "metadata": {},
   "source": [
    "---\n",
    "## Trail 2: PatchTST, Dataset:ETTm2,  Metric: 192\n",
    "### Set hyperparameters\n",
    "Set some parameters (Args) for the our experiment like dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "485a67e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ETTm2,  Prediction Length : 192\n"
     ]
    }
   ],
   "source": [
    "args.pred_len = 192 # prediction sequence length\n",
    "print(f\"Dataset: {args.data},  Prediction Length : {args.pred_len}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f77dcdc",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c3feac6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "train 34033\n",
      "val 11329\n",
      "test 11329\n",
      "\titers: 100, epoch: 1 | loss: 0.3124763\n",
      "\tspeed: 0.0878s/iter; left time: 9321.1883s\n",
      "\titers: 200, epoch: 1 | loss: 0.3796742\n",
      "\tspeed: 0.0962s/iter; left time: 10207.2771s\n",
      "\titers: 300, epoch: 1 | loss: 0.3381073\n",
      "\tspeed: 0.0900s/iter; left time: 9538.5721s\n",
      "\titers: 400, epoch: 1 | loss: 0.4121913\n",
      "\tspeed: 0.0940s/iter; left time: 9956.7004s\n",
      "\titers: 500, epoch: 1 | loss: 0.3012684\n",
      "\tspeed: 0.0931s/iter; left time: 9846.1644s\n",
      "\titers: 600, epoch: 1 | loss: 0.2452905\n",
      "\tspeed: 0.0860s/iter; left time: 9093.2682s\n",
      "\titers: 700, epoch: 1 | loss: 0.3639145\n",
      "\tspeed: 0.0910s/iter; left time: 9606.1875s\n",
      "\titers: 800, epoch: 1 | loss: 0.2285268\n",
      "\tspeed: 0.0852s/iter; left time: 8986.0999s\n",
      "\titers: 900, epoch: 1 | loss: 0.2316541\n",
      "\tspeed: 0.0889s/iter; left time: 9366.8485s\n",
      "\titers: 1000, epoch: 1 | loss: 0.3153989\n",
      "\tspeed: 0.0930s/iter; left time: 9797.8035s\n",
      "Epoch: 1 cost time: 96.19215726852417\n",
      "Epoch: 1, Steps: 1063 | Train Loss: 0.3403623 Vali Loss: 0.1967488 Test Loss: 0.2710284\n",
      "Validation loss decreased (inf --> 0.196749).  Saving model ...\n",
      "Updating learning rate to 0.0002131482749512777\n",
      "\titers: 100, epoch: 2 | loss: 0.2281117\n",
      "\tspeed: 1.8649s/iter; left time: 196067.0105s\n",
      "\titers: 200, epoch: 2 | loss: 0.3518193\n",
      "\tspeed: 0.0872s/iter; left time: 9161.3539s\n",
      "\titers: 300, epoch: 2 | loss: 0.2029787\n",
      "\tspeed: 0.0897s/iter; left time: 9413.0552s\n",
      "\titers: 400, epoch: 2 | loss: 0.4842460\n",
      "\tspeed: 0.0931s/iter; left time: 9761.1841s\n",
      "\titers: 500, epoch: 2 | loss: 0.2666498\n",
      "\tspeed: 0.1039s/iter; left time: 10884.4151s\n",
      "\titers: 600, epoch: 2 | loss: 0.2610039\n",
      "\tspeed: 0.0959s/iter; left time: 10032.9437s\n",
      "\titers: 700, epoch: 2 | loss: 0.3615511\n",
      "\tspeed: 0.0950s/iter; left time: 9926.4610s\n",
      "\titers: 800, epoch: 2 | loss: 0.3226240\n",
      "\tspeed: 0.0970s/iter; left time: 10130.9723s\n",
      "\titers: 900, epoch: 2 | loss: 0.2739692\n",
      "\tspeed: 0.0944s/iter; left time: 9852.7369s\n",
      "\titers: 1000, epoch: 2 | loss: 0.2100141\n",
      "\tspeed: 0.1096s/iter; left time: 11425.1541s\n",
      "Epoch: 2 cost time: 101.59554195404053\n",
      "Epoch: 2, Steps: 1063 | Train Loss: 0.2856421 Vali Loss: 0.1753528 Test Loss: 0.2446045\n",
      "Validation loss decreased (0.196749 --> 0.175353).  Saving model ...\n",
      "Updating learning rate to 0.0002524490355266156\n",
      "\titers: 100, epoch: 3 | loss: 0.2242823\n",
      "\tspeed: 3.3030s/iter; left time: 343762.0589s\n",
      "\titers: 200, epoch: 3 | loss: 0.2942918\n",
      "\tspeed: 0.3900s/iter; left time: 40546.5516s\n",
      "\titers: 300, epoch: 3 | loss: 0.1873042\n",
      "\tspeed: 0.3820s/iter; left time: 39685.3525s\n",
      "\titers: 400, epoch: 3 | loss: 0.2698720\n",
      "\tspeed: 0.3910s/iter; left time: 40574.3791s\n",
      "\titers: 500, epoch: 3 | loss: 0.1852386\n",
      "\tspeed: 0.3860s/iter; left time: 40023.4975s\n",
      "\titers: 600, epoch: 3 | loss: 0.2042091\n",
      "\tspeed: 0.3950s/iter; left time: 40916.4959s\n",
      "\titers: 700, epoch: 3 | loss: 0.3016474\n",
      "\tspeed: 0.3870s/iter; left time: 40041.6349s\n",
      "\titers: 800, epoch: 3 | loss: 0.2564363\n",
      "\tspeed: 0.3990s/iter; left time: 41245.8147s\n",
      "\titers: 900, epoch: 3 | loss: 0.3009569\n",
      "\tspeed: 0.2750s/iter; left time: 28404.3536s\n",
      "\titers: 1000, epoch: 3 | loss: 0.1877891\n",
      "\tspeed: 0.0930s/iter; left time: 9600.1610s\n",
      "Epoch: 3 cost time: 355.9111547470093\n",
      "Epoch: 3, Steps: 1063 | Train Loss: 0.2674528 Vali Loss: 0.1835992 Test Loss: 0.2768622\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Updating learning rate to 0.0003174716673878166\n",
      "\titers: 100, epoch: 4 | loss: 0.2031191\n",
      "\tspeed: 1.9620s/iter; left time: 202113.5861s\n",
      "\titers: 200, epoch: 4 | loss: 0.2687604\n",
      "\tspeed: 0.0990s/iter; left time: 10189.6714s\n",
      "\titers: 300, epoch: 4 | loss: 0.2728185\n",
      "\tspeed: 0.0950s/iter; left time: 9768.6965s\n",
      "\titers: 400, epoch: 4 | loss: 0.1929307\n",
      "\tspeed: 0.0878s/iter; left time: 9015.4911s\n",
      "\titers: 500, epoch: 4 | loss: 0.2225536\n",
      "\tspeed: 0.0942s/iter; left time: 9662.7010s\n",
      "\titers: 600, epoch: 4 | loss: 0.1816235\n",
      "\tspeed: 0.0948s/iter; left time: 9717.5677s\n",
      "\titers: 700, epoch: 4 | loss: 0.2501734\n",
      "\tspeed: 0.1033s/iter; left time: 10575.7075s\n",
      "\titers: 800, epoch: 4 | loss: 0.3988492\n",
      "\tspeed: 0.0987s/iter; left time: 10102.6207s\n",
      "\titers: 900, epoch: 4 | loss: 0.1990785\n",
      "\tspeed: 0.1040s/iter; left time: 10628.7926s\n",
      "\titers: 1000, epoch: 4 | loss: 0.2532085\n",
      "\tspeed: 0.1033s/iter; left time: 10545.5154s\n",
      "Epoch: 4 cost time: 104.20960354804993\n",
      "Epoch: 4, Steps: 1063 | Train Loss: 0.2522621 Vali Loss: 0.1777454 Test Loss: 0.2497053\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Updating learning rate to 0.0004075037243334058\n",
      "\titers: 100, epoch: 5 | loss: 0.2339256\n",
      "\tspeed: 2.0171s/iter; left time: 205638.3621s\n",
      "\titers: 200, epoch: 5 | loss: 0.2880846\n",
      "\tspeed: 0.0969s/iter; left time: 9871.2208s\n",
      "\titers: 300, epoch: 5 | loss: 0.1911021\n",
      "\tspeed: 0.0888s/iter; left time: 9030.3538s\n",
      "\titers: 400, epoch: 5 | loss: 0.2329271\n",
      "\tspeed: 0.0911s/iter; left time: 9261.6401s\n",
      "\titers: 500, epoch: 5 | loss: 0.1702241\n",
      "\tspeed: 0.0961s/iter; left time: 9754.7071s\n",
      "\titers: 600, epoch: 5 | loss: 0.1602678\n",
      "\tspeed: 0.0930s/iter; left time: 9436.4646s\n",
      "\titers: 700, epoch: 5 | loss: 0.1796533\n",
      "\tspeed: 0.0898s/iter; left time: 9102.9394s\n",
      "\titers: 800, epoch: 5 | loss: 0.1825186\n",
      "\tspeed: 0.0862s/iter; left time: 8732.2794s\n",
      "\titers: 900, epoch: 5 | loss: 0.2774276\n",
      "\tspeed: 0.0957s/iter; left time: 9683.3340s\n",
      "\titers: 1000, epoch: 5 | loss: 0.1666816\n",
      "\tspeed: 0.0963s/iter; left time: 9732.3328s\n",
      "Epoch: 5 cost time: 99.03519916534424\n",
      "Epoch: 5, Steps: 1063 | Train Loss: 0.2424493 Vali Loss: 0.1972537 Test Loss: 0.2853675\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Updating learning rate to 0.0005215587344974256\n",
      "\titers: 100, epoch: 6 | loss: 0.1698690\n",
      "\tspeed: 1.9237s/iter; left time: 194076.5073s\n",
      "\titers: 200, epoch: 6 | loss: 0.2414351\n",
      "\tspeed: 0.1000s/iter; left time: 10081.9809s\n",
      "\titers: 300, epoch: 6 | loss: 0.2521616\n",
      "\tspeed: 0.0971s/iter; left time: 9780.6023s\n",
      "\titers: 400, epoch: 6 | loss: 0.2388376\n",
      "\tspeed: 0.0911s/iter; left time: 9162.7380s\n",
      "\titers: 500, epoch: 6 | loss: 0.1886344\n",
      "\tspeed: 0.1010s/iter; left time: 10150.4180s\n",
      "\titers: 600, epoch: 6 | loss: 0.1891562\n",
      "\tspeed: 0.0929s/iter; left time: 9330.7622s\n",
      "\titers: 700, epoch: 6 | loss: 0.3711707\n",
      "\tspeed: 0.0958s/iter; left time: 9602.7026s\n",
      "\titers: 800, epoch: 6 | loss: 0.2910411\n",
      "\tspeed: 0.0940s/iter; left time: 9417.7287s\n",
      "\titers: 900, epoch: 6 | loss: 0.2096024\n",
      "\tspeed: 0.0940s/iter; left time: 9410.4183s\n",
      "\titers: 1000, epoch: 6 | loss: 0.2499814\n",
      "\tspeed: 0.1021s/iter; left time: 10204.0542s\n",
      "Epoch: 6 cost time: 101.82003402709961\n",
      "Epoch: 6, Steps: 1063 | Train Loss: 0.2326663 Vali Loss: 0.2050723 Test Loss: 0.3579863\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Updating learning rate to 0.0006583870090188714\n",
      "\titers: 100, epoch: 7 | loss: 0.2705721\n",
      "\tspeed: 2.7289s/iter; left time: 272410.2142s\n",
      "\titers: 200, epoch: 7 | loss: 0.1623830\n",
      "\tspeed: 0.1163s/iter; left time: 11595.5522s\n",
      "\titers: 300, epoch: 7 | loss: 0.1716653\n",
      "\tspeed: 0.1030s/iter; left time: 10264.2311s\n",
      "\titers: 400, epoch: 7 | loss: 0.2135610\n",
      "\tspeed: 0.1038s/iter; left time: 10331.1557s\n",
      "\titers: 500, epoch: 7 | loss: 0.1663377\n",
      "\tspeed: 0.1099s/iter; left time: 10926.6550s\n",
      "\titers: 600, epoch: 7 | loss: 0.2071665\n",
      "\tspeed: 0.1173s/iter; left time: 11647.4294s\n",
      "\titers: 700, epoch: 7 | loss: 0.2152469\n",
      "\tspeed: 0.1050s/iter; left time: 10414.0816s\n",
      "\titers: 800, epoch: 7 | loss: 0.2611154\n",
      "\tspeed: 0.1050s/iter; left time: 10403.4900s\n",
      "\titers: 900, epoch: 7 | loss: 0.2666175\n",
      "\tspeed: 0.0990s/iter; left time: 9801.0260s\n",
      "\titers: 1000, epoch: 7 | loss: 0.2540214\n",
      "\tspeed: 0.1070s/iter; left time: 10585.7728s\n",
      "Epoch: 7 cost time: 113.50444602966309\n",
      "Epoch: 7, Steps: 1063 | Train Loss: 0.2271946 Vali Loss: 0.1958878 Test Loss: 0.2944368\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Updating learning rate to 0.000816489334752311\n",
      "\titers: 100, epoch: 8 | loss: 0.3183868\n",
      "\tspeed: 2.3789s/iter; left time: 234938.4438s\n",
      "\titers: 200, epoch: 8 | loss: 0.2243003\n",
      "\tspeed: 0.1051s/iter; left time: 10365.2537s\n",
      "\titers: 300, epoch: 8 | loss: 0.1858455\n",
      "\tspeed: 0.1111s/iter; left time: 10947.0600s\n",
      "\titers: 400, epoch: 8 | loss: 0.2559542\n",
      "\tspeed: 0.1072s/iter; left time: 10550.7025s\n",
      "\titers: 500, epoch: 8 | loss: 0.2338331\n",
      "\tspeed: 0.0968s/iter; left time: 9520.6841s\n",
      "\titers: 600, epoch: 8 | loss: 0.2031990\n",
      "\tspeed: 0.0961s/iter; left time: 9440.9129s\n",
      "\titers: 700, epoch: 8 | loss: 0.1892611\n",
      "\tspeed: 0.0978s/iter; left time: 9600.7009s\n",
      "\titers: 800, epoch: 8 | loss: 0.2181173\n",
      "\tspeed: 0.0972s/iter; left time: 9531.0760s\n",
      "\titers: 900, epoch: 8 | loss: 0.2394966\n",
      "\tspeed: 0.1088s/iter; left time: 10657.4278s\n",
      "\titers: 1000, epoch: 8 | loss: 0.2818621\n",
      "\tspeed: 0.0862s/iter; left time: 8438.2337s\n",
      "Epoch: 8 cost time: 109.20076179504395\n",
      "Epoch: 8, Steps: 1063 | Train Loss: 0.2237331 Vali Loss: 0.2035532 Test Loss: 0.3018684\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Updating learning rate to 0.0009941334009900956\n",
      "\titers: 100, epoch: 9 | loss: 0.1351460\n",
      "\tspeed: 2.2318s/iter; left time: 218042.2967s\n",
      "\titers: 200, epoch: 9 | loss: 0.2176486\n",
      "\tspeed: 0.0931s/iter; left time: 9087.4273s\n",
      "\titers: 300, epoch: 9 | loss: 0.2180275\n",
      "\tspeed: 0.0968s/iter; left time: 9438.0839s\n",
      "\titers: 400, epoch: 9 | loss: 0.1929881\n",
      "\tspeed: 0.0982s/iter; left time: 9567.9774s\n",
      "\titers: 500, epoch: 9 | loss: 0.1679625\n",
      "\tspeed: 0.1157s/iter; left time: 11260.8965s\n",
      "\titers: 600, epoch: 9 | loss: 0.1991687\n",
      "\tspeed: 0.0960s/iter; left time: 9330.9087s\n",
      "\titers: 700, epoch: 9 | loss: 0.2171101\n",
      "\tspeed: 0.1012s/iter; left time: 9825.3591s\n",
      "\titers: 800, epoch: 9 | loss: 0.1932411\n",
      "\tspeed: 0.0959s/iter; left time: 9305.3234s\n",
      "\titers: 900, epoch: 9 | loss: 0.4569197\n",
      "\tspeed: 0.0992s/iter; left time: 9614.0487s\n",
      "\titers: 1000, epoch: 9 | loss: 0.1609016\n",
      "\tspeed: 0.1009s/iter; left time: 9766.7671s\n",
      "Epoch: 9 cost time: 106.88720393180847\n",
      "Epoch: 9, Steps: 1063 | Train Loss: 0.2203389 Vali Loss: 0.2000832 Test Loss: 0.2715221\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Updating learning rate to 0.0011893727802102599\n",
      "\titers: 100, epoch: 10 | loss: 0.2394937\n",
      "\tspeed: 2.3430s/iter; left time: 226412.9327s\n",
      "\titers: 200, epoch: 10 | loss: 0.2477372\n",
      "\tspeed: 0.1060s/iter; left time: 10235.9847s\n",
      "\titers: 300, epoch: 10 | loss: 0.1761660\n",
      "\tspeed: 0.0989s/iter; left time: 9542.0760s\n",
      "\titers: 400, epoch: 10 | loss: 0.2609574\n",
      "\tspeed: 0.0980s/iter; left time: 9436.6839s\n",
      "\titers: 500, epoch: 10 | loss: 0.2826767\n",
      "\tspeed: 0.1019s/iter; left time: 9804.5078s\n",
      "\titers: 600, epoch: 10 | loss: 0.2566098\n",
      "\tspeed: 0.1039s/iter; left time: 9992.6615s\n",
      "\titers: 700, epoch: 10 | loss: 0.1924226\n",
      "\tspeed: 0.1022s/iter; left time: 9814.4942s\n",
      "\titers: 800, epoch: 10 | loss: 0.4292867\n",
      "\tspeed: 0.1001s/iter; left time: 9602.9623s\n",
      "\titers: 900, epoch: 10 | loss: 0.2529979\n",
      "\tspeed: 0.0957s/iter; left time: 9175.6664s\n",
      "\titers: 1000, epoch: 10 | loss: 0.1892515\n",
      "\tspeed: 0.1113s/iter; left time: 10651.0929s\n",
      "Epoch: 10 cost time: 110.99022316932678\n",
      "Epoch: 10, Steps: 1063 | Train Loss: 0.2678569 Vali Loss: 0.2057982 Test Loss: 0.3638391\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Updating learning rate to 0.0014000682548800506\n",
      "\titers: 100, epoch: 11 | loss: 0.2337417\n",
      "\tspeed: 2.3687s/iter; left time: 226378.6491s\n",
      "\titers: 200, epoch: 11 | loss: 0.2454593\n",
      "\tspeed: 0.1112s/iter; left time: 10617.6639s\n",
      "\titers: 300, epoch: 11 | loss: 0.2233463\n",
      "\tspeed: 0.1011s/iter; left time: 9641.5985s\n",
      "\titers: 400, epoch: 11 | loss: 0.2899923\n",
      "\tspeed: 0.1059s/iter; left time: 10088.5138s\n",
      "\titers: 500, epoch: 11 | loss: 0.3736537\n",
      "\tspeed: 0.1139s/iter; left time: 10843.2592s\n",
      "\titers: 600, epoch: 11 | loss: 0.3304113\n",
      "\tspeed: 0.1101s/iter; left time: 10465.0599s\n",
      "\titers: 700, epoch: 11 | loss: 0.3684672\n",
      "\tspeed: 0.1288s/iter; left time: 12232.4956s\n",
      "\titers: 800, epoch: 11 | loss: 0.1974131\n",
      "\tspeed: 0.1173s/iter; left time: 11128.4868s\n",
      "\titers: 900, epoch: 11 | loss: 0.2057974\n",
      "\tspeed: 0.1257s/iter; left time: 11913.5265s\n",
      "\titers: 1000, epoch: 11 | loss: 0.2102413\n",
      "\tspeed: 0.1150s/iter; left time: 10887.9554s\n",
      "Epoch: 11 cost time: 120.70794343948364\n",
      "Epoch: 11, Steps: 1063 | Train Loss: 0.2764897 Vali Loss: 0.1859709 Test Loss: 0.2762768\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Updating learning rate to 0.0016239112566395117\n",
      "\titers: 100, epoch: 12 | loss: 0.3195765\n",
      "\tspeed: 2.2290s/iter; left time: 210662.8109s\n",
      "\titers: 200, epoch: 12 | loss: 0.3299564\n",
      "\tspeed: 0.1161s/iter; left time: 10965.1932s\n",
      "\titers: 300, epoch: 12 | loss: 0.3039523\n",
      "\tspeed: 0.1091s/iter; left time: 10288.5759s\n",
      "\titers: 400, epoch: 12 | loss: 0.3250135\n",
      "\tspeed: 0.1087s/iter; left time: 10243.2429s\n",
      "\titers: 500, epoch: 12 | loss: 0.3434088\n",
      "\tspeed: 0.1042s/iter; left time: 9807.2949s\n",
      "\titers: 600, epoch: 12 | loss: 0.2313672\n",
      "\tspeed: 0.1037s/iter; left time: 9751.9924s\n",
      "\titers: 700, epoch: 12 | loss: 0.3830277\n",
      "\tspeed: 0.1052s/iter; left time: 9883.6995s\n",
      "\titers: 800, epoch: 12 | loss: 0.2406300\n",
      "\tspeed: 0.0990s/iter; left time: 9286.4714s\n",
      "\titers: 900, epoch: 12 | loss: 0.2719788\n",
      "\tspeed: 0.1060s/iter; left time: 9928.8137s\n",
      "\titers: 1000, epoch: 12 | loss: 0.5771335\n",
      "\tspeed: 0.0960s/iter; left time: 8989.3099s\n",
      "Epoch: 12 cost time: 112.5012092590332\n",
      "Epoch: 12, Steps: 1063 | Train Loss: 0.3013951 Vali Loss: 0.2266076 Test Loss: 0.3293654\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Updating learning rate to 0.0018584491610444316\n",
      "\titers: 100, epoch: 13 | loss: 0.2405906\n",
      "\tspeed: 2.3868s/iter; left time: 223030.7469s\n",
      "\titers: 200, epoch: 13 | loss: 0.5273322\n",
      "\tspeed: 0.1082s/iter; left time: 10098.7053s\n",
      "\titers: 300, epoch: 13 | loss: 0.2854801\n",
      "\tspeed: 0.0918s/iter; left time: 8562.0353s\n",
      "\titers: 400, epoch: 13 | loss: 0.3367800\n",
      "\tspeed: 0.1062s/iter; left time: 9892.8774s\n",
      "\titers: 500, epoch: 13 | loss: 0.1928395\n",
      "\tspeed: 0.0990s/iter; left time: 9210.7255s\n",
      "\titers: 600, epoch: 13 | loss: 0.2746867\n",
      "\tspeed: 0.1008s/iter; left time: 9372.2863s\n",
      "\titers: 700, epoch: 13 | loss: 0.2590524\n",
      "\tspeed: 0.1032s/iter; left time: 9583.2597s\n",
      "\titers: 800, epoch: 13 | loss: 0.2513372\n",
      "\tspeed: 0.1087s/iter; left time: 10085.6738s\n",
      "\titers: 900, epoch: 13 | loss: 0.6736512\n",
      "\tspeed: 0.1060s/iter; left time: 9819.7276s\n",
      "\titers: 1000, epoch: 13 | loss: 0.3505722\n",
      "\tspeed: 0.0951s/iter; left time: 8804.8773s\n",
      "Epoch: 13 cost time: 110.3233802318573\n",
      "Epoch: 13, Steps: 1063 | Train Loss: 0.3151652 Vali Loss: 0.2353366 Test Loss: 0.3675754\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Updating learning rate to 0.0021011121607168\n",
      "\titers: 100, epoch: 14 | loss: 0.3477822\n",
      "\tspeed: 2.1040s/iter; left time: 194374.3245s\n",
      "\titers: 200, epoch: 14 | loss: 0.2850129\n",
      "\tspeed: 0.1060s/iter; left time: 9779.7841s\n",
      "\titers: 300, epoch: 14 | loss: 0.2891188\n",
      "\tspeed: 0.1140s/iter; left time: 10508.2556s\n",
      "\titers: 400, epoch: 14 | loss: 0.3304399\n",
      "\tspeed: 0.1032s/iter; left time: 9502.7879s\n",
      "\titers: 500, epoch: 14 | loss: 0.5112638\n",
      "\tspeed: 0.1097s/iter; left time: 10086.1203s\n",
      "\titers: 600, epoch: 14 | loss: 0.2540327\n",
      "\tspeed: 0.0943s/iter; left time: 8661.0791s\n",
      "\titers: 700, epoch: 14 | loss: 0.3350054\n",
      "\tspeed: 0.0999s/iter; left time: 9171.5864s\n",
      "\titers: 800, epoch: 14 | loss: 0.5205640\n",
      "\tspeed: 0.0878s/iter; left time: 8053.9470s\n",
      "\titers: 900, epoch: 14 | loss: 0.2941037\n",
      "\tspeed: 0.0972s/iter; left time: 8905.8234s\n",
      "\titers: 1000, epoch: 14 | loss: 0.3540082\n",
      "\tspeed: 0.1020s/iter; left time: 9331.8919s\n",
      "Epoch: 14 cost time: 108.41584944725037\n",
      "Epoch: 14, Steps: 1063 | Train Loss: 0.3216712 Vali Loss: 0.2514035 Test Loss: 0.3674967\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Updating learning rate to 0.0023492414224564567\n",
      "\titers: 100, epoch: 15 | loss: 0.2147915\n",
      "\tspeed: 1.7729s/iter; left time: 161895.2036s\n",
      "\titers: 200, epoch: 15 | loss: 0.4917603\n",
      "\tspeed: 0.0929s/iter; left time: 8477.4029s\n",
      "\titers: 300, epoch: 15 | loss: 0.2802823\n",
      "\tspeed: 0.0919s/iter; left time: 8375.7099s\n",
      "\titers: 400, epoch: 15 | loss: 0.3274817\n",
      "\tspeed: 0.0952s/iter; left time: 8661.1530s\n",
      "\titers: 500, epoch: 15 | loss: 0.3090478\n",
      "\tspeed: 0.0958s/iter; left time: 8713.8167s\n",
      "\titers: 600, epoch: 15 | loss: 0.4494929\n",
      "\tspeed: 0.0970s/iter; left time: 8809.5087s\n",
      "\titers: 700, epoch: 15 | loss: 0.3135633\n",
      "\tspeed: 0.0870s/iter; left time: 7894.7216s\n",
      "\titers: 800, epoch: 15 | loss: 0.4032300\n",
      "\tspeed: 0.0873s/iter; left time: 7913.4963s\n",
      "\titers: 900, epoch: 15 | loss: 0.3134359\n",
      "\tspeed: 0.0919s/iter; left time: 8318.2278s\n",
      "\titers: 1000, epoch: 15 | loss: 0.2448537\n",
      "\tspeed: 0.0860s/iter; left time: 7779.4928s\n",
      "Epoch: 15 cost time: 98.3860981464386\n",
      "Epoch: 15, Steps: 1063 | Train Loss: 0.3371051 Vali Loss: 0.2484336 Test Loss: 0.4532644\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Updating learning rate to 0.0026001182197993907\n",
      "\titers: 100, epoch: 16 | loss: 0.3948284\n",
      "\tspeed: 1.6608s/iter; left time: 149897.0132s\n",
      "\titers: 200, epoch: 16 | loss: 0.1846018\n",
      "\tspeed: 0.0891s/iter; left time: 8036.2105s\n",
      "\titers: 300, epoch: 16 | loss: 0.2724224\n",
      "\tspeed: 0.0901s/iter; left time: 8110.0020s\n",
      "\titers: 400, epoch: 16 | loss: 0.3692958\n",
      "\tspeed: 0.0870s/iter; left time: 7824.7754s\n",
      "\titers: 500, epoch: 16 | loss: 0.2399341\n",
      "\tspeed: 0.0908s/iter; left time: 8160.7678s\n",
      "\titers: 600, epoch: 16 | loss: 0.4437795\n",
      "\tspeed: 0.0892s/iter; left time: 8006.9656s\n",
      "\titers: 700, epoch: 16 | loss: 0.3169717\n",
      "\tspeed: 0.0977s/iter; left time: 8760.2853s\n",
      "\titers: 800, epoch: 16 | loss: 0.2388676\n",
      "\tspeed: 0.0882s/iter; left time: 7903.0403s\n",
      "\titers: 900, epoch: 16 | loss: 0.3803713\n",
      "\tspeed: 0.0890s/iter; left time: 7963.2899s\n",
      "\titers: 1000, epoch: 16 | loss: 0.1714797\n",
      "\tspeed: 0.0978s/iter; left time: 8736.8403s\n",
      "Epoch: 16 cost time: 96.31326222419739\n",
      "Epoch: 16, Steps: 1063 | Train Loss: 0.3308497 Vali Loss: 0.2442779 Test Loss: 0.3366480\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Updating learning rate to 0.0028509937218203023\n",
      "\titers: 100, epoch: 17 | loss: 0.4247243\n",
      "\tspeed: 1.7215s/iter; left time: 153542.5662s\n",
      "\titers: 200, epoch: 17 | loss: 0.2355375\n",
      "\tspeed: 0.0955s/iter; left time: 8508.6667s\n",
      "\titers: 300, epoch: 17 | loss: 0.2033632\n",
      "\tspeed: 0.1020s/iter; left time: 9077.0781s\n",
      "\titers: 400, epoch: 17 | loss: 0.3021364\n",
      "\tspeed: 0.0921s/iter; left time: 8190.7199s\n",
      "\titers: 500, epoch: 17 | loss: 0.3703957\n",
      "\tspeed: 0.1030s/iter; left time: 9147.7246s\n",
      "\titers: 600, epoch: 17 | loss: 0.3374915\n",
      "\tspeed: 0.0990s/iter; left time: 8779.1947s\n",
      "\titers: 700, epoch: 17 | loss: 0.2029384\n",
      "\tspeed: 0.0981s/iter; left time: 8687.1457s\n",
      "\titers: 800, epoch: 17 | loss: 0.2506482\n",
      "\tspeed: 0.1001s/iter; left time: 8857.4971s\n",
      "\titers: 900, epoch: 17 | loss: 0.3351734\n",
      "\tspeed: 0.0941s/iter; left time: 8320.8842s\n",
      "\titers: 1000, epoch: 17 | loss: 0.6390423\n",
      "\tspeed: 0.0967s/iter; left time: 8542.0713s\n",
      "Epoch: 17 cost time: 103.702712059021\n",
      "Epoch: 17, Steps: 1063 | Train Loss: 0.3278184 Vali Loss: 0.4312465 Test Loss: 0.8962480\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Updating learning rate to 0.0030991191117865995\n",
      "\titers: 100, epoch: 18 | loss: 0.2967284\n",
      "\tspeed: 1.5722s/iter; left time: 138558.0757s\n",
      "\titers: 200, epoch: 18 | loss: 0.4034863\n",
      "\tspeed: 0.0979s/iter; left time: 8620.3953s\n",
      "\titers: 300, epoch: 18 | loss: 0.3834883\n",
      "\tspeed: 0.0940s/iter; left time: 8268.9167s\n",
      "\titers: 400, epoch: 18 | loss: 0.2494793\n",
      "\tspeed: 0.0930s/iter; left time: 8164.9777s\n",
      "\titers: 500, epoch: 18 | loss: 0.2143807\n",
      "\tspeed: 0.0948s/iter; left time: 8316.0196s\n",
      "\titers: 600, epoch: 18 | loss: 0.2666363\n",
      "\tspeed: 0.0909s/iter; left time: 7969.7645s\n",
      "\titers: 700, epoch: 18 | loss: 0.3773842\n",
      "\tspeed: 0.0941s/iter; left time: 8239.7654s\n",
      "\titers: 800, epoch: 18 | loss: 0.2756038\n",
      "\tspeed: 0.0968s/iter; left time: 8463.8254s\n",
      "\titers: 900, epoch: 18 | loss: 0.6182615\n",
      "\tspeed: 0.0941s/iter; left time: 8220.9855s\n",
      "\titers: 1000, epoch: 18 | loss: 0.2815792\n",
      "\tspeed: 0.0991s/iter; left time: 8647.2177s\n",
      "Epoch: 18 cost time: 101.3974621295929\n",
      "Epoch: 18, Steps: 1063 | Train Loss: 0.3335427 Vali Loss: 0.2737995 Test Loss: 0.5489855\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Updating learning rate to 0.00334177570565689\n",
      "\titers: 100, epoch: 19 | loss: 0.2128833\n",
      "\tspeed: 1.6297s/iter; left time: 141896.3176s\n",
      "\titers: 200, epoch: 19 | loss: 0.2915721\n",
      "\tspeed: 0.0962s/iter; left time: 8369.4665s\n",
      "\titers: 300, epoch: 19 | loss: 0.3272201\n",
      "\tspeed: 0.0969s/iter; left time: 8420.4674s\n",
      "\titers: 400, epoch: 19 | loss: 0.4372116\n",
      "\tspeed: 0.1019s/iter; left time: 8839.3796s\n",
      "\titers: 500, epoch: 19 | loss: 0.2261289\n",
      "\tspeed: 0.0921s/iter; left time: 7983.0091s\n",
      "\titers: 600, epoch: 19 | loss: 0.2270280\n",
      "\tspeed: 0.0921s/iter; left time: 7972.9764s\n",
      "\titers: 700, epoch: 19 | loss: 0.2555828\n",
      "\tspeed: 0.0899s/iter; left time: 7776.0998s\n",
      "\titers: 800, epoch: 19 | loss: 0.1938287\n",
      "\tspeed: 0.0848s/iter; left time: 7324.0052s\n",
      "\titers: 900, epoch: 19 | loss: 0.2902481\n",
      "\tspeed: 0.0963s/iter; left time: 8311.4281s\n",
      "\titers: 1000, epoch: 19 | loss: 0.3241431\n",
      "\tspeed: 0.0988s/iter; left time: 8516.9723s\n",
      "Epoch: 19 cost time: 100.69171619415283\n",
      "Epoch: 19, Steps: 1063 | Train Loss: 0.3383753 Vali Loss: 0.2555009 Test Loss: 0.5329122\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Updating learning rate to 0.0035763047404187174\n",
      "\titers: 100, epoch: 20 | loss: 0.4008043\n",
      "\tspeed: 1.7241s/iter; left time: 148278.5975s\n",
      "\titers: 200, epoch: 20 | loss: 0.2589297\n",
      "\tspeed: 0.0879s/iter; left time: 7552.9376s\n",
      "\titers: 300, epoch: 20 | loss: 0.4692506\n",
      "\tspeed: 0.0831s/iter; left time: 7130.0008s\n",
      "\titers: 400, epoch: 20 | loss: 0.6491532\n",
      "\tspeed: 0.0927s/iter; left time: 7947.3419s\n",
      "\titers: 500, epoch: 20 | loss: 0.2783465\n",
      "\tspeed: 0.0892s/iter; left time: 7638.3797s\n",
      "\titers: 600, epoch: 20 | loss: 0.1972369\n",
      "\tspeed: 0.0978s/iter; left time: 8361.8643s\n",
      "\titers: 700, epoch: 20 | loss: 0.4186691\n",
      "\tspeed: 0.0920s/iter; left time: 7858.7058s\n",
      "\titers: 800, epoch: 20 | loss: 0.3563157\n",
      "\tspeed: 0.0929s/iter; left time: 7927.2615s\n",
      "\titers: 900, epoch: 20 | loss: 0.2749789\n",
      "\tspeed: 0.0932s/iter; left time: 7943.2867s\n",
      "\titers: 1000, epoch: 20 | loss: 0.2835973\n",
      "\tspeed: 0.0918s/iter; left time: 7814.0798s\n",
      "Epoch: 20 cost time: 96.71155881881714\n",
      "Epoch: 20, Steps: 1063 | Train Loss: 0.3211810 Vali Loss: 0.3005919 Test Loss: 0.5528057\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Updating learning rate to 0.0038001365058778274\n",
      "\titers: 100, epoch: 21 | loss: 0.4927607\n",
      "\tspeed: 1.6430s/iter; left time: 139561.2961s\n",
      "\titers: 200, epoch: 21 | loss: 0.2828558\n",
      "\tspeed: 0.0911s/iter; left time: 7729.7778s\n",
      "\titers: 300, epoch: 21 | loss: 0.3185462\n",
      "\tspeed: 0.0930s/iter; left time: 7884.1359s\n",
      "\titers: 400, epoch: 21 | loss: 0.3809265\n",
      "\tspeed: 0.0928s/iter; left time: 7852.6268s\n",
      "\titers: 500, epoch: 21 | loss: 0.2550139\n",
      "\tspeed: 0.0932s/iter; left time: 7882.3125s\n",
      "\titers: 600, epoch: 21 | loss: 0.3432809\n",
      "\tspeed: 0.0860s/iter; left time: 7261.9346s\n",
      "\titers: 700, epoch: 21 | loss: 0.3193093\n",
      "\tspeed: 0.0970s/iter; left time: 8176.9930s\n",
      "\titers: 800, epoch: 21 | loss: 0.2441162\n",
      "\tspeed: 0.0911s/iter; left time: 7670.3218s\n",
      "\titers: 900, epoch: 21 | loss: 0.3836806\n",
      "\tspeed: 0.0941s/iter; left time: 7916.2966s\n",
      "\titers: 1000, epoch: 21 | loss: 0.3962571\n",
      "\tspeed: 0.0960s/iter; left time: 8064.8344s\n",
      "Epoch: 21 cost time: 98.81135725975037\n",
      "Epoch: 21, Steps: 1063 | Train Loss: 0.3520656 Vali Loss: 0.2734602 Test Loss: 0.6448992\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Updating learning rate to 0.00401081850070498\n",
      "\titers: 100, epoch: 22 | loss: 0.4544123\n",
      "\tspeed: 1.6147s/iter; left time: 135439.5157s\n",
      "\titers: 200, epoch: 22 | loss: 0.4187537\n",
      "\tspeed: 0.0892s/iter; left time: 7470.6976s\n",
      "\titers: 300, epoch: 22 | loss: 0.3114863\n",
      "\tspeed: 0.0971s/iter; left time: 8125.1701s\n",
      "\titers: 400, epoch: 22 | loss: 0.2556697\n",
      "\tspeed: 0.0968s/iter; left time: 8087.9262s\n",
      "\titers: 500, epoch: 22 | loss: 0.3275388\n",
      "\tspeed: 0.0991s/iter; left time: 8271.5547s\n",
      "\titers: 600, epoch: 22 | loss: 0.2990640\n",
      "\tspeed: 0.1001s/iter; left time: 8347.0969s\n",
      "\titers: 700, epoch: 22 | loss: 0.2376956\n",
      "\tspeed: 0.0950s/iter; left time: 7914.7842s\n",
      "\titers: 800, epoch: 22 | loss: 0.3666638\n",
      "\tspeed: 0.0909s/iter; left time: 7560.8450s\n",
      "\titers: 900, epoch: 22 | loss: 0.3383608\n",
      "\tspeed: 0.1041s/iter; left time: 8645.9032s\n",
      "\titers: 1000, epoch: 22 | loss: 0.2856630\n",
      "\tspeed: 0.0919s/iter; left time: 7627.4843s\n",
      "Epoch: 22 cost time: 102.21487283706665\n",
      "Epoch: 22, Steps: 1063 | Train Loss: 0.3523954 Vali Loss: 0.2398282 Test Loss: 0.4631505\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): PatchTST_backbone(\n",
       "    (backbone): TSTiEncoder(\n",
       "      (W_P): Linear(in_features=16, out_features=128, bias=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (encoder): TSTEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-2): 3 x TSTEncoderLayer(\n",
       "            (self_attn): _MultiheadAttention(\n",
       "              (W_Q): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (W_K): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (W_V): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (sdp_attn): _ScaledDotProductAttention(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (dropout_attn): Dropout(p=0.2, inplace=False)\n",
       "            (norm_attn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.2, inplace=False)\n",
       "              (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "            )\n",
       "            (dropout_ffn): Dropout(p=0.2, inplace=False)\n",
       "            (norm_ffn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): Flatten_Head(\n",
       "      (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "      (linear): Linear(in_features=5248, out_features=192, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exp = Exp_Main\n",
    "setting=f'PatchTST_train_on_{args.data}_{args.pred_len}'\n",
    "# set experiments\n",
    "exp = Exp(args)\n",
    "exp.train(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431132eb",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca36035e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 11329\n",
      "mse:0.24460437893867493, mae:0.3230002522468567, rse:0.40032851696014404\n"
     ]
    }
   ],
   "source": [
    "exp.test(setting)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcc6d82",
   "metadata": {},
   "source": [
    "---\n",
    "## Trail 3: PatchTST, Dataset:ETTm2,  Metric: 336\n",
    "\n",
    "### Set hyperparameters\n",
    "Set some parameters (Args) for the our experiment like dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8056d709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ETTm2,  Prediction Length : 336\n"
     ]
    }
   ],
   "source": [
    "args.pred_len = 336 # prediction sequence length\n",
    "print(f\"Dataset: {args.data},  Prediction Length : {args.pred_len}\") \n",
    "# print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f97484c",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4efb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "train 33889\n",
      "val 11185\n",
      "test 11185\n",
      "\titers: 100, epoch: 1 | loss: 0.4401748\n",
      "\tspeed: 0.1030s/iter; left time: 10898.1162s\n",
      "\titers: 200, epoch: 1 | loss: 0.5422932\n",
      "\tspeed: 0.0977s/iter; left time: 10327.0890s\n",
      "\titers: 300, epoch: 1 | loss: 0.3221259\n",
      "\tspeed: 0.1112s/iter; left time: 11747.2829s\n",
      "\titers: 400, epoch: 1 | loss: 0.7222717\n",
      "\tspeed: 0.1010s/iter; left time: 10656.1548s\n",
      "\titers: 500, epoch: 1 | loss: 0.3426677\n",
      "\tspeed: 0.1169s/iter; left time: 12325.2431s\n",
      "\titers: 600, epoch: 1 | loss: 0.3434246\n",
      "\tspeed: 0.1098s/iter; left time: 11563.6212s\n",
      "\titers: 700, epoch: 1 | loss: 0.5051081\n",
      "\tspeed: 0.1080s/iter; left time: 11361.8850s\n",
      "\titers: 800, epoch: 1 | loss: 0.4058499\n",
      "\tspeed: 0.0944s/iter; left time: 9919.6070s\n",
      "\titers: 900, epoch: 1 | loss: 0.4125472\n",
      "\tspeed: 0.1078s/iter; left time: 11315.0532s\n",
      "\titers: 1000, epoch: 1 | loss: 0.4514018\n",
      "\tspeed: 0.1049s/iter; left time: 11003.0042s\n",
      "Epoch: 1 cost time: 112.20184254646301\n",
      "Epoch: 1, Steps: 1059 | Train Loss: 0.4023900 Vali Loss: 0.2454564 Test Loss: 0.4043933\n",
      "Validation loss decreased (inf --> 0.245456).  Saving model ...\n",
      "Updating learning rate to 0.00021314827806317212\n",
      "\titers: 100, epoch: 2 | loss: 0.2571965\n",
      "\tspeed: 1.7181s/iter; left time: 179958.8204s\n",
      "\titers: 200, epoch: 2 | loss: 0.3154560\n",
      "\tspeed: 0.1019s/iter; left time: 10660.3124s\n",
      "\titers: 300, epoch: 2 | loss: 0.2886730\n",
      "\tspeed: 0.1042s/iter; left time: 10893.0033s\n",
      "\titers: 400, epoch: 2 | loss: 0.3832514\n",
      "\tspeed: 0.1080s/iter; left time: 11275.0865s\n",
      "\titers: 500, epoch: 2 | loss: 0.3081667\n",
      "\tspeed: 0.1002s/iter; left time: 10452.0894s\n",
      "\titers: 600, epoch: 2 | loss: 0.2681034\n",
      "\tspeed: 0.1109s/iter; left time: 11557.4417s\n",
      "\titers: 700, epoch: 2 | loss: 0.5147971\n",
      "\tspeed: 0.0948s/iter; left time: 9873.0882s\n",
      "\titers: 800, epoch: 2 | loss: 0.2134295\n",
      "\tspeed: 0.1080s/iter; left time: 11234.2695s\n",
      "\titers: 900, epoch: 2 | loss: 0.2945268\n",
      "\tspeed: 0.1041s/iter; left time: 10815.3056s\n",
      "\titers: 1000, epoch: 2 | loss: 0.2791829\n",
      "\tspeed: 0.1002s/iter; left time: 10404.7517s\n",
      "Epoch: 2 cost time: 110.82189893722534\n",
      "Epoch: 2, Steps: 1059 | Train Loss: 0.3484399 Vali Loss: 0.2260688 Test Loss: 0.3013671\n",
      "Validation loss decreased (0.245456 --> 0.226069).  Saving model ...\n",
      "Updating learning rate to 0.00025244904790599956\n",
      "\titers: 100, epoch: 3 | loss: 0.2816249\n",
      "\tspeed: 1.6927s/iter; left time: 175508.9484s\n",
      "\titers: 200, epoch: 3 | loss: 0.2262956\n",
      "\tspeed: 0.1061s/iter; left time: 10987.1381s\n",
      "\titers: 300, epoch: 3 | loss: 0.3312964\n",
      "\tspeed: 0.1031s/iter; left time: 10669.0592s\n",
      "\titers: 400, epoch: 3 | loss: 0.2744778\n",
      "\tspeed: 0.1010s/iter; left time: 10439.3684s\n",
      "\titers: 500, epoch: 3 | loss: 0.2257413\n",
      "\tspeed: 0.1069s/iter; left time: 11038.4110s\n",
      "\titers: 600, epoch: 3 | loss: 0.3055498\n",
      "\tspeed: 0.1060s/iter; left time: 10940.0467s\n",
      "\titers: 700, epoch: 3 | loss: 0.2773753\n",
      "\tspeed: 0.0980s/iter; left time: 10097.0500s\n",
      "\titers: 800, epoch: 3 | loss: 0.3472599\n",
      "\tspeed: 0.1002s/iter; left time: 10317.7797s\n",
      "\titers: 900, epoch: 3 | loss: 0.3540894\n",
      "\tspeed: 0.1011s/iter; left time: 10396.8651s\n",
      "\titers: 1000, epoch: 3 | loss: 0.3357842\n",
      "\tspeed: 0.1019s/iter; left time: 10477.7267s\n",
      "Epoch: 3 cost time: 108.77155113220215\n",
      "Epoch: 3, Steps: 1059 | Train Loss: 0.3243675 Vali Loss: 0.2647043 Test Loss: 0.3539332\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Updating learning rate to 0.00031747169498682476\n",
      "\titers: 100, epoch: 4 | loss: 0.2806730\n",
      "\tspeed: 1.8329s/iter; left time: 188097.2022s\n",
      "\titers: 200, epoch: 4 | loss: 0.2757632\n",
      "\tspeed: 0.0892s/iter; left time: 9144.9830s\n",
      "\titers: 300, epoch: 4 | loss: 0.2334811\n",
      "\tspeed: 0.1009s/iter; left time: 10333.2360s\n",
      "\titers: 400, epoch: 4 | loss: 0.2070050\n",
      "\tspeed: 0.1079s/iter; left time: 11043.2604s\n",
      "\titers: 500, epoch: 4 | loss: 0.3274098\n",
      "\tspeed: 0.1014s/iter; left time: 10364.0582s\n",
      "\titers: 600, epoch: 4 | loss: 0.3648450\n",
      "\tspeed: 0.1046s/iter; left time: 10680.3282s\n",
      "\titers: 700, epoch: 4 | loss: 0.3780724\n",
      "\tspeed: 0.1081s/iter; left time: 11033.6502s\n",
      "\titers: 800, epoch: 4 | loss: 0.3649552\n",
      "\tspeed: 0.1030s/iter; left time: 10499.1987s\n",
      "\titers: 900, epoch: 4 | loss: 0.3531912\n",
      "\tspeed: 0.1061s/iter; left time: 10805.4985s\n",
      "\titers: 1000, epoch: 4 | loss: 0.2757315\n",
      "\tspeed: 0.1028s/iter; left time: 10462.2145s\n",
      "Epoch: 4 cost time: 107.98747444152832\n",
      "Epoch: 4, Steps: 1059 | Train Loss: 0.3054501 Vali Loss: 0.2373027 Test Loss: 0.3248338\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Updating learning rate to 0.0004075037727687943\n",
      "\titers: 100, epoch: 5 | loss: 0.3896559\n",
      "\tspeed: 1.7630s/iter; left time: 179061.3617s\n",
      "\titers: 200, epoch: 5 | loss: 0.3063377\n",
      "\tspeed: 0.1141s/iter; left time: 11573.8784s\n",
      "\titers: 300, epoch: 5 | loss: 0.2201653\n",
      "\tspeed: 0.1049s/iter; left time: 10632.5454s\n",
      "\titers: 400, epoch: 5 | loss: 0.2109058\n",
      "\tspeed: 0.0991s/iter; left time: 10039.1466s\n",
      "\titers: 500, epoch: 5 | loss: 0.3571260\n",
      "\tspeed: 0.1089s/iter; left time: 11017.7726s\n",
      "\titers: 600, epoch: 5 | loss: 0.3602307\n",
      "\tspeed: 0.1108s/iter; left time: 11198.2388s\n",
      "\titers: 700, epoch: 5 | loss: 0.2883099\n",
      "\tspeed: 0.1161s/iter; left time: 11722.8628s\n",
      "\titers: 800, epoch: 5 | loss: 0.1999359\n",
      "\tspeed: 0.1059s/iter; left time: 10681.2049s\n",
      "\titers: 900, epoch: 5 | loss: 0.3844627\n",
      "\tspeed: 0.1052s/iter; left time: 10596.5430s\n",
      "\titers: 1000, epoch: 5 | loss: 0.2064380\n",
      "\tspeed: 0.1008s/iter; left time: 10151.3016s\n",
      "Epoch: 5 cost time: 115.72008323669434\n",
      "Epoch: 5, Steps: 1059 | Train Loss: 0.2910843 Vali Loss: 0.2577706 Test Loss: 0.4259371\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Updating learning rate to 0.0005215588089241743\n",
      "\titers: 100, epoch: 6 | loss: 0.2483973\n",
      "\tspeed: 1.8272s/iter; left time: 183648.6541s\n",
      "\titers: 200, epoch: 6 | loss: 0.3663763\n",
      "\tspeed: 0.1108s/iter; left time: 11125.4156s\n",
      "\titers: 300, epoch: 6 | loss: 0.2145101\n",
      "\tspeed: 0.1129s/iter; left time: 11329.4344s\n",
      "\titers: 400, epoch: 6 | loss: 0.2381754\n",
      "\tspeed: 0.1042s/iter; left time: 10440.9492s\n",
      "\titers: 500, epoch: 6 | loss: 0.2944377\n",
      "\tspeed: 0.1138s/iter; left time: 11395.5134s\n",
      "\titers: 600, epoch: 6 | loss: 0.4257794\n",
      "\tspeed: 0.0952s/iter; left time: 9524.5938s\n",
      "\titers: 700, epoch: 6 | loss: 0.1935005\n",
      "\tspeed: 0.1078s/iter; left time: 10767.5746s\n",
      "\titers: 800, epoch: 6 | loss: 0.2251147\n",
      "\tspeed: 0.1061s/iter; left time: 10589.7018s\n",
      "\titers: 900, epoch: 6 | loss: 0.2717364\n",
      "\tspeed: 0.1141s/iter; left time: 11373.4492s\n",
      "\titers: 1000, epoch: 6 | loss: 0.1863000\n",
      "\tspeed: 0.1140s/iter; left time: 11359.0899s\n",
      "Epoch: 6 cost time: 115.09947061538696\n",
      "Epoch: 6, Steps: 1059 | Train Loss: 0.2811409 Vali Loss: 0.3140468 Test Loss: 0.5532068\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Updating learning rate to 0.0006583871140114009\n",
      "\titers: 100, epoch: 7 | loss: 0.2620639\n",
      "\tspeed: 1.8570s/iter; left time: 184674.0327s\n",
      "\titers: 200, epoch: 7 | loss: 0.3514777\n",
      "\tspeed: 0.1120s/iter; left time: 11124.6984s\n",
      "\titers: 300, epoch: 7 | loss: 0.3688088\n",
      "\tspeed: 0.1071s/iter; left time: 10625.2784s\n",
      "\titers: 400, epoch: 7 | loss: 0.2985604\n",
      "\tspeed: 0.1200s/iter; left time: 11894.0356s\n",
      "\titers: 500, epoch: 7 | loss: 0.3647348\n",
      "\tspeed: 0.1039s/iter; left time: 10295.5424s\n",
      "\titers: 600, epoch: 7 | loss: 0.2830276\n",
      "\tspeed: 0.1198s/iter; left time: 11852.8735s\n",
      "\titers: 700, epoch: 7 | loss: 0.2333349\n",
      "\tspeed: 0.1173s/iter; left time: 11589.9987s\n",
      "\titers: 800, epoch: 7 | loss: 0.2735699\n",
      "\tspeed: 0.1129s/iter; left time: 11150.9407s\n",
      "\titers: 900, epoch: 7 | loss: 0.2100556\n",
      "\tspeed: 0.1080s/iter; left time: 10656.5833s\n",
      "\titers: 1000, epoch: 7 | loss: 0.2202823\n",
      "\tspeed: 0.1028s/iter; left time: 10129.2418s\n",
      "Epoch: 7 cost time: 117.99454379081726\n",
      "Epoch: 7, Steps: 1059 | Train Loss: 0.2687412 Vali Loss: 0.2592706 Test Loss: 0.4187395\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Updating learning rate to 0.0008164894741953064\n",
      "\titers: 100, epoch: 8 | loss: 0.1845372\n",
      "\tspeed: 1.8762s/iter; left time: 184599.2443s\n",
      "\titers: 200, epoch: 8 | loss: 0.1964010\n",
      "\tspeed: 0.1140s/iter; left time: 11200.6607s\n",
      "\titers: 300, epoch: 8 | loss: 0.2550322\n",
      "\tspeed: 0.1239s/iter; left time: 12162.0404s\n",
      "\titers: 400, epoch: 8 | loss: 0.2757240\n",
      "\tspeed: 0.1133s/iter; left time: 11112.2922s\n",
      "\titers: 500, epoch: 8 | loss: 0.2177419\n",
      "\tspeed: 0.1218s/iter; left time: 11932.8539s\n",
      "\titers: 600, epoch: 8 | loss: 0.3845646\n",
      "\tspeed: 0.1291s/iter; left time: 12641.3747s\n",
      "\titers: 700, epoch: 8 | loss: 0.2273962\n",
      "\tspeed: 0.2080s/iter; left time: 20339.6160s\n",
      "\titers: 800, epoch: 8 | loss: 0.1853822\n",
      "\tspeed: 0.1609s/iter; left time: 15720.5112s\n",
      "\titers: 900, epoch: 8 | loss: 0.2067098\n",
      "\tspeed: 0.1290s/iter; left time: 12588.9815s\n",
      "\titers: 1000, epoch: 8 | loss: 0.2276401\n",
      "\tspeed: 0.2228s/iter; left time: 21721.0736s\n",
      "Epoch: 8 cost time: 156.1881217956543\n",
      "Epoch: 8, Steps: 1059 | Train Loss: 0.2522283 Vali Loss: 0.2669345 Test Loss: 0.3902646\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Updating learning rate to 0.0009941335779807756\n",
      "\titers: 100, epoch: 9 | loss: 0.2134014\n",
      "\tspeed: 2.9050s/iter; left time: 282744.4963s\n",
      "\titers: 200, epoch: 9 | loss: 0.2188047\n",
      "\tspeed: 0.1090s/iter; left time: 10597.3320s\n",
      "\titers: 300, epoch: 9 | loss: 0.2343898\n",
      "\tspeed: 0.1101s/iter; left time: 10695.2798s\n",
      "\titers: 400, epoch: 9 | loss: 0.2358723\n",
      "\tspeed: 0.1081s/iter; left time: 10485.6447s\n",
      "\titers: 500, epoch: 9 | loss: 0.1675746\n",
      "\tspeed: 0.1088s/iter; left time: 10544.4032s\n",
      "\titers: 600, epoch: 9 | loss: 0.2754135\n",
      "\tspeed: 0.1035s/iter; left time: 10019.5219s\n",
      "\titers: 700, epoch: 9 | loss: 0.2890368\n",
      "\tspeed: 0.1105s/iter; left time: 10692.9759s\n",
      "\titers: 800, epoch: 9 | loss: 0.2584350\n",
      "\tspeed: 0.1080s/iter; left time: 10433.9023s\n",
      "\titers: 900, epoch: 9 | loss: 0.2003377\n",
      "\tspeed: 0.1063s/iter; left time: 10265.6216s\n",
      "\titers: 1000, epoch: 9 | loss: 0.3416343\n",
      "\tspeed: 0.1139s/iter; left time: 10980.2457s\n",
      "Epoch: 9 cost time: 115.19793176651001\n",
      "Epoch: 9, Steps: 1059 | Train Loss: 0.2545282 Vali Loss: 0.2498611 Test Loss: 0.3548174\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Updating learning rate to 0.0011893729969737607\n",
      "\titers: 100, epoch: 10 | loss: 0.1705978\n",
      "\tspeed: 1.8030s/iter; left time: 173571.2530s\n",
      "\titers: 200, epoch: 10 | loss: 0.2853386\n",
      "\tspeed: 0.1050s/iter; left time: 10101.9652s\n",
      "\titers: 300, epoch: 10 | loss: 0.2388230\n",
      "\tspeed: 0.1110s/iter; left time: 10668.0153s\n",
      "\titers: 400, epoch: 10 | loss: 0.2229032\n",
      "\tspeed: 0.1040s/iter; left time: 9984.5543s\n",
      "\titers: 500, epoch: 10 | loss: 0.2188758\n",
      "\tspeed: 0.1020s/iter; left time: 9776.1981s\n",
      "\titers: 600, epoch: 10 | loss: 0.2553244\n",
      "\tspeed: 0.1100s/iter; left time: 10537.1272s\n",
      "\titers: 700, epoch: 10 | loss: 0.2731254\n",
      "\tspeed: 0.1197s/iter; left time: 11454.1812s\n",
      "\titers: 800, epoch: 10 | loss: 0.1985476\n",
      "\tspeed: 0.1042s/iter; left time: 9962.6096s\n",
      "\titers: 900, epoch: 10 | loss: 0.2764691\n",
      "\tspeed: 0.1147s/iter; left time: 10952.7904s\n",
      "\titers: 1000, epoch: 10 | loss: 0.1723913\n",
      "\tspeed: 0.1281s/iter; left time: 12217.1775s\n",
      "Epoch: 10 cost time: 116.32503890991211\n",
      "Epoch: 10, Steps: 1059 | Train Loss: 0.2485833 Vali Loss: 0.3395384 Test Loss: 0.4028524\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Updating learning rate to 0.0014000685126994198\n",
      "\titers: 100, epoch: 11 | loss: 0.3128731\n",
      "\tspeed: 2.0162s/iter; left time: 191961.0499s\n",
      "\titers: 200, epoch: 11 | loss: 0.5669043\n",
      "\tspeed: 0.1280s/iter; left time: 12170.8775s\n",
      "\titers: 300, epoch: 11 | loss: 0.4821243\n",
      "\tspeed: 0.1220s/iter; left time: 11590.9671s\n",
      "\titers: 400, epoch: 11 | loss: 0.4018037\n",
      "\tspeed: 0.1030s/iter; left time: 9773.6853s\n",
      "\titers: 500, epoch: 11 | loss: 0.4254403\n",
      "\tspeed: 0.1070s/iter; left time: 10142.2663s\n",
      "\titers: 600, epoch: 11 | loss: 0.2890559\n",
      "\tspeed: 0.1230s/iter; left time: 11647.7226s\n",
      "\titers: 700, epoch: 11 | loss: 0.2942436\n",
      "\tspeed: 0.1268s/iter; left time: 12000.2183s\n",
      "\titers: 800, epoch: 11 | loss: 0.3006028\n",
      "\tspeed: 0.1373s/iter; left time: 12975.0854s\n",
      "\titers: 900, epoch: 11 | loss: 0.3117775\n",
      "\tspeed: 0.2280s/iter; left time: 21523.1502s\n",
      "\titers: 1000, epoch: 11 | loss: 0.4135766\n",
      "\tspeed: 0.2219s/iter; left time: 20928.8895s\n",
      "Epoch: 11 cost time: 149.39415764808655\n",
      "Epoch: 11, Steps: 1059 | Train Loss: 0.3529222 Vali Loss: 0.2421411 Test Loss: 0.3561878\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Updating learning rate to 0.001623911555801565\n",
      "\titers: 100, epoch: 12 | loss: 0.3408028\n",
      "\tspeed: 2.0252s/iter; left time: 190679.3477s\n",
      "\titers: 200, epoch: 12 | loss: 0.5074769\n",
      "\tspeed: 0.1117s/iter; left time: 10502.7086s\n",
      "\titers: 300, epoch: 12 | loss: 0.7626450\n",
      "\tspeed: 0.1140s/iter; left time: 10707.7624s\n",
      "\titers: 400, epoch: 12 | loss: 0.4975671\n",
      "\tspeed: 0.1052s/iter; left time: 9869.1141s\n",
      "\titers: 500, epoch: 12 | loss: 0.1860222\n",
      "\tspeed: 0.1138s/iter; left time: 10671.3596s\n",
      "\titers: 600, epoch: 12 | loss: 0.4587065\n",
      "\tspeed: 0.1210s/iter; left time: 11329.5669s\n",
      "\titers: 700, epoch: 12 | loss: 0.2538766\n",
      "\tspeed: 0.1142s/iter; left time: 10686.1232s\n",
      "\titers: 800, epoch: 12 | loss: 0.2954935\n",
      "\tspeed: 0.1398s/iter; left time: 13066.1898s\n",
      "\titers: 900, epoch: 12 | loss: 0.2772677\n",
      "\tspeed: 0.1890s/iter; left time: 17639.4030s\n",
      "\titers: 1000, epoch: 12 | loss: 0.3531424\n",
      "\tspeed: 0.2342s/iter; left time: 21841.6790s\n",
      "Epoch: 12 cost time: 148.50333905220032\n",
      "Epoch: 12, Steps: 1059 | Train Loss: 0.3447265 Vali Loss: 0.2507640 Test Loss: 0.3765141\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Updating learning rate to 0.0018584495008025182\n",
      "\titers: 100, epoch: 13 | loss: 0.3210990\n",
      "\tspeed: 3.6658s/iter; left time: 341262.0672s\n",
      "\titers: 200, epoch: 13 | loss: 0.2936592\n",
      "\tspeed: 0.2010s/iter; left time: 18688.0950s\n",
      "\titers: 300, epoch: 13 | loss: 0.4456398\n",
      "\tspeed: 0.2571s/iter; left time: 23884.8445s\n",
      "\titers: 400, epoch: 13 | loss: 0.6723849\n",
      "\tspeed: 0.2990s/iter; left time: 27747.4887s\n",
      "\titers: 500, epoch: 13 | loss: 0.3702572\n",
      "\tspeed: 0.2271s/iter; left time: 21045.9827s\n",
      "\titers: 600, epoch: 13 | loss: 0.3543067\n",
      "\tspeed: 0.2298s/iter; left time: 21281.9658s\n",
      "\titers: 700, epoch: 13 | loss: 0.2753006\n",
      "\tspeed: 0.2271s/iter; left time: 21005.6726s\n",
      "\titers: 800, epoch: 13 | loss: 0.2854079\n",
      "\tspeed: 0.2269s/iter; left time: 20963.2091s\n",
      "\titers: 900, epoch: 13 | loss: 0.3500788\n",
      "\tspeed: 0.2231s/iter; left time: 20593.2484s\n",
      "\titers: 1000, epoch: 13 | loss: 0.3479631\n",
      "\tspeed: 0.2941s/iter; left time: 27109.9403s\n",
      "Epoch: 13 cost time: 257.9147379398346\n",
      "Epoch: 13, Steps: 1059 | Train Loss: 0.3684426 Vali Loss: 0.2655584 Test Loss: 0.3532808\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Updating learning rate to 0.00210111253927125\n",
      "\titers: 100, epoch: 14 | loss: 0.4349500\n",
      "\tspeed: 3.9599s/iter; left time: 364449.6904s\n",
      "\titers: 200, epoch: 14 | loss: 0.3077633\n",
      "\tspeed: 0.2660s/iter; left time: 24456.3335s\n",
      "\titers: 300, epoch: 14 | loss: 0.2610802\n",
      "\tspeed: 0.2591s/iter; left time: 23790.2022s\n",
      "\titers: 400, epoch: 14 | loss: 0.4630559\n",
      "\tspeed: 0.3040s/iter; left time: 27887.5971s\n",
      "\titers: 500, epoch: 14 | loss: 0.2925757\n",
      "\tspeed: 0.3118s/iter; left time: 28570.2901s\n",
      "\titers: 600, epoch: 14 | loss: 0.3343959\n",
      "\tspeed: 0.2971s/iter; left time: 27190.5742s\n",
      "\titers: 700, epoch: 14 | loss: 0.6358486\n",
      "\tspeed: 0.2931s/iter; left time: 26798.8709s\n",
      "\titers: 800, epoch: 14 | loss: 0.2791616\n",
      "\tspeed: 0.3218s/iter; left time: 29392.0654s\n",
      "\titers: 900, epoch: 14 | loss: 0.3980779\n",
      "\tspeed: 0.3610s/iter; left time: 32937.3620s\n",
      "\titers: 1000, epoch: 14 | loss: 0.3359269\n",
      "\tspeed: 0.3302s/iter; left time: 30088.7984s\n",
      "Epoch: 14 cost time: 319.5914444923401\n",
      "Epoch: 14, Steps: 1059 | Train Loss: 0.3552203 Vali Loss: 0.2751789 Test Loss: 0.4268894\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Updating learning rate to 0.0023492418369532235\n",
      "\titers: 100, epoch: 15 | loss: 0.4096157\n",
      "\tspeed: 7.2781s/iter; left time: 662122.9971s\n",
      "\titers: 200, epoch: 15 | loss: 0.4464207\n",
      "\tspeed: 0.3298s/iter; left time: 29970.8978s\n",
      "\titers: 300, epoch: 15 | loss: 0.2725753\n",
      "\tspeed: 0.3691s/iter; left time: 33506.4093s\n",
      "\titers: 400, epoch: 15 | loss: 0.2588170\n",
      "\tspeed: 0.3470s/iter; left time: 31461.3712s\n",
      "\titers: 500, epoch: 15 | loss: 0.2503833\n",
      "\tspeed: 0.3421s/iter; left time: 30985.8183s\n",
      "\titers: 600, epoch: 15 | loss: 0.3620712\n",
      "\tspeed: 0.3398s/iter; left time: 30739.5093s\n",
      "\titers: 700, epoch: 15 | loss: 0.2451329\n",
      "\tspeed: 0.3552s/iter; left time: 32099.7305s\n",
      "\titers: 800, epoch: 15 | loss: 0.3592632\n",
      "\tspeed: 0.3589s/iter; left time: 32400.4679s\n",
      "\titers: 900, epoch: 15 | loss: 0.3812117\n",
      "\tspeed: 0.4730s/iter; left time: 42653.5023s\n",
      "\titers: 1000, epoch: 15 | loss: 0.3420056\n",
      "\tspeed: 0.4661s/iter; left time: 41985.1096s\n",
      "Epoch: 15 cost time: 423.717755317688\n",
      "Epoch: 15, Steps: 1059 | Train Loss: 0.3564524 Vali Loss: 0.2681546 Test Loss: 0.3516504\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Updating learning rate to 0.0026001186663471548\n",
      "\titers: 100, epoch: 16 | loss: 0.3154500\n",
      "\tspeed: 7.0329s/iter; left time: 632372.3969s\n",
      "\titers: 200, epoch: 16 | loss: 0.2857058\n",
      "\tspeed: 0.3569s/iter; left time: 32057.5890s\n",
      "\titers: 300, epoch: 16 | loss: 0.2125641\n",
      "\tspeed: 0.3679s/iter; left time: 33010.8339s\n",
      "\titers: 400, epoch: 16 | loss: 0.2894378\n",
      "\tspeed: 0.4250s/iter; left time: 38085.0512s\n",
      "\titers: 500, epoch: 16 | loss: 0.2728182\n",
      "\tspeed: 0.5931s/iter; left time: 53090.2595s\n",
      "\titers: 600, epoch: 16 | loss: 0.2601228\n",
      "\tspeed: 0.5949s/iter; left time: 53196.0081s\n",
      "\titers: 700, epoch: 16 | loss: 0.1916155\n",
      "\tspeed: 0.6000s/iter; left time: 53589.0438s\n",
      "\titers: 800, epoch: 16 | loss: 0.2134269\n",
      "\tspeed: 0.6141s/iter; left time: 54786.7325s\n",
      "\titers: 900, epoch: 16 | loss: 0.4192522\n",
      "\tspeed: 0.5869s/iter; left time: 52304.9109s\n",
      "\titers: 1000, epoch: 16 | loss: 0.2703533\n",
      "\tspeed: 0.5451s/iter; left time: 48522.9136s\n",
      "Epoch: 16 cost time: 527.3016831874847\n",
      "Epoch: 16, Steps: 1059 | Train Loss: 0.3783840 Vali Loss: 0.2589285 Test Loss: 0.3613908\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Updating learning rate to 0.002850994195525979\n",
      "\titers: 100, epoch: 17 | loss: 0.2408244\n",
      "\tspeed: 6.2660s/iter; left time: 556780.2258s\n",
      "\titers: 200, epoch: 17 | loss: 0.3033597\n",
      "\tspeed: 0.3561s/iter; left time: 31607.7147s\n",
      "\titers: 300, epoch: 17 | loss: 0.3854488\n",
      "\tspeed: 0.3629s/iter; left time: 32170.6421s\n",
      "\titers: 400, epoch: 17 | loss: 0.3061281\n",
      "\tspeed: 0.3501s/iter; left time: 30999.9172s\n",
      "\titers: 500, epoch: 17 | loss: 0.4338572\n",
      "\tspeed: 0.4290s/iter; left time: 37944.0167s\n",
      "\titers: 600, epoch: 17 | loss: 0.3028900\n",
      "\tspeed: 0.4679s/iter; left time: 41341.1648s\n",
      "\titers: 700, epoch: 17 | loss: 0.3879633\n",
      "\tspeed: 0.4570s/iter; left time: 40330.9465s\n",
      "\titers: 800, epoch: 17 | loss: 0.4479241\n",
      "\tspeed: 0.4722s/iter; left time: 41630.2494s\n",
      "\titers: 900, epoch: 17 | loss: 0.3377287\n",
      "\tspeed: 0.3788s/iter; left time: 33354.7912s\n",
      "\titers: 1000, epoch: 17 | loss: 0.3703802\n",
      "\tspeed: 0.3430s/iter; left time: 30172.2623s\n",
      "Epoch: 17 cost time: 417.30429196357727\n",
      "Epoch: 17, Steps: 1059 | Train Loss: 0.3669414 Vali Loss: 0.3066694 Test Loss: 0.4134468\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Updating learning rate to 0.0030991196068089547\n",
      "\titers: 100, epoch: 18 | loss: 0.4629577\n",
      "\tspeed: 6.1950s/iter; left time: 543906.5000s\n",
      "\titers: 200, epoch: 18 | loss: 0.3317726\n",
      "\tspeed: 0.3541s/iter; left time: 31051.7020s\n",
      "\titers: 300, epoch: 18 | loss: 0.3443174\n",
      "\tspeed: 0.3580s/iter; left time: 31360.1188s\n",
      "\titers: 400, epoch: 18 | loss: 0.2833342\n",
      "\tspeed: 0.4719s/iter; left time: 41291.4780s\n",
      "\titers: 500, epoch: 18 | loss: 0.3748202\n",
      "\tspeed: 0.4590s/iter; left time: 40118.1849s\n",
      "\titers: 600, epoch: 18 | loss: 0.4926224\n",
      "\tspeed: 0.4650s/iter; left time: 40597.8474s\n",
      "\titers: 700, epoch: 18 | loss: 0.2748054\n",
      "\tspeed: 0.4462s/iter; left time: 38906.2296s\n",
      "\titers: 800, epoch: 18 | loss: 0.3300471\n",
      "\tspeed: 0.3649s/iter; left time: 31781.0539s\n",
      "\titers: 900, epoch: 18 | loss: 0.3169562\n",
      "\tspeed: 0.3519s/iter; left time: 30612.6760s\n",
      "\titers: 1000, epoch: 18 | loss: 0.3073115\n",
      "\tspeed: 0.3420s/iter; left time: 29715.4966s\n",
      "Epoch: 18 cost time: 418.3026645183563\n",
      "Epoch: 18, Steps: 1059 | Train Loss: 0.3787965 Vali Loss: 0.3383077 Test Loss: 0.6673880\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Updating learning rate to 0.0033417762152776753\n",
      "\titers: 100, epoch: 19 | loss: 0.2796184\n",
      "\tspeed: 6.3181s/iter; left time: 548026.8019s\n",
      "\titers: 200, epoch: 19 | loss: 0.3796871\n",
      "\tspeed: 0.4370s/iter; left time: 37859.9882s\n",
      "\titers: 300, epoch: 19 | loss: 0.3792863\n",
      "\tspeed: 0.4689s/iter; left time: 40578.0041s\n",
      "\titers: 400, epoch: 19 | loss: 0.6191514\n",
      "\tspeed: 0.4591s/iter; left time: 39686.8820s\n",
      "\titers: 500, epoch: 19 | loss: 0.4424975\n",
      "\tspeed: 0.4600s/iter; left time: 39717.1245s\n",
      "\titers: 600, epoch: 19 | loss: 0.4307166\n",
      "\tspeed: 0.4291s/iter; left time: 37002.7222s\n",
      "\titers: 700, epoch: 19 | loss: 0.2997456\n",
      "\tspeed: 0.3779s/iter; left time: 32553.5682s\n",
      "\titers: 800, epoch: 19 | loss: 0.2830936\n",
      "\tspeed: 0.3369s/iter; left time: 28985.4076s\n",
      "\titers: 900, epoch: 19 | loss: 0.4026217\n",
      "\tspeed: 0.3250s/iter; left time: 27928.5301s\n",
      "\titers: 1000, epoch: 19 | loss: 0.3679082\n",
      "\tspeed: 0.3322s/iter; left time: 28516.4661s\n",
      "Epoch: 19 cost time: 419.77430748939514\n",
      "Epoch: 19, Steps: 1059 | Train Loss: 0.3862156 Vali Loss: 0.2805347 Test Loss: 0.6576432\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Updating learning rate to 0.0035763052571304655\n",
      "\titers: 100, epoch: 20 | loss: 0.3083633\n",
      "\tspeed: 7.1108s/iter; left time: 609251.6652s\n",
      "\titers: 200, epoch: 20 | loss: 0.3792100\n",
      "\tspeed: 0.7851s/iter; left time: 67187.6134s\n",
      "\titers: 300, epoch: 20 | loss: 0.3226756\n",
      "\tspeed: 0.7660s/iter; left time: 65474.1609s\n",
      "\titers: 400, epoch: 20 | loss: 0.2751724\n",
      "\tspeed: 0.7661s/iter; left time: 65409.6336s\n",
      "\titers: 500, epoch: 20 | loss: 0.2417019\n",
      "\tspeed: 0.7250s/iter; left time: 61825.4778s\n",
      "\titers: 600, epoch: 20 | loss: 0.3393027\n",
      "\tspeed: 0.7241s/iter; left time: 61674.7642s\n",
      "\titers: 700, epoch: 20 | loss: 0.2339223\n",
      "\tspeed: 0.7419s/iter; left time: 63117.3420s\n",
      "\titers: 800, epoch: 20 | loss: 0.3552803\n",
      "\tspeed: 0.7260s/iter; left time: 61698.7103s\n",
      "\titers: 900, epoch: 20 | loss: 0.2712102\n",
      "\tspeed: 0.7301s/iter; left time: 61974.3291s\n",
      "\titers: 1000, epoch: 20 | loss: 0.3020853\n",
      "\tspeed: 0.6950s/iter; left time: 58922.2401s\n",
      "Epoch: 20 cost time: 766.8885185718536\n",
      "Epoch: 20, Steps: 1059 | Train Loss: 0.3755410 Vali Loss: 0.2737915 Test Loss: 0.5543501\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Updating learning rate to 0.0038001370214871813\n",
      "\titers: 100, epoch: 21 | loss: 0.3760686\n",
      "\tspeed: 8.1939s/iter; left time: 693372.5172s\n",
      "\titers: 200, epoch: 21 | loss: 0.3035435\n",
      "\tspeed: 0.3331s/iter; left time: 28153.7186s\n",
      "\titers: 300, epoch: 21 | loss: 0.5106573\n",
      "\tspeed: 0.3348s/iter; left time: 28267.5640s\n",
      "\titers: 400, epoch: 21 | loss: 0.5407304\n",
      "\tspeed: 0.3411s/iter; left time: 28763.3455s\n",
      "\titers: 500, epoch: 21 | loss: 0.6487441\n",
      "\tspeed: 0.3301s/iter; left time: 27801.8216s\n",
      "\titers: 600, epoch: 21 | loss: 0.3017833\n",
      "\tspeed: 0.3139s/iter; left time: 26406.9298s\n",
      "\titers: 700, epoch: 21 | loss: 0.5165290\n",
      "\tspeed: 0.3381s/iter; left time: 28407.0065s\n",
      "\titers: 800, epoch: 21 | loss: 0.4256693\n",
      "\tspeed: 0.3268s/iter; left time: 27422.3820s\n",
      "\titers: 900, epoch: 21 | loss: 0.2420259\n",
      "\tspeed: 0.3710s/iter; left time: 31101.0768s\n",
      "\titers: 1000, epoch: 21 | loss: 0.3226547\n",
      "\tspeed: 0.4232s/iter; left time: 35428.2289s\n",
      "Epoch: 21 cost time: 377.1977949142456\n",
      "Epoch: 21, Steps: 1059 | Train Loss: 0.4032170 Vali Loss: 0.3066720 Test Loss: 0.4517811\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Updating learning rate to 0.004010819006450213\n",
      "\titers: 100, epoch: 22 | loss: 0.4295470\n",
      "\tspeed: 6.1809s/iter; left time: 516490.1550s\n",
      "\titers: 200, epoch: 22 | loss: 0.6774302\n",
      "\tspeed: 0.3271s/iter; left time: 27298.6540s\n",
      "\titers: 300, epoch: 22 | loss: 0.4568318\n",
      "\tspeed: 0.3409s/iter; left time: 28421.2215s\n",
      "\titers: 400, epoch: 22 | loss: 0.3201110\n",
      "\tspeed: 0.3279s/iter; left time: 27301.8595s\n",
      "\titers: 500, epoch: 22 | loss: 0.2771139\n",
      "\tspeed: 0.3521s/iter; left time: 29277.3244s\n",
      "\titers: 600, epoch: 22 | loss: 0.3404574\n",
      "\tspeed: 0.3350s/iter; left time: 27827.6907s\n",
      "\titers: 700, epoch: 22 | loss: 0.2697943\n",
      "\tspeed: 0.3471s/iter; left time: 28799.1088s\n",
      "\titers: 800, epoch: 22 | loss: 0.3314655\n",
      "\tspeed: 0.4040s/iter; left time: 33474.9110s\n",
      "\titers: 900, epoch: 22 | loss: 0.3948396\n",
      "\tspeed: 0.4439s/iter; left time: 36739.7467s\n",
      "\titers: 1000, epoch: 22 | loss: 0.4243910\n",
      "\tspeed: 0.4513s/iter; left time: 37302.4094s\n",
      "Epoch: 22 cost time: 391.4971911907196\n",
      "Epoch: 22, Steps: 1059 | Train Loss: 0.3920734 Vali Loss: 0.2730600 Test Loss: 0.3631283\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): PatchTST_backbone(\n",
       "    (backbone): TSTiEncoder(\n",
       "      (W_P): Linear(in_features=16, out_features=128, bias=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (encoder): TSTEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-2): 3 x TSTEncoderLayer(\n",
       "            (self_attn): _MultiheadAttention(\n",
       "              (W_Q): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (W_K): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (W_V): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (sdp_attn): _ScaledDotProductAttention(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (dropout_attn): Dropout(p=0.2, inplace=False)\n",
       "            (norm_attn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.2, inplace=False)\n",
       "              (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "            )\n",
       "            (dropout_ffn): Dropout(p=0.2, inplace=False)\n",
       "            (norm_ffn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): Flatten_Head(\n",
       "      (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "      (linear): Linear(in_features=5248, out_features=336, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exp = Exp_Main\n",
    "setting=f'PatchTST_train_on_{args.data}_{args.pred_len}'\n",
    "# set experiments\n",
    "exp = Exp(args)\n",
    "exp.train(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cfcbf6",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb59aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 11185\n",
      "mse:0.3013668358325958, mae:0.35843971371650696, rse:0.4432353377342224\n"
     ]
    }
   ],
   "source": [
    "exp.test(setting)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbba07d",
   "metadata": {},
   "source": [
    "---\n",
    "## Trail 4: PatchTST, Dataset:ETTm2,  Metric: 720\n",
    "\n",
    "### Set hyperparameters\n",
    "Set some parameters (Args) for the our experiment like dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8f5423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ETTm2,  Prediction Length : 720\n"
     ]
    }
   ],
   "source": [
    "args.pred_len = 720 # prediction sequence length\n",
    "print(f\"Dataset: {args.data},  Prediction Length : {args.pred_len}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca4b90c",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f56874c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "train 33505\n",
      "val 10801\n",
      "test 10801\n",
      "\titers: 100, epoch: 1 | loss: 0.2949437\n",
      "\tspeed: 0.3523s/iter; left time: 36853.6838s\n",
      "\titers: 200, epoch: 1 | loss: 0.8657505\n",
      "\tspeed: 0.4260s/iter; left time: 44519.8551s\n",
      "\titers: 300, epoch: 1 | loss: 0.3538330\n",
      "\tspeed: 0.4561s/iter; left time: 47612.6423s\n",
      "\titers: 400, epoch: 1 | loss: 0.3703703\n",
      "\tspeed: 0.4670s/iter; left time: 48712.9703s\n",
      "\titers: 500, epoch: 1 | loss: 0.6584207\n",
      "\tspeed: 0.4519s/iter; left time: 47086.6378s\n",
      "\titers: 600, epoch: 1 | loss: 0.5931085\n",
      "\tspeed: 0.3570s/iter; left time: 37162.7061s\n",
      "\titers: 700, epoch: 1 | loss: 0.3703278\n",
      "\tspeed: 0.3511s/iter; left time: 36516.6377s\n",
      "\titers: 800, epoch: 1 | loss: 0.2711176\n",
      "\tspeed: 0.3659s/iter; left time: 38018.1046s\n",
      "\titers: 900, epoch: 1 | loss: 0.3374104\n",
      "\tspeed: 0.3499s/iter; left time: 36324.9557s\n",
      "\titers: 1000, epoch: 1 | loss: 0.5459972\n",
      "\tspeed: 0.3690s/iter; left time: 38269.0294s\n",
      "Epoch: 1 cost time: 410.51699566841125\n",
      "Epoch: 1, Steps: 1047 | Train Loss: 0.5027259 Vali Loss: 0.2946491 Test Loss: 0.3930673\n",
      "Validation loss decreased (inf --> 0.294649).  Saving model ...\n",
      "Updating learning rate to 0.00021314828754152686\n",
      "\titers: 100, epoch: 2 | loss: 0.3017486\n",
      "\tspeed: 6.4571s/iter; left time: 668661.2075s\n",
      "\titers: 200, epoch: 2 | loss: 0.4161893\n",
      "\tspeed: 0.3969s/iter; left time: 41060.7720s\n",
      "\titers: 300, epoch: 2 | loss: 0.3991577\n",
      "\tspeed: 0.3661s/iter; left time: 37834.8161s\n",
      "\titers: 400, epoch: 2 | loss: 0.5014530\n",
      "\tspeed: 0.3570s/iter; left time: 36859.1737s\n",
      "\titers: 500, epoch: 2 | loss: 0.3841600\n",
      "\tspeed: 0.3559s/iter; left time: 36716.6877s\n",
      "\titers: 600, epoch: 2 | loss: 0.3961470\n",
      "\tspeed: 0.3502s/iter; left time: 36086.4919s\n",
      "\titers: 700, epoch: 2 | loss: 0.3753093\n",
      "\tspeed: 0.3778s/iter; left time: 38895.0943s\n",
      "\titers: 800, epoch: 2 | loss: 0.3777305\n",
      "\tspeed: 0.3361s/iter; left time: 34569.9488s\n",
      "\titers: 900, epoch: 2 | loss: 0.3328338\n",
      "\tspeed: 0.4490s/iter; left time: 46139.3725s\n",
      "\titers: 1000, epoch: 2 | loss: 0.6354039\n",
      "\tspeed: 0.4790s/iter; left time: 49172.4967s\n",
      "Epoch: 2 cost time: 416.21111392974854\n",
      "Epoch: 2, Steps: 1047 | Train Loss: 0.4444984 Vali Loss: 0.3185882 Test Loss: 0.5095870\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Updating learning rate to 0.00025244908561171224\n",
      "\titers: 100, epoch: 3 | loss: 0.3431017\n",
      "\tspeed: 6.3318s/iter; left time: 649057.1628s\n",
      "\titers: 200, epoch: 3 | loss: 0.4068609\n",
      "\tspeed: 0.3681s/iter; left time: 37694.8808s\n",
      "\titers: 300, epoch: 3 | loss: 0.5091508\n",
      "\tspeed: 0.3559s/iter; left time: 36413.9753s\n",
      "\titers: 400, epoch: 3 | loss: 0.3774953\n",
      "\tspeed: 0.3530s/iter; left time: 36077.3976s\n",
      "\titers: 500, epoch: 3 | loss: 0.4285896\n",
      "\tspeed: 0.3771s/iter; left time: 38509.6350s\n",
      "\titers: 600, epoch: 3 | loss: 0.3926800\n",
      "\tspeed: 0.4750s/iter; left time: 48448.7958s\n",
      "\titers: 700, epoch: 3 | loss: 0.3572131\n",
      "\tspeed: 0.4739s/iter; left time: 48297.3150s\n",
      "\titers: 800, epoch: 3 | loss: 0.4245554\n",
      "\tspeed: 0.4850s/iter; left time: 49376.4955s\n",
      "\titers: 900, epoch: 3 | loss: 0.3835365\n",
      "\tspeed: 0.4620s/iter; left time: 46991.0723s\n",
      "\titers: 1000, epoch: 3 | loss: 0.3331112\n",
      "\tspeed: 0.4380s/iter; left time: 44498.9408s\n",
      "Epoch: 3 cost time: 432.0046491622925\n",
      "Epoch: 3, Steps: 1047 | Train Loss: 0.4145130 Vali Loss: 0.3288545 Test Loss: 0.4865827\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Updating learning rate to 0.00031747177904919207\n",
      "\titers: 100, epoch: 4 | loss: 0.6457956\n",
      "\tspeed: 6.1891s/iter; left time: 627947.9289s\n",
      "\titers: 200, epoch: 4 | loss: 0.3079990\n",
      "\tspeed: 0.3709s/iter; left time: 37596.9705s\n",
      "\titers: 300, epoch: 4 | loss: 0.3358302\n",
      "\tspeed: 0.3691s/iter; left time: 37374.0439s\n",
      "\titers: 400, epoch: 4 | loss: 0.3369409\n",
      "\tspeed: 0.3590s/iter; left time: 36313.8242s\n",
      "\titers: 500, epoch: 4 | loss: 0.3607472\n",
      "\tspeed: 0.3880s/iter; left time: 39211.7830s\n",
      "\titers: 600, epoch: 4 | loss: 0.2757963\n",
      "\tspeed: 0.4580s/iter; left time: 46239.6932s\n",
      "\titers: 700, epoch: 4 | loss: 0.2902972\n",
      "\tspeed: 0.4779s/iter; left time: 48202.8364s\n",
      "\titers: 800, epoch: 4 | loss: 0.3665338\n",
      "\tspeed: 0.4610s/iter; left time: 46453.6518s\n",
      "\titers: 900, epoch: 4 | loss: 0.2772483\n",
      "\tspeed: 0.3993s/iter; left time: 40190.7839s\n",
      "\titers: 1000, epoch: 4 | loss: 0.4407834\n",
      "\tspeed: 0.3847s/iter; left time: 38684.6967s\n",
      "Epoch: 4 cost time: 421.3139326572418\n",
      "Epoch: 4, Steps: 1047 | Train Loss: 0.3894261 Vali Loss: 0.3690714 Test Loss: 0.5527086\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Updating learning rate to 0.00040750392029559844\n",
      "\titers: 100, epoch: 5 | loss: 0.3672725\n",
      "\tspeed: 6.1412s/iter; left time: 616652.7618s\n",
      "\titers: 200, epoch: 5 | loss: 0.3295778\n",
      "\tspeed: 0.3698s/iter; left time: 37094.4270s\n",
      "\titers: 300, epoch: 5 | loss: 0.3452764\n",
      "\tspeed: 0.3552s/iter; left time: 35595.0404s\n",
      "\titers: 400, epoch: 5 | loss: 0.3210312\n",
      "\tspeed: 0.4659s/iter; left time: 46639.7556s\n",
      "\titers: 500, epoch: 5 | loss: 0.3000572\n",
      "\tspeed: 0.4660s/iter; left time: 46601.0681s\n",
      "\titers: 600, epoch: 5 | loss: 0.2212833\n",
      "\tspeed: 0.4622s/iter; left time: 46177.8289s\n",
      "\titers: 700, epoch: 5 | loss: 0.4202524\n",
      "\tspeed: 0.4548s/iter; left time: 45397.5732s\n",
      "\titers: 800, epoch: 5 | loss: 0.3187603\n",
      "\tspeed: 0.4541s/iter; left time: 45280.6524s\n",
      "\titers: 900, epoch: 5 | loss: 0.2811488\n",
      "\tspeed: 0.3669s/iter; left time: 36544.7784s\n",
      "\titers: 1000, epoch: 5 | loss: 0.3215207\n",
      "\tspeed: 0.3490s/iter; left time: 34732.1838s\n",
      "Epoch: 5 cost time: 424.9047532081604\n",
      "Epoch: 5, Steps: 1047 | Train Loss: 0.3694771 Vali Loss: 0.3610373 Test Loss: 0.4634228\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Updating learning rate to 0.0005215590356166906\n",
      "\titers: 100, epoch: 6 | loss: 0.2417310\n",
      "\tspeed: 5.6851s/iter; left time: 564905.7674s\n",
      "\titers: 200, epoch: 6 | loss: 0.3014424\n",
      "\tspeed: 0.3410s/iter; left time: 33848.3195s\n",
      "\titers: 300, epoch: 6 | loss: 0.2758686\n",
      "\tspeed: 0.3389s/iter; left time: 33606.3274s\n",
      "\titers: 400, epoch: 6 | loss: 0.2795708\n",
      "\tspeed: 0.3212s/iter; left time: 31816.4763s\n",
      "\titers: 500, epoch: 6 | loss: 0.3259834\n",
      "\tspeed: 0.4200s/iter; left time: 41564.4031s\n",
      "\titers: 600, epoch: 6 | loss: 0.4473558\n",
      "\tspeed: 0.4271s/iter; left time: 42221.1667s\n",
      "\titers: 700, epoch: 6 | loss: 0.3602542\n",
      "\tspeed: 0.4391s/iter; left time: 43364.2279s\n",
      "\titers: 800, epoch: 6 | loss: 0.3302968\n",
      "\tspeed: 0.4017s/iter; left time: 39638.5802s\n",
      "\titers: 900, epoch: 6 | loss: 0.4063141\n",
      "\tspeed: 0.3481s/iter; left time: 34306.1819s\n",
      "\titers: 1000, epoch: 6 | loss: 0.2725025\n",
      "\tspeed: 0.3330s/iter; left time: 32792.1352s\n",
      "Epoch: 6 cost time: 386.8066756725311\n",
      "Epoch: 6, Steps: 1047 | Train Loss: 0.3502433 Vali Loss: 0.3538483 Test Loss: 0.5008769\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Updating learning rate to 0.0006583874338026178\n",
      "\titers: 100, epoch: 7 | loss: 0.3565946\n",
      "\tspeed: 5.5019s/iter; left time: 540941.8179s\n",
      "\titers: 200, epoch: 7 | loss: 0.3094568\n",
      "\tspeed: 0.3312s/iter; left time: 32526.9599s\n",
      "\titers: 300, epoch: 7 | loss: 0.2591558\n",
      "\tspeed: 0.3340s/iter; left time: 32776.3986s\n",
      "\titers: 400, epoch: 7 | loss: 0.3692208\n",
      "\tspeed: 0.3769s/iter; left time: 36943.0695s\n",
      "\titers: 500, epoch: 7 | loss: 0.3297894\n",
      "\tspeed: 0.4379s/iter; left time: 42877.3443s\n",
      "\titers: 600, epoch: 7 | loss: 0.2336789\n",
      "\tspeed: 0.4461s/iter; left time: 43638.7224s\n",
      "\titers: 700, epoch: 7 | loss: 0.4055492\n",
      "\tspeed: 0.4379s/iter; left time: 42793.4584s\n",
      "\titers: 800, epoch: 7 | loss: 0.3533462\n",
      "\tspeed: 0.3230s/iter; left time: 31533.1687s\n",
      "\titers: 900, epoch: 7 | loss: 0.5492975\n",
      "\tspeed: 0.3221s/iter; left time: 31411.2440s\n",
      "\titers: 1000, epoch: 7 | loss: 0.3434221\n",
      "\tspeed: 0.3309s/iter; left time: 32236.7144s\n",
      "Epoch: 7 cost time: 384.18237566947937\n",
      "Epoch: 7, Steps: 1047 | Train Loss: 0.3247531 Vali Loss: 0.3571140 Test Loss: 0.5164676\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Updating learning rate to 0.0008164898989173816\n",
      "\titers: 100, epoch: 8 | loss: 0.3914958\n",
      "\tspeed: 5.5351s/iter; left time: 538410.7252s\n",
      "\titers: 200, epoch: 8 | loss: 0.2539486\n",
      "\tspeed: 0.3259s/iter; left time: 31665.6207s\n",
      "\titers: 300, epoch: 8 | loss: 0.3176886\n",
      "\tspeed: 0.3420s/iter; left time: 33200.2358s\n",
      "\titers: 400, epoch: 8 | loss: 0.3438441\n",
      "\tspeed: 0.4241s/iter; left time: 41124.1442s\n",
      "\titers: 500, epoch: 8 | loss: 0.3111409\n",
      "\tspeed: 0.4409s/iter; left time: 42707.9091s\n",
      "\titers: 600, epoch: 8 | loss: 0.2772051\n",
      "\tspeed: 0.4450s/iter; left time: 43062.4791s\n",
      "\titers: 700, epoch: 8 | loss: 0.2511033\n",
      "\tspeed: 0.4231s/iter; left time: 40902.4738s\n",
      "\titers: 800, epoch: 8 | loss: 0.3384694\n",
      "\tspeed: 0.4302s/iter; left time: 41540.5682s\n",
      "\titers: 900, epoch: 8 | loss: 0.2906554\n",
      "\tspeed: 0.2729s/iter; left time: 26331.3615s\n",
      "\titers: 1000, epoch: 8 | loss: 0.3205668\n",
      "\tspeed: 0.3049s/iter; left time: 29383.6222s\n",
      "Epoch: 8 cost time: 389.0017514228821\n",
      "Epoch: 8, Steps: 1047 | Train Loss: 0.3041128 Vali Loss: 0.4017514 Test Loss: 0.6090229\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Updating learning rate to 0.0009941341170673574\n",
      "\titers: 100, epoch: 9 | loss: 0.3533549\n",
      "\tspeed: 5.0560s/iter; left time: 486516.7154s\n",
      "\titers: 200, epoch: 9 | loss: 0.2532784\n",
      "\tspeed: 0.3409s/iter; left time: 32772.1254s\n",
      "\titers: 300, epoch: 9 | loss: 0.4089308\n",
      "\tspeed: 0.3280s/iter; left time: 31496.7011s\n",
      "\titers: 400, epoch: 9 | loss: 0.4014816\n",
      "\tspeed: 0.3320s/iter; left time: 31844.3234s\n",
      "\titers: 500, epoch: 9 | loss: 0.2309908\n",
      "\tspeed: 0.3330s/iter; left time: 31905.6396s\n",
      "\titers: 600, epoch: 9 | loss: 0.2997770\n",
      "\tspeed: 0.3250s/iter; left time: 31113.4906s\n",
      "\titers: 700, epoch: 9 | loss: 0.2664208\n",
      "\tspeed: 0.3301s/iter; left time: 31567.2527s\n",
      "\titers: 800, epoch: 9 | loss: 0.3399932\n",
      "\tspeed: 0.3222s/iter; left time: 30777.5740s\n",
      "\titers: 900, epoch: 9 | loss: 0.2763721\n",
      "\tspeed: 0.3317s/iter; left time: 31647.8532s\n",
      "\titers: 1000, epoch: 9 | loss: 0.2083537\n",
      "\tspeed: 0.3112s/iter; left time: 29660.8367s\n",
      "Epoch: 9 cost time: 345.5996286869049\n",
      "Epoch: 9, Steps: 1047 | Train Loss: 0.2936215 Vali Loss: 0.3765737 Test Loss: 0.5201599\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Updating learning rate to 0.0011893736572022714\n",
      "\titers: 100, epoch: 10 | loss: 0.4473637\n",
      "\tspeed: 5.6460s/iter; left time: 537374.5999s\n",
      "\titers: 200, epoch: 10 | loss: 0.2492246\n",
      "\tspeed: 0.4449s/iter; left time: 42301.8289s\n",
      "\titers: 300, epoch: 10 | loss: 0.2428414\n",
      "\tspeed: 0.4279s/iter; left time: 40644.4398s\n",
      "\titers: 400, epoch: 10 | loss: 0.2271190\n",
      "\tspeed: 0.4540s/iter; left time: 43075.8528s\n",
      "\titers: 500, epoch: 10 | loss: 0.3480138\n",
      "\tspeed: 0.4360s/iter; left time: 41321.7667s\n",
      "\titers: 600, epoch: 10 | loss: 0.3068928\n",
      "\tspeed: 0.4254s/iter; left time: 40271.3797s\n",
      "\titers: 700, epoch: 10 | loss: 0.2894973\n",
      "\tspeed: 0.4407s/iter; left time: 41677.3390s\n",
      "\titers: 800, epoch: 10 | loss: 0.2761613\n",
      "\tspeed: 0.4450s/iter; left time: 42041.7874s\n",
      "\titers: 900, epoch: 10 | loss: 0.2786397\n",
      "\tspeed: 0.4381s/iter; left time: 41342.4537s\n",
      "\titers: 1000, epoch: 10 | loss: 0.2621397\n",
      "\tspeed: 0.4320s/iter; left time: 40729.6005s\n",
      "Epoch: 10 cost time: 456.49585914611816\n",
      "Epoch: 10, Steps: 1047 | Train Loss: 0.2817865 Vali Loss: 0.3780961 Test Loss: 0.4802564\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Updating learning rate to 0.0014000692979778168\n",
      "\titers: 100, epoch: 11 | loss: 0.2108110\n",
      "\tspeed: 5.5740s/iter; left time: 524684.5899s\n",
      "\titers: 200, epoch: 11 | loss: 0.3265758\n",
      "\tspeed: 0.3210s/iter; left time: 30180.3368s\n",
      "\titers: 300, epoch: 11 | loss: 0.3584332\n",
      "\tspeed: 0.3300s/iter; left time: 31000.2663s\n",
      "\titers: 400, epoch: 11 | loss: 0.3023160\n",
      "\tspeed: 0.3019s/iter; left time: 28332.0852s\n",
      "\titers: 500, epoch: 11 | loss: 0.3090826\n",
      "\tspeed: 0.3162s/iter; left time: 29636.5499s\n",
      "\titers: 600, epoch: 11 | loss: 0.3250398\n",
      "\tspeed: 0.3398s/iter; left time: 31817.5946s\n",
      "\titers: 700, epoch: 11 | loss: 0.2563840\n",
      "\tspeed: 0.3271s/iter; left time: 30592.3520s\n",
      "\titers: 800, epoch: 11 | loss: 0.2942249\n",
      "\tspeed: 0.3311s/iter; left time: 30934.5442s\n",
      "\titers: 900, epoch: 11 | loss: 0.2440730\n",
      "\tspeed: 0.3290s/iter; left time: 30708.8871s\n",
      "\titers: 1000, epoch: 11 | loss: 0.3905061\n",
      "\tspeed: 0.3338s/iter; left time: 31118.7639s\n",
      "Epoch: 11 cost time: 342.32390904426575\n",
      "Epoch: 11, Steps: 1047 | Train Loss: 0.2881017 Vali Loss: 0.3739040 Test Loss: 0.4033081\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Updating learning rate to 0.0016239124670034398\n",
      "\titers: 100, epoch: 12 | loss: 0.3889026\n",
      "\tspeed: 5.1010s/iter; left time: 474821.6299s\n",
      "\titers: 200, epoch: 12 | loss: 0.3693558\n",
      "\tspeed: 0.3350s/iter; left time: 31149.2108s\n",
      "\titers: 300, epoch: 12 | loss: 0.3356895\n",
      "\tspeed: 0.3112s/iter; left time: 28906.3987s\n",
      "\titers: 400, epoch: 12 | loss: 0.3385721\n",
      "\tspeed: 0.4128s/iter; left time: 38303.3650s\n",
      "\titers: 500, epoch: 12 | loss: 0.2725324\n",
      "\tspeed: 0.4410s/iter; left time: 40875.9624s\n",
      "\titers: 600, epoch: 12 | loss: 0.2419038\n",
      "\tspeed: 0.4401s/iter; left time: 40741.9074s\n",
      "\titers: 700, epoch: 12 | loss: 0.2465722\n",
      "\tspeed: 0.4479s/iter; left time: 41425.5043s\n",
      "\titers: 800, epoch: 12 | loss: 0.2848138\n",
      "\tspeed: 0.4392s/iter; left time: 40574.3776s\n",
      "\titers: 900, epoch: 12 | loss: 0.2891808\n",
      "\tspeed: 0.4290s/iter; left time: 39585.5945s\n",
      "\titers: 1000, epoch: 12 | loss: 0.2896015\n",
      "\tspeed: 0.4518s/iter; left time: 41651.5660s\n",
      "Epoch: 12 cost time: 423.01089334487915\n",
      "Epoch: 12, Steps: 1047 | Train Loss: 0.3121380 Vali Loss: 0.3830597 Test Loss: 0.5071394\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Updating learning rate to 0.0018584505356536792\n",
      "\titers: 100, epoch: 13 | loss: 0.3779915\n",
      "\tspeed: 6.4860s/iter; left time: 596951.5196s\n",
      "\titers: 200, epoch: 13 | loss: 0.3444454\n",
      "\tspeed: 0.3350s/iter; left time: 30798.4242s\n",
      "\titers: 300, epoch: 13 | loss: 0.2098237\n",
      "\tspeed: 0.3210s/iter; left time: 29479.9125s\n",
      "\titers: 400, epoch: 13 | loss: 0.3150337\n",
      "\tspeed: 0.3230s/iter; left time: 29630.8399s\n",
      "\titers: 500, epoch: 13 | loss: 0.4641393\n",
      "\tspeed: 0.3231s/iter; left time: 29612.1536s\n",
      "\titers: 600, epoch: 13 | loss: 0.2304707\n",
      "\tspeed: 0.3199s/iter; left time: 29283.3334s\n",
      "\titers: 700, epoch: 13 | loss: 0.2001424\n",
      "\tspeed: 0.3431s/iter; left time: 31372.6494s\n",
      "\titers: 800, epoch: 13 | loss: 0.2784059\n",
      "\tspeed: 0.3201s/iter; left time: 29234.1247s\n",
      "\titers: 900, epoch: 13 | loss: 0.2253390\n",
      "\tspeed: 0.3499s/iter; left time: 31923.9888s\n",
      "\titers: 1000, epoch: 13 | loss: 0.3265966\n",
      "\tspeed: 0.2102s/iter; left time: 19155.5409s\n",
      "Epoch: 13 cost time: 323.924681186676\n",
      "Epoch: 13, Steps: 1047 | Train Loss: 0.2958181 Vali Loss: 0.4501164 Test Loss: 0.5836146\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Updating learning rate to 0.0021011136922901613\n",
      "\titers: 100, epoch: 14 | loss: 0.4639778\n",
      "\tspeed: 1.9120s/iter; left time: 173969.0986s\n",
      "\titers: 200, epoch: 14 | loss: 0.3074532\n",
      "\tspeed: 0.0980s/iter; left time: 8906.8399s\n",
      "\titers: 300, epoch: 14 | loss: 0.2555628\n",
      "\tspeed: 0.1040s/iter; left time: 9443.5151s\n",
      "\titers: 400, epoch: 14 | loss: 0.5794921\n",
      "\tspeed: 0.1137s/iter; left time: 10312.5887s\n",
      "\titers: 500, epoch: 14 | loss: 0.2803272\n",
      "\tspeed: 0.1102s/iter; left time: 9981.4564s\n",
      "\titers: 600, epoch: 14 | loss: 0.3634336\n",
      "\tspeed: 0.1051s/iter; left time: 9512.9054s\n",
      "\titers: 700, epoch: 14 | loss: 0.6801400\n",
      "\tspeed: 0.1039s/iter; left time: 9395.0681s\n",
      "\titers: 800, epoch: 14 | loss: 0.3912366\n",
      "\tspeed: 0.1110s/iter; left time: 10023.2781s\n",
      "\titers: 900, epoch: 14 | loss: 0.3527757\n",
      "\tspeed: 0.1020s/iter; left time: 9200.6857s\n",
      "\titers: 1000, epoch: 14 | loss: 0.3697698\n",
      "\tspeed: 0.1068s/iter; left time: 9621.3608s\n",
      "Epoch: 14 cost time: 111.59213185310364\n",
      "Epoch: 14, Steps: 1047 | Train Loss: 0.3600223 Vali Loss: 0.4795335 Test Loss: 0.7961571\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Updating learning rate to 0.002349243099446893\n",
      "\titers: 100, epoch: 15 | loss: 0.3960978\n",
      "\tspeed: 3.0540s/iter; left time: 274688.1881s\n",
      "\titers: 200, epoch: 15 | loss: 0.3179326\n",
      "\tspeed: 0.2241s/iter; left time: 20133.4165s\n",
      "\titers: 300, epoch: 15 | loss: 0.7023801\n",
      "\tspeed: 0.2210s/iter; left time: 19831.8969s\n",
      "\titers: 400, epoch: 15 | loss: 0.4711274\n",
      "\tspeed: 0.2381s/iter; left time: 21341.7189s\n",
      "\titers: 500, epoch: 15 | loss: 0.3494137\n",
      "\tspeed: 0.3309s/iter; left time: 29627.7255s\n",
      "\titers: 600, epoch: 15 | loss: 0.4448909\n",
      "\tspeed: 0.2781s/iter; left time: 24871.9235s\n",
      "\titers: 700, epoch: 15 | loss: 0.2523688\n",
      "\tspeed: 0.2071s/iter; left time: 18503.6934s\n",
      "\titers: 800, epoch: 15 | loss: 0.4064528\n",
      "\tspeed: 0.2258s/iter; left time: 20152.8117s\n",
      "\titers: 900, epoch: 15 | loss: 0.3606653\n",
      "\tspeed: 0.2009s/iter; left time: 17912.4961s\n",
      "\titers: 1000, epoch: 15 | loss: 0.3170582\n",
      "\tspeed: 0.2273s/iter; left time: 20239.6926s\n",
      "Epoch: 15 cost time: 248.5079584121704\n",
      "Epoch: 15, Steps: 1047 | Train Loss: 0.4360125 Vali Loss: 0.3313555 Test Loss: 0.4866230\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Updating learning rate to 0.0026001200264632028\n",
      "\titers: 100, epoch: 16 | loss: 0.4297650\n",
      "\tspeed: 3.9187s/iter; left time: 348361.0408s\n",
      "\titers: 200, epoch: 16 | loss: 0.5540642\n",
      "\tspeed: 0.2251s/iter; left time: 19986.4881s\n",
      "\titers: 300, epoch: 16 | loss: 0.7069722\n",
      "\tspeed: 0.1968s/iter; left time: 17455.3707s\n",
      "\titers: 400, epoch: 16 | loss: 0.3158711\n",
      "\tspeed: 0.2101s/iter; left time: 18613.7798s\n",
      "\titers: 500, epoch: 16 | loss: 0.5112680\n",
      "\tspeed: 0.2239s/iter; left time: 19814.6410s\n",
      "\titers: 600, epoch: 16 | loss: 0.3919389\n",
      "\tspeed: 0.2401s/iter; left time: 21226.6234s\n",
      "\titers: 700, epoch: 16 | loss: 0.6918677\n",
      "\tspeed: 0.2210s/iter; left time: 19517.4357s\n",
      "\titers: 800, epoch: 16 | loss: 0.3899342\n",
      "\tspeed: 0.2192s/iter; left time: 19329.9212s\n",
      "\titers: 900, epoch: 16 | loss: 0.5764273\n",
      "\tspeed: 0.2067s/iter; left time: 18209.7148s\n",
      "\titers: 1000, epoch: 16 | loss: 0.4402377\n",
      "\tspeed: 0.2271s/iter; left time: 19985.5207s\n",
      "Epoch: 16 cost time: 231.09910035133362\n",
      "Epoch: 16, Steps: 1047 | Train Loss: 0.4534053 Vali Loss: 0.3438300 Test Loss: 0.4616021\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Updating learning rate to 0.0028509956383608033\n",
      "\titers: 100, epoch: 17 | loss: 0.3963515\n",
      "\tspeed: 4.1510s/iter; left time: 364661.3541s\n",
      "\titers: 200, epoch: 17 | loss: 0.4022421\n",
      "\tspeed: 0.2061s/iter; left time: 18082.0457s\n",
      "\titers: 300, epoch: 17 | loss: 0.7288215\n",
      "\tspeed: 0.2198s/iter; left time: 19267.7353s\n",
      "\titers: 400, epoch: 17 | loss: 0.7358111\n",
      "\tspeed: 0.2322s/iter; left time: 20325.5661s\n",
      "\titers: 500, epoch: 17 | loss: 0.3221314\n",
      "\tspeed: 0.2089s/iter; left time: 18271.0633s\n",
      "\titers: 600, epoch: 17 | loss: 0.5424894\n",
      "\tspeed: 0.2259s/iter; left time: 19729.9380s\n",
      "\titers: 700, epoch: 17 | loss: 0.7168568\n",
      "\tspeed: 0.2172s/iter; left time: 18946.1546s\n",
      "\titers: 800, epoch: 17 | loss: 0.5428334\n",
      "\tspeed: 0.2150s/iter; left time: 18738.1890s\n",
      "\titers: 900, epoch: 17 | loss: 0.6686635\n",
      "\tspeed: 0.2269s/iter; left time: 19753.0610s\n",
      "\titers: 1000, epoch: 17 | loss: 0.3221341\n",
      "\tspeed: 0.2279s/iter; left time: 19813.7535s\n",
      "Epoch: 17 cost time: 231.5144305229187\n",
      "Epoch: 17, Steps: 1047 | Train Loss: 0.4641940 Vali Loss: 0.3583253 Test Loss: 0.7865935\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Updating learning rate to 0.00309912111457104\n",
      "\titers: 100, epoch: 18 | loss: 0.2726431\n",
      "\tspeed: 3.8730s/iter; left time: 336183.3173s\n",
      "\titers: 200, epoch: 18 | loss: 0.4752985\n",
      "\tspeed: 0.2941s/iter; left time: 25496.5533s\n",
      "\titers: 300, epoch: 18 | loss: 0.3614736\n",
      "\tspeed: 0.3070s/iter; left time: 26586.7244s\n",
      "\titers: 400, epoch: 18 | loss: 0.3076224\n",
      "\tspeed: 0.3001s/iter; left time: 25956.5225s\n",
      "\titers: 500, epoch: 18 | loss: 0.6153498\n",
      "\tspeed: 0.2029s/iter; left time: 17528.8201s\n",
      "\titers: 600, epoch: 18 | loss: 0.7320676\n",
      "\tspeed: 0.2190s/iter; left time: 18898.9881s\n",
      "\titers: 700, epoch: 18 | loss: 0.3365445\n",
      "\tspeed: 0.2303s/iter; left time: 19849.7988s\n",
      "\titers: 800, epoch: 18 | loss: 0.6766329\n",
      "\tspeed: 0.2190s/iter; left time: 18856.0971s\n",
      "\titers: 900, epoch: 18 | loss: 0.3903949\n",
      "\tspeed: 0.2218s/iter; left time: 19075.8133s\n",
      "\titers: 1000, epoch: 18 | loss: 0.7666185\n",
      "\tspeed: 0.2130s/iter; left time: 18292.8594s\n",
      "Epoch: 18 cost time: 264.09879994392395\n",
      "Epoch: 18, Steps: 1047 | Train Loss: 0.4643991 Vali Loss: 0.4282673 Test Loss: 0.5484781\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Updating learning rate to 0.0033417777675042544\n",
      "\titers: 100, epoch: 19 | loss: 0.2946793\n",
      "\tspeed: 3.4633s/iter; left time: 296994.2185s\n",
      "\titers: 200, epoch: 19 | loss: 0.3028231\n",
      "\tspeed: 0.3037s/iter; left time: 26014.0318s\n",
      "\titers: 300, epoch: 19 | loss: 0.4350162\n",
      "\tspeed: 0.3111s/iter; left time: 26615.3792s\n",
      "\titers: 400, epoch: 19 | loss: 0.5169563\n",
      "\tspeed: 0.2979s/iter; left time: 25456.0832s\n",
      "\titers: 500, epoch: 19 | loss: 0.6876037\n",
      "\tspeed: 0.3120s/iter; left time: 26630.7922s\n",
      "\titers: 600, epoch: 19 | loss: 0.2662513\n",
      "\tspeed: 0.3103s/iter; left time: 26456.2853s\n",
      "\titers: 700, epoch: 19 | loss: 0.4198073\n",
      "\tspeed: 0.3098s/iter; left time: 26381.8673s\n",
      "\titers: 800, epoch: 19 | loss: 0.7568004\n",
      "\tspeed: 0.3081s/iter; left time: 26203.0343s\n",
      "\titers: 900, epoch: 19 | loss: 0.4267732\n",
      "\tspeed: 0.2098s/iter; left time: 17824.2568s\n",
      "\titers: 1000, epoch: 19 | loss: 0.4442010\n",
      "\tspeed: 0.2160s/iter; left time: 18330.4671s\n",
      "Epoch: 19 cost time: 288.19360184669495\n",
      "Epoch: 19, Steps: 1047 | Train Loss: 0.4821382 Vali Loss: 0.3741992 Test Loss: 0.5905896\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Updating learning rate to 0.00357630683095492\n",
      "\titers: 100, epoch: 20 | loss: 0.5159686\n",
      "\tspeed: 3.2880s/iter; left time: 278519.7715s\n",
      "\titers: 200, epoch: 20 | loss: 0.4741187\n",
      "\tspeed: 0.1842s/iter; left time: 15585.8309s\n",
      "\titers: 300, epoch: 20 | loss: 0.5360455\n",
      "\tspeed: 0.2028s/iter; left time: 17134.5612s\n",
      "\titers: 400, epoch: 20 | loss: 0.5435162\n",
      "\tspeed: 0.2191s/iter; left time: 18492.9869s\n",
      "\titers: 500, epoch: 20 | loss: 0.3649034\n",
      "\tspeed: 0.2220s/iter; left time: 18714.9511s\n",
      "\titers: 600, epoch: 20 | loss: 0.4268269\n",
      "\tspeed: 0.1970s/iter; left time: 16592.3668s\n",
      "\titers: 700, epoch: 20 | loss: 0.6381600\n",
      "\tspeed: 0.2729s/iter; left time: 22954.5723s\n",
      "\titers: 800, epoch: 20 | loss: 0.5398762\n",
      "\tspeed: 0.3090s/iter; left time: 25956.4299s\n",
      "\titers: 900, epoch: 20 | loss: 0.6392728\n",
      "\tspeed: 0.3351s/iter; left time: 28119.4297s\n",
      "\titers: 1000, epoch: 20 | loss: 0.4087259\n",
      "\tspeed: 0.3190s/iter; left time: 26732.5252s\n",
      "Epoch: 20 cost time: 262.2927691936493\n",
      "Epoch: 20, Steps: 1047 | Train Loss: 0.4697873 Vali Loss: 0.4545306 Test Loss: 0.7796924\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Updating learning rate to 0.003800138591953792\n",
      "\titers: 100, epoch: 21 | loss: 0.4208873\n",
      "\tspeed: 5.2201s/iter; left time: 436717.3374s\n",
      "\titers: 200, epoch: 21 | loss: 0.4047890\n",
      "\tspeed: 0.3530s/iter; left time: 29493.9458s\n",
      "\titers: 300, epoch: 21 | loss: 0.3317319\n",
      "\tspeed: 0.3592s/iter; left time: 29975.3327s\n",
      "\titers: 400, epoch: 21 | loss: 0.5361326\n",
      "\tspeed: 0.3398s/iter; left time: 28328.6277s\n",
      "\titers: 500, epoch: 21 | loss: 0.7574785\n",
      "\tspeed: 0.3479s/iter; left time: 28966.0292s\n",
      "\titers: 600, epoch: 21 | loss: 0.3195833\n",
      "\tspeed: 0.3293s/iter; left time: 27383.0736s\n",
      "\titers: 700, epoch: 21 | loss: 0.6818704\n",
      "\tspeed: 0.3358s/iter; left time: 27894.9035s\n",
      "\titers: 800, epoch: 21 | loss: 0.5093860\n",
      "\tspeed: 0.3359s/iter; left time: 27863.2067s\n",
      "\titers: 900, epoch: 21 | loss: 0.5763773\n",
      "\tspeed: 0.3422s/iter; left time: 28355.1130s\n",
      "\titers: 1000, epoch: 21 | loss: 0.3802993\n",
      "\tspeed: 0.3418s/iter; left time: 28287.5477s\n",
      "Epoch: 21 cost time: 362.4105429649353\n",
      "Epoch: 21, Steps: 1047 | Train Loss: 0.4634687 Vali Loss: 0.4651189 Test Loss: 0.8351835\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): PatchTST_backbone(\n",
       "    (backbone): TSTiEncoder(\n",
       "      (W_P): Linear(in_features=16, out_features=128, bias=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (encoder): TSTEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-2): 3 x TSTEncoderLayer(\n",
       "            (self_attn): _MultiheadAttention(\n",
       "              (W_Q): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (W_K): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (W_V): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (sdp_attn): _ScaledDotProductAttention(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (dropout_attn): Dropout(p=0.2, inplace=False)\n",
       "            (norm_attn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.2, inplace=False)\n",
       "              (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "            )\n",
       "            (dropout_ffn): Dropout(p=0.2, inplace=False)\n",
       "            (norm_ffn): Sequential(\n",
       "              (0): Transpose()\n",
       "              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Transpose()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): Flatten_Head(\n",
       "      (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "      (linear): Linear(in_features=5248, out_features=720, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exp = Exp_Main\n",
    "setting=f'PatchTST_train_on_{args.data}_{args.pred_len}'\n",
    "# set experiments\n",
    "exp = Exp(args)\n",
    "exp.train(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b56e28a",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a7e70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 10801\n",
      "mse:0.3930669128894806, mae:0.4152883291244507, rse:0.5037342309951782\n"
     ]
    }
   ],
   "source": [
    "exp.test(setting)\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
